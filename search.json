[
  {
    "objectID": "tile_clustering.html",
    "href": "tile_clustering.html",
    "title": "Tile Clustering",
    "section": "",
    "text": "cluster together adjacent grid tiles\nsource"
  },
  {
    "objectID": "tile_clustering.html#test-data",
    "href": "tile_clustering.html#test-data",
    "title": "Tile Clustering",
    "section": "Test data",
    "text": "Test data\nCreate sample scores for square grid cells and cluster the cells\n\nimport geopandas as gpd\nimport numpy as np\n\nfrom geowrangler2 import grids\n\n\nnp.random.seed(1562)\n\nregion3_gdf = gpd.read_file(\"../data/region3_admin.geojson\")\n\n\ngrid_generator5k = grids.SquareGridGenerator(5_000)\ngrid_gdf5k = grid_generator5k.generate_grid(region3_gdf)\ngrid_gdf5k.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n\n\n3\n9\n9\nPOLYGON ((120.19008 14.79871, 120.23499 14.798...\n\n\n4\n10\n9\nPOLYGON ((120.23499 14.79871, 120.27991 14.798...\n\n\n\n\n\n\n\n\ngrid_gdf5k.plot()\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\ngrid_gdf5k[\"score\"] = np.random.random(len(grid_gdf5k))\ngrid_gdf5k[\"class\"] = grid_gdf5k[\"score\"] &gt; 0.7\ngrid_gdf5k.head()\n\nCPU times: user 3.15 ms, sys: 1.32 ms, total: 4.47 ms\nWall time: 10 ms\n\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.761806\nTrue\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.012455\nFalse\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.446552\nFalse\n\n\n3\n9\n9\nPOLYGON ((120.19008 14.79871, 120.23499 14.798...\n0.669020\nFalse\n\n\n4\n10\n9\nPOLYGON ((120.23499 14.79871, 120.27991 14.798...\n0.815914\nTrue\n\n\n\n\n\n\n\n\ntileclustering = TileClustering()\ngrid_gdf5k = tileclustering.cluster_tiles(grid_gdf5k, category_col=\"class\")\ngrid_gdf5k.head()\n\nCPU times: user 25.8 ms, sys: 0 ns, total: 25.8 ms\nWall time: 47.6 ms\n\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\ntile_cluster\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.761806\nTrue\n6-1\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.012455\nFalse\n7-2\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.446552\nFalse\n1-2\n\n\n3\n9\n9\nPOLYGON ((120.19008 14.79871, 120.23499 14.798...\n0.669020\nFalse\n1-2\n\n\n4\n10\n9\nPOLYGON ((120.23499 14.79871, 120.27991 14.798...\n0.815914\nTrue\n23-1\n\n\n\n\n\n\n\n\ngrid_gdf5k[\"tile_cluster\"].nunique()\n\n160\n\n\n\ngrid_gdf5k.plot(column=\"class\", categorical=True, cmap=\"Spectral\")\n\n&lt;AxesSubplot:&gt;"
  },
  {
    "objectID": "spatialjoin_highest_intersection.html",
    "href": "spatialjoin_highest_intersection.html",
    "title": "Spatial Join Highest Intersection",
    "section": "",
    "text": "Import\n\n\nGenerate Test Data\n\n\nLoad a sample admin boundary file using geopandas\n\nadmin_bounds_gdf = gpd.read_file(\"../data/geoboundary.geojson\")\n\n\nadmin_bounds_gdf.head(3)\n\n\n\n\n\n\n\n\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\ngeometry\n\n\n\n\n0\nAbra\nNone\nPHL-ADM2-3_0_0-B1\nPHL\nADM2\nMULTIPOLYGON (((120.96795 17.95706, 120.97803 ...\n\n\n1\nAgusan del Norte\nNone\nPHL-ADM2-3_0_0-B2\nPHL\nADM2\nMULTIPOLYGON (((125.57724 9.45679, 125.59687 9...\n\n\n2\nAgusan del Sur\nNone\nPHL-ADM2-3_0_0-B3\nPHL\nADM2\nMULTIPOLYGON (((125.91087 8.85625, 125.91461 8...\n\n\n\n\n\n\n\n\nadmin_bounds_gdf.dtypes\n\nshapeName       object\nshapeISO        object\nshapeID         object\nshapeGroup      object\nshapeType       object\ngeometry      geometry\ndtype: object\n\n\n\n# admin_bounds_gdf.explore()\n\n\n\nGenerate a sample grid\n\ngrid_generator5k = grids.SquareGridGenerator(50_000)  # 5 km x 5 km square cells\n\n\ngrid_gdf = grid_generator5k.generate_grid(admin_bounds_gdf)\n\nCPU times: user 3.67 s, sys: 19.1 ms, total: 3.69 s\nWall time: 3.69 s\n\n\n\ngrid_gdf.plot();\n\n\n\n\n\nax = admin_bounds_gdf.plot(facecolor=\"grey\", edgecolor=\"grey\", alpha=0.2)\nax = grid_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\ngrid_gdf.describe()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\ncount\n323.000000\n323.000000\n\n\nmean\n11.773994\n15.018576\n\n\nstd\n4.861594\n8.791210\n\n\nmin\n0.000000\n0.000000\n\n\n25%\n8.000000\n8.000000\n\n\n50%\n11.000000\n14.000000\n\n\n75%\n16.000000\n21.000000\n\n\nmax\n21.000000\n37.000000\n\n\n\n\n\n\n\n\ngrid_gdf.head(3)\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n3\n3\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n\n\n1\n2\n3\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n\n\n2\n3\n4\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n\n\n\n\n\n\n\n\ngrid_gdf.dtypes\n\nx              int64\ny              int64\ngeometry    geometry\ndtype: object\n\n\n\n\nSpatial join with highest intersection\n\nsource\n\nget_highest_intersection\n\n get_highest_intersection (gdf1:geopandas.geodataframe.GeoDataFrame,\n                           gdf2:geopandas.geodataframe.GeoDataFrame,\n                           proj_crs:str)\n\nGets the intersection based on the largest area joined\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ngdf1\nGeoDataFrame\ngdf1 will be the basis of output geometry\n\n\ngdf2\nGeoDataFrame\ngdf2 data will all be included during intersection\n\n\nproj_crs\nstr\nmetric CRS (e.g., Philippines uses EPSG:32651)\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\nget_highest_intersection(grid_gdf, admin_bounds_gdf, \"EPSG:32651\")\n\n\n\n\n\n\n\n\ngeometry\nx\ny\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\n\n\n\n\n0\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n3\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n1\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n2\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n2\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n3\n4\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n3\nPOLYGON ((118.27581 6.82146, 118.72497 6.82146...\n3\n5\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n4\nPOLYGON ((116.92834 7.26723, 117.37749 7.26723...\n0\n6\nPalawan\nNone\nPHL-ADM2-3_0_0-B59\nPHL\nADM2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n318\nPOLYGON ((125.46233 5.03451, 125.91149 5.03451...\n19\n1\nDavao del Sur\nNone\nPHL-ADM2-3_0_0-B28\nPHL\nADM2\n\n\n319\nPOLYGON ((125.46233 9.93163, 125.91149 9.93163...\n19\n12\nDinagat Islands\nNone\nPHL-ADM2-3_0_0-B30\nPHL\nADM2\n\n\n320\nPOLYGON ((125.46233 10.37375, 125.91149 10.373...\n19\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n321\nPOLYGON ((125.91149 9.93163, 126.36065 9.93163...\n20\n12\nSurigao del Norte\nNone\nPHL-ADM2-3_0_0-B74\nPHL\nADM2\n\n\n322\nPOLYGON ((125.91149 10.37375, 126.36065 10.373...\n20\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n\n\n323 rows × 8 columns\n\n\n\n\n\n\nCheck plot of output\n\noutput = get_highest_intersection(grid_gdf, admin_bounds_gdf, \"EPSG:32651\")\n\n\noutput.plot()\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\n# output.explore()"
  },
  {
    "objectID": "raster_to_dataframe.html",
    "href": "raster_to_dataframe.html",
    "title": "Raster to Dataframe",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "raster_to_dataframe.html#test-data",
    "href": "raster_to_dataframe.html#test-data",
    "title": "Raster to Dataframe",
    "section": "Test data",
    "text": "Test data\n\nConverting an image to dataframe with labels\n\n# Get filepaths\ntiff_files = [\"../data/raster_to_df_sample/cabanglasan.tif\"]\nmask_file = \"../data/raster_to_df_sample/cabanglasan_mask.tiff\"\n\n\ndata = read_bands(tiff_files, mask_file)\n\n/home/avell/miniconda3/envs/geowrangler2/lib/python3.9/site-packages/rasterio/__init__.py:220: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix be returned.\n  s = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)\n\n\n\ndata\n\n\n\n\n\n\n\n\nB1_0\nB2_0\nB3_0\nB4_0\nB5_0\nB6_0\nB7_0\nB8_0\nB9_0\nB10_0\nB11_0\nB12_0\nlabel\n\n\n\n\n0\n514530987\n413800618\n400693218\n299766238\n458038093\n869741527\n1069432766\n1010383929\n1207977984\n161941927\n855782146\n430381479\n0\n\n\n1\n514530987\n411441286\n397088683\n304091680\n458038093\n869741527\n1069432766\n1027554623\n1207977984\n161941927\n855782146\n430381479\n0\n\n\n2\n493034851\n404559901\n406329400\n303632921\n445848211\n875967542\n1064320880\n994261827\n1166755211\n165349851\n783429298\n387389207\n0\n\n\n3\n493034851\n394729351\n380114600\n270995495\n445848211\n875967542\n1064320880\n1000749990\n1166755211\n165349851\n783429298\n387389207\n0\n\n\n4\n493034851\n401610736\n390010687\n276172918\n453778188\n894645587\n1059143457\n1039613431\n1159218456\n165349851\n775237173\n383981283\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n775824\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n775825\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n775826\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n775827\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n775828\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n\n\n775829 rows × 13 columns"
  },
  {
    "objectID": "tutorial.geometry_validation.html",
    "href": "tutorial.geometry_validation.html",
    "title": "Geometry Validation Tutorial",
    "section": "",
    "text": "A basic introduction to using geometry validation"
  },
  {
    "objectID": "tutorial.geometry_validation.html#basic-usage",
    "href": "tutorial.geometry_validation.html#basic-usage",
    "title": "Geometry Validation Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nLoading a geojson with invalid geometries\n\nimport geopandas as gpd\nimport pandas as pd\n\ngdf = gpd.read_file(\"../data/broken.geojson\")\ngdf = pd.concat([gdf, gpd.GeoDataFrame({\"geometry\": [None], \"id\": \"null geometry\"})])\ngdf\n\n/home/jt/.cache/pypoetry/virtualenvs/geowrangler2-U9oiUrW5-py3.9/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\nid\ngeometry\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n\n\n3\nself_intersecting\nPOLYGON ((0.00000 0.00000, 1.00000 1.00000, 2....\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 0.00000, 5.00000 0.00000, 5....\n\n\n0\nnull geometry\nNone\n\n\n\n\n\n\n\nWe then run Geometry Validation. By default, these append a new column if the validation fails, applies a fix if possible, and raises a warning if no fix is available.\n\nfrom geowrangler2.validation import GeometryValidation\n\nGeometryValidation(gdf)\n\nvalidated_gdf = GeometryValidation(gdf).validate_all()\nvalidated_gdf\n\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found null geometries\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found geometries out of bounds from crs\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found geometries with area equals or less than zero\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_null\nis_not_self_intersecting\nis_oriented_properly\nis_within_crs_bounds\narea_is_not_zero\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\nTrue\nTrue\nFalse\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 0.00000 0.000...\nTrue\nFalse\nFalse\nTrue\nTrue\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 0.00000 2.50000, 0....\nTrue\nFalse\nFalse\nTrue\nTrue\n\n\n0\nnull geometry\nNone\nFalse\nTrue\nTrue\nTrue\nTrue\n\n\n\n\n\n\n\n\ngdf.iloc[5].geometry.area\n\n0.0\n\n\nRunning the validation again shows that validation applies some fixes\n\nGeometryValidation(validated_gdf[[\"id\", \"geometry\"]]).validate_all()\n\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found null geometries\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found geometries out of bounds from crs\n  warnings.warn(self.warning_message)\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found geometries with area equals or less than zero\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_null\nis_not_self_intersecting\nis_oriented_properly\nis_within_crs_bounds\narea_is_not_zero\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\nTrue\nTrue\nFalse\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 0.00000 0.000...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\nTrue\nTrue\nTrue\nFalse\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 0.00000 2.50000, 0....\nTrue\nTrue\nTrue\nTrue\nTrue\n\n\n0\nnull geometry\nNone\nFalse\nTrue\nTrue\nTrue\nTrue"
  },
  {
    "objectID": "tutorial.geometry_validation.html#passing-validators",
    "href": "tutorial.geometry_validation.html#passing-validators",
    "title": "Geometry Validation Tutorial",
    "section": "Passing Validators",
    "text": "Passing Validators\nYou can pass a list of Validators to selective run validators, the default uses the following - NullValidator - Checks if geometry is null. No fix - OrientationValidator - Check the orientation of the outer most ring of each polygon is counter clockwise. Converts it to counter-clockwise if as the fix - SelfIntersectingValidator - Checks if the polygons is self intersecting. Runs shapely.validation.make_valid as the fix. - CrsBoundsValidator - Checks if bounds of each geometry are within the CRS. No fix - AreaValidator - Checks if polygons or multipolygon have an area greater than zero\n\nfrom geowrangler2.validation import NullValidator, SelfIntersectingValidator\n\nvalidated_gdf = GeometryValidation(\n    gdf, validators=[NullValidator, SelfIntersectingValidator]\n).validate_all()\nvalidated_gdf\n\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found null geometries\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_null\nis_not_self_intersecting\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\nTrue\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 1.00000 1.000...\nTrue\nFalse\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\nTrue\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 5.00000 5.00000, 5....\nTrue\nFalse\n\n\n0\nnull geometry\nNone\nFalse\nTrue\n\n\n\n\n\n\n\nYou can also use a single validator at a time\n\nSelfIntersectingValidator().validate(gdf)\n\n\n\n\n\n\n\n\nid\ngeometry\nis_not_self_intersecting\n\n\n\n\n0\nvalid\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 0....\nTrue\n\n\n1\nout_of_crs_bounds\nPOLYGON ((200.00000 0.00000, 0.00000 1.00000, ...\nTrue\n\n\n2\nmisoriented\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\nTrue\n\n\n3\nself_intersecting\nMULTIPOLYGON (((0.00000 2.00000, 1.00000 1.000...\nFalse\n\n\n4\ncounterclockwise\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\n\n\n5\nsliver\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 0....\nTrue\n\n\n6\nholes\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\n\n\n7\nnon-closed polygon\nPOLYGON ((0.00000 0.00000, 1.00000 0.00000, 1....\nTrue\n\n\n8\nmultipolygon\nMULTIPOLYGON (((0.00000 0.00000, 1.00000 0.000...\nTrue\n\n\n9\npolygon z\nPOLYGON Z ((0.00000 0.00000 1.00000, 1.00000 0...\nTrue\n\n\n10\ncomplex self-intersecting polygon\nPOLYGON ((0.00000 5.00000, 5.00000 5.00000, 5....\nFalse\n\n\n0\nnull geometry\nNone\nTrue"
  },
  {
    "objectID": "tutorial.geometry_validation.html#building-your-own-validator",
    "href": "tutorial.geometry_validation.html#building-your-own-validator",
    "title": "Geometry Validation Tutorial",
    "section": "Building your own validator",
    "text": "Building your own validator\nLet’s build a validator that check if the is point below 0 in the x axis, if that is the case we set it to 0\n\nfrom shapely.geometry.point import Point\nfrom shapely.geometry.polygon import Polygon\n\nfrom geowrangler2.validation import BaseValidator\n\n\nclass PointValidator(BaseValidator):\n    validator_column_name = \"is_not_point\"\n    geometry_types = [\"Point\"]  # What kind of geometies to validate and fix\n\n    def check(self, geometry):\n        # Checks if the geometry is valid. If False, applies the fix\n        return geometry.x &gt; 0\n\n    def fix(self, geometry):\n        return Point(0, geometry.y)\n\n\ngdf = gpd.GeoDataFrame(\n    geometry=[Point(-0.1, 0), Polygon([(-0.1, 0.1), (-0.1, 1), (1, 1)])]\n)\nvalidated_gdf = PointValidator().validate(gdf)\n\nax = gdf.plot()\nax = validated_gdf.plot()\n\n\n\n\n\n\n\nThere are several cases where no fix is available or you want to fix them manualy, we can create a validator that warns the users.\n\nfrom shapely.geometry.point import Point\nfrom shapely.geometry.polygon import Polygon\n\nfrom geowrangler2.validation import BaseValidator\n\n\nclass PointValidator(BaseValidator):\n    validator_column_name = \"is_not_point\"\n    fix_available = False  # Telling the validator that there is no available fixes\n    warning_message = \"Found geometries that are points below 0\"  # warning message\n    geometry_types = [\"Point\"]  # What kind of geometies to validate and fix\n\n    def check(self, geometry):\n        # Checks if the geometry is valid. If False, warn the user\n        return geometry.x &gt; 0\n\n\ngdf = gpd.GeoDataFrame(geometry=[Point(-0.1, 0), Polygon([(0, 0.0), (0, 1), (1, 1)])])\nvalidated_gdf = PointValidator().validate(gdf)\nvalidated_gdf\n\n/home/jt/repos/geowrangler2/geowrangler2/validation.py:107: UserWarning: Found geometries that are points below 0\n  warnings.warn(self.warning_message)\n\n\n\n\n\n\n\n\n\ngeometry\nis_not_point\n\n\n\n\n0\nPOINT (-0.10000 0.00000)\nFalse\n\n\n1\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\nTrue"
  },
  {
    "objectID": "overview.usecase_ookla.html",
    "href": "overview.usecase_ookla.html",
    "title": "Exploring Internet Speeds with Ookla",
    "section": "",
    "text": "A simple use case demo for using geowrangler2 modules to find the Philippine provinces/towns with the slowest/fastest internet speeds."
  },
  {
    "objectID": "overview.usecase_ookla.html#summary",
    "href": "overview.usecase_ookla.html#summary",
    "title": "Exploring Internet Speeds with Ookla",
    "section": "Summary",
    "text": "Summary\nThis Use Case Demo shows how to use the geowrangler2.datasets.ookla and the geowrangler2.area_zonal_stats modules to find the slowest/fastest internet speeds within an area or region of interest.\n\nHow geowrangler2 can make this process easier\ngeowrangler2 can:\n\nValidate your geodataframes\nHelp you download Ookla data (internet speed)\nGenerate zonal stats for your province/town\n\n\n\nWhat you need to do\n\nGet your AOIs (areas of interest) - get the boundaries of your administrative regions\nDownload ookla data\nValidate AOIs and ookla data\nGenerate zonal Stats\nAnalyze and find fastest/slowest internet speeds"
  },
  {
    "objectID": "overview.usecase_ookla.html#tutorial",
    "href": "overview.usecase_ookla.html#tutorial",
    "title": "Exploring Internet Speeds with Ookla",
    "section": "Tutorial",
    "text": "Tutorial\n\nImport libraries\nLets start by importing the required libraries\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport geowrangler2.area_zonal_stats as azs\n\n\n\nDownload Admin Areas\nNext, we get the administrative boundaries geodataset using data from Humanitarian Data Exchange\n\nSet Region Filter\n\n\n\n\n\n\nImportant\n\n\n\nsetting the region filter to None will compute the zonal stats for the whole Philippines and can take a lot longer than for a region\n\n\nSet the REGION_FILTER to your Region (or None for the whole Philippines)\n\n# REGION_FILTER = None  # All regions\nREGION_FILTER = \"National Capital Region\"  # limit to 1 to speed up processing\n\nDownload the geodataset containing the admin areas of your country.\nHere we are using the data for the Philippines.\n\n# no_test\nphl_admin3_file = \"phl_adminboundaries_candidate_adm3\"\nphl_admin3_zip = f\"{phl_admin3_file}.zip\"\n# shapefiles\nphl_admin3_link = f\"https://data.humdata.org/dataset/caf116df-f984-4deb-85ca-41b349d3f313/resource/12457689-6a86-4474-8032-5ca9464d38a8/download/{phl_admin3_zip}\"\n\nDownload the zipped file. Depending on your internet connection, it can take several minutes.\n\n# no_test\n![ ! -e ../data/{phl_admin3_zip} ] && curl -L -o ../data/{phl_admin3_zip} {phl_admin3_link}\n\nCPU times: user 3.9 ms, sys: 12.6 ms, total: 16.5 ms\nWall time: 123 ms\n\n\n\n!mkdir -p ../data/{phl_admin3_file}\n\n\nmain_file = \"phl_admbnda_adm3_psa_namria_20200529\"\nphl_admin3_shp = f\"../data/{phl_admin3_file}/{main_file}.shp\"\n\n\n![ ! -e {phl_admin3_shp} ] && unzip -d ../data/{phl_admin3_file} ../data/{phl_admin3_zip}\n\nCPU times: user 5.08 ms, sys: 3.09 ms, total: 8.17 ms\nWall time: 112 ms\n\n\nLoad the admin area geo dataset.\nIn our example we are loading the .shp or shape file as a geopandas dataframe.\n\nprint(f\"loading {phl_admin3_shp}\")\nadmin3 = gpd.read_file(phl_admin3_shp)\n\nloading ../data/phl_adminboundaries_candidate_adm3/phl_admbnda_adm3_psa_namria_20200529.shp\nCPU times: user 4.4 s, sys: 4.54 s, total: 8.93 s\nWall time: 9.1 s\n\n\n\nadmin3.head()\n\n\n\n\n\n\n\n\nShape_Leng\nShape_Area\nADM3_EN\nADM3_PCODE\nADM3_REF\nADM3ALT1EN\nADM3ALT2EN\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\nADM0_EN\nADM0_PCODE\ndate\nvalidOn\nvalidTo\ngeometry\n\n\n\n\n0\n1.601219\n0.063496\nAborlan\nPH175301000\nNone\nNone\nNone\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nMULTIPOLYGON (((118.58350 9.37700, 118.58398 9...\n\n\n1\n1.078749\n0.050232\nAbra de Ilog\nPH175101000\nNone\nNone\nNone\nOccidental Mindoro\nPH175100000\nRegion IV-B\nPH170000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((120.58412 13.50198, 120.58420 13.501...\n\n\n2\n0.424301\n0.006453\nAbucay\nPH030801000\nNone\nNone\nNone\nBataan\nPH030800000\nRegion III\nPH030000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((120.49873 14.75614, 120.49891 14.755...\n\n\n3\n0.566053\n0.011343\nAbulug\nPH021501000\nNone\nNone\nNone\nCagayan\nPH021500000\nRegion II\nPH020000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((121.43455 18.46651, 121.43502 18.466...\n\n\n4\n1.013649\n0.026124\nAbuyog\nPH083701000\nNone\nNone\nNone\nLeyte\nPH083700000\nRegion VIII\nPH080000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nMULTIPOLYGON (((125.02684 10.73500, 125.02683 ...\n\n\n\n\n\n\n\n\nlist(admin3.columns.values)\n\n['Shape_Leng',\n 'Shape_Area',\n 'ADM3_EN',\n 'ADM3_PCODE',\n 'ADM3_REF',\n 'ADM3ALT1EN',\n 'ADM3ALT2EN',\n 'ADM2_EN',\n 'ADM2_PCODE',\n 'ADM1_EN',\n 'ADM1_PCODE',\n 'ADM0_EN',\n 'ADM0_PCODE',\n 'date',\n 'validOn',\n 'validTo',\n 'geometry']\n\n\n\nadmin3.ADM1_EN.unique()\n\narray(['Region IV-B', 'Region III', 'Region II', 'Region VIII',\n       'Region I', 'Region IV-A', 'Cordillera Administrative Region',\n       'Region VI', 'Autonomous Region in Muslim Mindanao', 'Region XII',\n       'Region VII', 'Region XIII', 'Region IX', 'Region X', 'Region V',\n       'Region XI', 'National Capital Region'], dtype=object)\n\n\nLimit the admin regions to only 1 in order to make the process run faster.\nThe REGION FILTER is set in the Set Region Filter Section\n\nif REGION_FILTER:\n    admin3 = admin3[admin3.ADM1_EN == REGION_FILTER]\n\n\nimport matplotlib.pyplot as plt\n\n\nax = plt.axes()\nax = admin3.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\n\n\nAdmin 3 Levels for NCR\n\n\n\nax = plt.axes()\nax = admin3[admin3.ADM3_EN == \"Pateros\"].plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\nCPU times: user 115 ms, sys: 92.5 ms, total: 207 ms\nWall time: 105 ms\n\n\n\n\n\n\nadmin3.crs\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nadmin3.total_bounds\n\narray([120.90639543,  14.35172957, 121.13503641,  14.78529173])\n\n\n\nlen(admin3)\n\n30\n\n\n\n\n\nDownload Ookla data\nUse the geowrangler2.datasets.ookla module to explore and download ookla (internet speed) data\n\nfrom geowrangler2.datasets import ookla\n\nList the publically available ookla datasets\n\nookla_dsets = ookla.list_ookla_files()\nookla_dsets\n\nCPU times: user 76.1 ms, sys: 14.5 ms, total: 90.5 ms\nWall time: 1.13 s\n\n\n{OoklaQuarter(type='fixed', year='2019', quarter='1'): '2019-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='2'): '2019-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='3'): '2019-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='4'): '2019-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='1'): '2020-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='2'): '2020-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='3'): '2020-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='4'): '2020-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='1'): '2021-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='2'): '2021-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='3'): '2021-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='4'): '2021-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='1'): '2022-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='2'): '2022-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='1'): '2019-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='2'): '2019-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='3'): '2019-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='4'): '2019-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='1'): '2020-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='2'): '2020-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='3'): '2020-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='4'): '2020-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='1'): '2021-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='2'): '2021-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='3'): '2021-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='4'): '2021-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='1'): '2022-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='2'): '2022-04-01_performance_mobile_tiles.parquet'}\n\n\nDownload the latest data (as of the time of writing this)\n\nookla_params = dict(year=\"2022\", quarter=\"2\", directory=\"../data\")\n\n\nookla_fixed = ookla.download_ookla_file(type_=\"fixed\", **ookla_params)\n\nCPU times: user 143 µs, sys: 118 µs, total: 261 µs\nWall time: 182 µs\n\n\n\nookla_fixed\n\nPosixPath('../data/2022-04-01_performance_fixed_tiles.parquet')\n\n\n\n\nConvert ookla data into a GeoDataFrame\nThe downloaded file from ookla is not yet a geodataset, so we will h have to convert it into a GeoDataFrame suitable for use in geowrangler2.\n\nimport pandas as pd\n\nThe downloaded ookla data contains the internet speed data for the whole world and can take a minute or two to load.\nLater, we will show how to filter the data to only include the data relevant to our AOI.\n\nfixed = pd.read_parquet(ookla_fixed)\n\nCPU times: user 7.72 s, sys: 14.2 s, total: 21.9 s\nWall time: 19.2 s\n\n\n\nlen(fixed)\n\n6581735\n\n\n\nfixed.head()\n\n\n\n\n\n\n\n\nquadkey\ntile\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\n\n\n\n\n0\n0000122200000000\nPOLYGON((-168.75 84.1249731939109, -168.744506...\n97075\n42458\n65\n7\n1\n\n\n1\n0022133222312322\nPOLYGON((-160.02685546875 70.6435894914449, -1...\n8324\n3798\n91\n2\n1\n\n\n2\n0022133222330100\nPOLYGON((-160.02685546875 70.6417687358462, -1...\n14972\n4461\n94\n29\n2\n\n\n3\n0022133222330201\nPOLYGON((-160.043334960938 70.6344840663086, -...\n6253\n2818\n91\n1\n1\n\n\n4\n0022202203233313\nPOLYGON((-179.478149414062 68.9169336615194, -...\n700\n126\n1090\n1\n1\n\n\n\n\n\n\n\n\nfixed.dtypes\n\nquadkey       object\ntile          object\navg_d_kbps     int64\navg_u_kbps     int64\navg_lat_ms     int64\ntests          int64\ndevices        int64\ndtype: object\n\n\nThe data is now a Pandas DataFrame but this needs to be converted to a GeoDataFrame by converting the tile column into a geometry with a crs (Coordinate Reference System).\nSee EPSG:4326 for more details about the CRS.\nConverting the data can also take a minute or two.\n\nfixed[\"geometry\"] = gpd.GeoSeries.from_wkt(fixed.tile, crs=\"EPSG:4326\")\n\nCPU times: user 30.1 s, sys: 1.55 s, total: 31.6 s\nWall time: 31.3 s\n\n\n\nfixed.head()\n\n\n\n\n\n\n\n\nquadkey\ntile\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\ngeometry\n\n\n\n\n0\n0000122200000000\nPOLYGON((-168.75 84.1249731939109, -168.744506...\n97075\n42458\n65\n7\n1\nPOLYGON ((-168.75000 84.12497, -168.74451 84.1...\n\n\n1\n0022133222312322\nPOLYGON((-160.02685546875 70.6435894914449, -1...\n8324\n3798\n91\n2\n1\nPOLYGON ((-160.02686 70.64359, -160.02136 70.6...\n\n\n2\n0022133222330100\nPOLYGON((-160.02685546875 70.6417687358462, -1...\n14972\n4461\n94\n29\n2\nPOLYGON ((-160.02686 70.64177, -160.02136 70.6...\n\n\n3\n0022133222330201\nPOLYGON((-160.043334960938 70.6344840663086, -...\n6253\n2818\n91\n1\n1\nPOLYGON ((-160.04333 70.63448, -160.03784 70.6...\n\n\n4\n0022202203233313\nPOLYGON((-179.478149414062 68.9169336615194, -...\n700\n126\n1090\n1\n1\nPOLYGON ((-179.47815 68.91693, -179.47266 68.9...\n\n\n\n\n\n\n\n\nfixed.drop(columns=[\"tile\"], inplace=True)\n\nCPU times: user 515 ms, sys: 95.8 ms, total: 610 ms\nWall time: 606 ms\n\n\n\nfixed = gpd.GeoDataFrame(fixed, geometry=\"geometry\", crs=\"EPSG:4326\")\n\nCPU times: user 71.8 ms, sys: 61.1 ms, total: 133 ms\nWall time: 131 ms\n\n\n\n\nValidate AOI and Data Geometries\nIn order to prevent more headaches as we process and analyze geospatial datasets down the line, it is prudent to check that our datasets have valid geometries.\nWe can use the geowrangler2.validation module to check as well fix these problems.\n\nfrom geowrangler2.validation import GeometryValidation\n\n\nValidate AOI\n\nadmin3_gvm = GeometryValidation(admin3)\n\n\nvalid_admin3 = admin3_gvm.validate_all()\n\nCPU times: user 306 ms, sys: 1.56 ms, total: 308 ms\nWall time: 306 ms\n\n\n\nvalid_admin3.head()\n\n\n\n\n\n\n\n\nShape_Leng\nShape_Area\nADM3_EN\nADM3_PCODE\nADM3_REF\nADM3ALT1EN\nADM3ALT2EN\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\nADM0_EN\nADM0_PCODE\ndate\nvalidOn\nvalidTo\ngeometry\nis_not_null\nis_not_self_intersecting\nis_oriented_properly\nis_within_crs_bounds\narea_is_not_zero\n\n\n\n\n211\n0.037803\n0.000056\nBinondo\nPH133902000\nNone\nNone\nNone\nNCR, City of Manila, First District\nPH133900000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((120.97738 14.60226, 120.97765 14.602...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n308\n0.692758\n0.004468\nCaloocan City\nPH137501000\nNone\nNone\nNone\nNCR, Third District\nPH137500000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nMULTIPOLYGON (((121.01856 14.69176, 121.01846 ...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n395\n0.362306\n0.002745\nCity of Las Piñas\nPH137601000\nCity of Las Pinas\nNone\nNone\nNCR, Fourth District\nPH137600000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nMULTIPOLYGON (((120.98122 14.48720, 120.98077 ...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n398\n0.260317\n0.002094\nCity of Makati\nPH137602000\nNone\nNone\nNone\nNCR, Fourth District\nPH137600000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((121.03468 14.56725, 121.03416 14.567...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n399\n0.262034\n0.001323\nCity of Malabon\nPH137502000\nNone\nNone\nNone\nNCR, Third District\nPH137500000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((120.92733 14.70265, 120.92690 14.702...\nTrue\nTrue\nFalse\nTrue\nTrue\n\n\n\n\n\n\n\n\nvalid_cols = [\n    \"is_oriented_properly\",\n    \"is_not_null\",\n    \"is_not_self_intersecting\",\n    \"is_within_crs_bounds\",\n    \"area_is_not_zero\",\n]\n\n\n[valid_admin3[col].value_counts() for col in valid_cols]\n\n[False    30\n Name: is_oriented_properly, dtype: int64,\n True    30\n Name: is_not_null, dtype: int64,\n True    30\n Name: is_not_self_intersecting, dtype: int64,\n True    30\n Name: is_within_crs_bounds, dtype: int64,\n True    30\n Name: area_is_not_zero, dtype: int64]\n\n\nSo the admin areas have their geometry improperly oriented (i.e. layed out in a counter clockwise direction instead of clockwise direction) and this has been fixed, but passes all the other default validations.\n\nvalid_admin3.drop(\n    columns=valid_cols,\n    inplace=True,\n)\n\n\n\nValidate Data Geometries\nBefore validating, let’s filter the data to only those intersecting our AOI because we don’t need to check all the data from around the world when we’re only interested in our AOI.\nBefore we validate, we need to create the spatial indexes for both the AOI and data geometries. Generating the spatial indexes of the data geometries can take a minute or two due to the size of the data and their geometries.\n\nvalid_admin3.geometry.sindex\n\nCPU times: user 1.12 ms, sys: 541 µs, total: 1.66 ms\nWall time: 1.61 ms\n\n\n&lt;geopandas.sindex.PyGEOSSTRTreeIndex at 0x7f6e434b17f0&gt;\n\n\n\nfixed.geometry.sindex\n\nCPU times: user 6.12 s, sys: 4.01 s, total: 10.1 s\nWall time: 10.1 s\n\n\n&lt;geopandas.sindex.PyGEOSSTRTreeIndex at 0x7f6e434b1880&gt;\n\n\nLets now filter the data (filtered_fixed).\nFiltering the data using a spatial join can also take a minute or two.\n\nfiltered_fixed = fixed.sjoin(\n    valid_admin3[[\"geometry\"]], how=\"inner\", predicate=\"intersects\"\n)\n\nCPU times: user 1.97 s, sys: 688 ms, total: 2.66 s\nWall time: 2.67 s\n\n\n\nfiltered_fixed.drop(columns=[\"index_right\"], inplace=True)\n\n\nfixed_gvm = GeometryValidation(filtered_fixed)\n\n\nvalid_fixed = fixed_gvm.validate_all()\n\nCPU times: user 676 ms, sys: 0 ns, total: 676 ms\nWall time: 673 ms\n\n\n\n[valid_fixed[col].value_counts() for col in valid_cols]\n\nCPU times: user 1.96 ms, sys: 961 µs, total: 2.92 ms\nWall time: 2.28 ms\n\n\n[False    2300\n Name: is_oriented_properly, dtype: int64,\n True    2300\n Name: is_not_null, dtype: int64,\n True    2300\n Name: is_not_self_intersecting, dtype: int64,\n True    2300\n Name: is_within_crs_bounds, dtype: int64,\n True    2300\n Name: area_is_not_zero, dtype: int64]\n\n\nAgain the data geometries have an improperly oriented geometry and have been fixed by the validator\n\nvalid_fixed.drop(columns=valid_cols, inplace=True)\nfiltered_fixed = valid_fixed\n\n\n\n\nfiltered fixed ookla data\n\n\n\n\n\nGenerate Zonal Stats\nLets now generate the zonal stats – the statistics of the data we are interested in.\n\nfiltered_fixed.head()\n\n\n\n\n\n\n\n\nquadkey\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\ngeometry\n\n\n\n\n5646006\n1323030313311323\n43565\n47889\n8\n93\n23\nPOLYGON ((120.92102 14.73770, 120.92102 14.732...\n\n\n5646008\n1323030313311332\n72579\n91717\n11\n149\n36\nPOLYGON ((120.92651 14.73770, 120.92651 14.732...\n\n\n5646009\n1323030313311333\n52572\n67337\n3\n1\n1\nPOLYGON ((120.93201 14.73770, 120.93201 14.732...\n\n\n5646018\n1323030313313110\n63548\n77538\n14\n601\n69\nPOLYGON ((120.92651 14.73239, 120.92651 14.727...\n\n\n5646019\n1323030313313111\n105903\n103874\n13\n115\n22\nPOLYGON ((120.93201 14.73239, 120.93201 14.727...\n\n\n\n\n\n\n\n\nlist(filtered_fixed.columns.values)\n\n['quadkey',\n 'avg_d_kbps',\n 'avg_u_kbps',\n 'avg_lat_ms',\n 'tests',\n 'devices',\n 'geometry']\n\n\n\nlen(filtered_fixed)\n\n2300\n\n\nConvert to planar CRS (since we are computing areas)\n\nvalid_admin3 = valid_admin3.to_crs(\"EPSG:3857\")\n\nCPU times: user 38.6 ms, sys: 0 ns, total: 38.6 ms\nWall time: 37.2 ms\n\n\n\nfiltered_fixed = filtered_fixed.to_crs(\"EPSG:3857\")\n\nCPU times: user 23.3 ms, sys: 1.52 ms, total: 24.8 ms\nWall time: 23.4 ms\n\n\nLets save the files so we can retrieve them as necessary without having to reprocess them again.\n\nvalid_admin3.to_file(\"../data/valid_admin3.geojson\", driver=\"GeoJSON\")\n\nCPU times: user 539 ms, sys: 37.6 ms, total: 577 ms\nWall time: 574 ms\n\n\n\nfiltered_fixed.to_file(\"../data/filtered_fixed.geojson\", driver=\"GeoJSON\")\n\nCPU times: user 583 ms, sys: 38.6 ms, total: 622 ms\nWall time: 620 ms\n\n\n\n# %%time\n# valid_admin3 = gpd.read_file(\"../data/valid_admin3.geojson\")\n\n\n# %%time\n# filtered_fixed = gpd.read_file(\"../data/filtered_fixed.geojson\")\n\nWe want the following statistics - mean (aka average), min (minimum), max (maximum) and the standard deviation (std) for the 3 data columns that ookla provides - average download speed (avg_d_kbps), average upload speed (avg_u_kbps) and average latency in milliseconds (avg_lat_ms)\n\nfuncs = [\"mean\", \"min\", \"max\", \"std\"]\ncolumns = [\"avg_d_kbps\", \"avg_u_kbps\", \"avg_lat_ms\"]\n\n\naggregations = [dict(func=funcs, column=c) for c in columns]\n\nThese are the aggregations to be performed for each data column\n\naggregations\n\n[{'func': ['mean', 'min', 'max', 'std'], 'column': 'avg_d_kbps'},\n {'func': ['mean', 'min', 'max', 'std'], 'column': 'avg_u_kbps'},\n {'func': ['mean', 'min', 'max', 'std'], 'column': 'avg_lat_ms'}]\n\n\nThe output columns use the default {column}_{func} format if not explicitly specified.\n\naoi = azs.create_area_zonal_stats(\n    valid_admin3, filtered_fixed, aggregations=aggregations\n)\n\nCPU times: user 3.74 s, sys: 0 ns, total: 3.74 s\nWall time: 3.73 s\n\n\n\n\nAnalyze Zonal Stats\nThese are the results - the same dataframe as the original, with the addition of zonal statistics we specified as the aggregations.\n\naoi.head()\n\n\n\n\n\n\n\n\nShape_Leng\nShape_Area\nADM3_EN\nADM3_PCODE\nADM3_REF\nADM3ALT1EN\nADM3ALT2EN\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\nADM0_EN\nADM0_PCODE\ndate\nvalidOn\nvalidTo\ngeometry\nintersect_area_sum\navg_d_kbps_mean\navg_d_kbps_min\navg_d_kbps_max\navg_d_kbps_std\navg_u_kbps_mean\navg_u_kbps_min\navg_u_kbps_max\navg_u_kbps_std\navg_lat_ms_mean\navg_lat_ms_min\navg_lat_ms_max\navg_lat_ms_std\n\n\n\n\n211\n0.037803\n0.000056\nBinondo\nPH133902000\nNone\nNone\nNone\nNCR, City of Manila, First District\nPH133900000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((13467140.279 1643403.808, 13467170.0...\n2.330890e+06\n15125.377199\n0.0\n97827\n4141.081774\n12152.916247\n0.0\n80923\n5625.791089\n1.228832\n0.0\n8\n0.923381\n\n\n308\n0.692758\n0.004468\nCaloocan City\nPH137501000\nNone\nNone\nNone\nNCR, Third District\nPH137500000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nMULTIPOLYGON (((13471724.654 1653701.565, 1347...\n7.425998e+07\n309.956521\n0.0\n123236\n15346.775252\n307.716950\n0.0\n117885\n15118.576034\n0.035243\n0.0\n59\n6.147227\n\n\n395\n0.362306\n0.002745\nCity of Las Piñas\nPH137601000\nCity of Las Pinas\nNone\nNone\nNCR, Fourth District\nPH137600000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nMULTIPOLYGON (((13467568.063 1630171.435, 1346...\n4.080667e+07\n649.603501\n0.0\n175810\n22328.120899\n555.324817\n0.0\n136167\n19944.226971\n0.045298\n0.0\n146\n11.110505\n\n\n398\n0.260317\n0.002094\nCity of Makati\nPH137602000\nNone\nNone\nNone\nNCR, Fourth District\nPH137600000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((13473518.917 1639376.906, 13473461.1...\n3.840895e+07\n765.462383\n0.0\n159496\n16771.721664\n663.200995\n0.0\n144939\n17818.361374\n0.091436\n0.0\n25\n5.288884\n\n\n399\n0.262034\n0.001323\nCity of Malabon\nPH137502000\nNone\nNone\nNone\nNCR, Third District\nPH137500000\nNational Capital Region\nPH130000000\nPhilippines (the)\nPH\n2016-06-30\n2020-05-29\nNone\nPOLYGON ((13461569.031 1654955.161, 13461520.7...\n2.583556e+07\n1006.838781\n0.0\n119622\n13444.542392\n933.345049\n0.0\n130002\n14309.585589\n0.096779\n0.0\n17\n2.893162\n\n\n\n\n\n\n\nLets save the results\n\naoi.to_file(\"../data/admin3_internet_aoi.geojson\", driver=\"GeoJSON\")\n\nCPU times: user 415 ms, sys: 12.3 ms, total: 428 ms\nWall time: 424 ms\n\n\n\nlist(aoi.columns.values)\n\n['Shape_Leng',\n 'Shape_Area',\n 'ADM3_EN',\n 'ADM3_PCODE',\n 'ADM3_REF',\n 'ADM3ALT1EN',\n 'ADM3ALT2EN',\n 'ADM2_EN',\n 'ADM2_PCODE',\n 'ADM1_EN',\n 'ADM1_PCODE',\n 'ADM0_EN',\n 'ADM0_PCODE',\n 'date',\n 'validOn',\n 'validTo',\n 'geometry',\n 'intersect_area_sum',\n 'avg_d_kbps_mean',\n 'avg_d_kbps_min',\n 'avg_d_kbps_max',\n 'avg_d_kbps_std',\n 'avg_u_kbps_mean',\n 'avg_u_kbps_min',\n 'avg_u_kbps_max',\n 'avg_u_kbps_std',\n 'avg_lat_ms_mean',\n 'avg_lat_ms_min',\n 'avg_lat_ms_max',\n 'avg_lat_ms_std']\n\n\nLet’s sort the different admin level 3 areas (cities/municipalities/district) by average download speed (avg_d_kbps_mean) in descending order\n\nfastest_mean_download = aoi.sort_values(\"avg_d_kbps_mean\", ascending=False)\n\nCPU times: user 3.72 ms, sys: 0 ns, total: 3.72 ms\nWall time: 3.16 ms\n\n\n\nlen(fastest_mean_download)\n\n30\n\n\nSo according the latest ookla data (as of this writing) the district/town/province within the NCR Region with the fastest average download speed is Binondo!! :)\n\nfastest_mean_download.iloc[0]\n\nShape_Leng                                                     0.037803\nShape_Area                                                     0.000056\nADM3_EN                                                         Binondo\nADM3_PCODE                                                  PH133902000\nADM3_REF                                                           None\nADM3ALT1EN                                                         None\nADM3ALT2EN                                                         None\nADM2_EN                             NCR, City of Manila, First District\nADM2_PCODE                                                  PH133900000\nADM1_EN                                         National Capital Region\nADM1_PCODE                                                  PH130000000\nADM0_EN                                               Philippines (the)\nADM0_PCODE                                                           PH\ndate                                                         2016-06-30\nvalidOn                                                      2020-05-29\nvalidTo                                                            None\ngeometry              POLYGON ((13467140.2793258 1643403.80801774, 1...\nintersect_area_sum                                       2330890.174196\navg_d_kbps_mean                                            15125.377199\navg_d_kbps_min                                                      0.0\navg_d_kbps_max                                                    97827\navg_d_kbps_std                                              4141.081774\navg_u_kbps_mean                                            12152.916247\navg_u_kbps_min                                                      0.0\navg_u_kbps_max                                                    80923\navg_u_kbps_std                                              5625.791089\navg_lat_ms_mean                                                1.228832\navg_lat_ms_min                                                      0.0\navg_lat_ms_max                                                        8\navg_lat_ms_std                                                 0.923381\nName: 211, dtype: object\n\n\nWhile the district/city/municipality within the NCR Regions with the slowest average download speed is Quezon City!!!\n\nfastest_mean_download.iloc[-1]\n\nShape_Leng                                                     0.773902\nShape_Area                                                      0.01363\nADM3_EN                                                     Quezon City\nADM3_PCODE                                                  PH137404000\nADM3_REF                                                           None\nADM3ALT1EN                                                         None\nADM3ALT2EN                                                         None\nADM2_EN                                            NCR, Second District\nADM2_PCODE                                                  PH137400000\nADM1_EN                                         National Capital Region\nADM1_PCODE                                                  PH130000000\nADM0_EN                                               Philippines (the)\nADM0_PCODE                                                           PH\ndate                                                         2016-06-30\nvalidOn                                                      2020-05-29\nvalidTo                                                            None\ngeometry              POLYGON ((13484683.37714301 1663482.482347114,...\nintersect_area_sum                                      174544789.29521\navg_d_kbps_mean                                              145.111131\navg_d_kbps_min                                                      0.0\navg_d_kbps_max                                                   269544\navg_d_kbps_std                                             20232.269854\navg_u_kbps_mean                                              133.033955\navg_u_kbps_min                                                      0.0\navg_u_kbps_max                                                   260425\navg_u_kbps_std                                             20141.871761\navg_lat_ms_mean                                                0.011798\navg_lat_ms_min                                                      0.0\navg_lat_ms_max                                                       29\navg_lat_ms_std                                                  2.90016\nName: 1191, dtype: object\n\n\nThe top 5 fastest areas are\n\nfastest_mean_download[[\"ADM3_EN\", \"ADM2_EN\", \"avg_d_kbps_mean\"]].head()\n\n\n\n\n\n\n\n\nADM3_EN\nADM2_EN\navg_d_kbps_mean\n\n\n\n\n211\nBinondo\nNCR, City of Manila, First District\n15125.377199\n\n\n1343\nSan Nicolas\nNCR, City of Manila, First District\n10897.783018\n\n\n1192\nQuiapo\nNCR, City of Manila, First District\n9799.121085\n\n\n1336\nSan Miguel\nNCR, City of Manila, First District\n8708.791412\n\n\n1112\nPateros\nNCR, Fourth District\n7581.975774\n\n\n\n\n\n\n\nThe top 5 slowest areas are\n\nfastest_mean_download[[\"ADM3_EN\", \"ADM2_EN\", \"avg_d_kbps_mean\"]].tail()\n\n\n\n\n\n\n\n\nADM3_EN\nADM2_EN\navg_d_kbps_mean\n\n\n\n\n1521\nTaguig City\nNCR, Fourth District\n531.559943\n\n\n411\nCity of Parañaque\nNCR, Fourth District\n470.491966\n\n\n436\nCity of Valenzuela\nNCR, Third District\n420.083766\n\n\n308\nCaloocan City\nNCR, Third District\n309.956521\n\n\n1191\nQuezon City\nNCR, Second District\n145.111131\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = fastest_mean_download.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\nax = fastest_mean_download.iloc[:1].plot(ax=ax, facecolor=\"red\", edgecolor=\"red\")\nax = fastest_mean_download.iloc[29:].plot(ax=ax, facecolor=\"green\", edgecolor=\"green\")\nax = fastest_mean_download.plot(ax=ax, column=\"avg_d_kbps_mean\", alpha=0.8)\n\n\n\n\n\n\n\nfastest fixed ookla by adm3\n\n\nSo now, we’ve answered the question of where the fastest/slowest internet speeds are for the National Capital Region (NCR)\n\n\nAdditional Exercises\nYou can further experiment and try out other exercises to explore ookla data, or even try it out using a different country using a different geodataset from the Humanitarian Data Exchange site.\nThe following are more exercises you can try:\n\nRepeat the same process to find the fastest and slowest mobile internet speeds\nRepeat the same process for a different REGION_FILTER\nAggregate by adm2 level instead of adm3"
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html",
    "href": "tutorial.spatialjoin_highest_intersection.html",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "",
    "text": "import geopandas as gpd\n\n#| include: false\n# no_test\nimport geowrangler2.grids as grids\n\n/home/butchtm/work/geomaint/wrkwrangler/.venv/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.3-CAPI-1.16.1) is incompatible with the GEOS version PyGEOS was compiled with (3.10.1-CAPI-1.16.0). Conversions between both will be slow.\n  warnings.warn("
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html#summary",
    "href": "tutorial.spatialjoin_highest_intersection.html#summary",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "Summary",
    "text": "Summary\nJoins attributes of two tables based on largest area of overlap. Usage of this function assumes that the two datasets are both vector polygon data."
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html#how-does-it-work",
    "href": "tutorial.spatialjoin_highest_intersection.html#how-does-it-work",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "How does it work?",
    "text": "How does it work?\nSpatial join using highest intersection works by assigning a unique ID to the first dataframe (gdf1) and using its geometry as basis for the intersection. Data from the second dataframe (gdf2), apart from its geometry, is retained in the output.\n\nget_highest_intersection (gdf1, gdf2, proj_crs)\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/ required\ndetails\n\n\n\n\ngdf1\nGeoDataFrame\nnone\nrequired\nbasis of output geometry\n\n\ngdf2\nGeoDataFrame\nnone\nrequired\ndata to be included during intersection\n\n\nproj_crs\nString\nnone\nrequired\nmetric CRS (e.g., Philippines uses EPSG:32651)\n\n\n\nA technical step-by-step explanation of how get_highest_intersection works is detailed in the cell blocks below. An example on how to use it with its arguments is shown in the sample use case section thereafter.\n\nDefine the function and its arguments.\n\ndef get_highest_intersection(\n    gdf1: gpd.GeoDataFrame,\n    gdf2: gpd.GeoDataFrame,\n    proj_crs: str,\n) -&gt; gpd.GeoDataFrame:\n\nCreate a copy of the two geodataframes.\n\n    gdf1 = gdf1.copy()\n    gdf2 = gdf2.copy()\n\nRename new columns with “__” prefixes and suffixes to prevent overwriting existing columns in the original geodataframes.\n\n    uid_col = \"__uid__\"\n    area_col = \"__area_highest_intersection__\"\n    auxiliary_cols = [uid_col, area_col]\n\nConduct checks to make sure we are not overwriting existing columns.\n\n    for col in auxiliary_cols:\n        if col in gdf1.columns:\n            raise ValueError(f\"Make sure {col} isn't already a column in gdf1\")\n        if col in gdf2.columns:\n            raise ValueError(f\"Make sure {col} isn't already a column in gdf2\")\n\nAssign a unique ID to the first geodataframe. Note that uid_col is also defined in Step 2.\n\n    gdf1[uid_col] = range(len(gdf1))\n\nGet intersection of the geodataframes.\n\n    overlay = gdf1.overlay(gdf2, how=\"intersection\")\n\nAdd a column for overlapping area. Note that area_col is also defined in Step 2.\n\n    overlay[\"geometry\"] = overlay[\"geometry\"].to_crs(proj_crs)\n    overlay[area_col] = (overlay.geometry.area)\n\nSort values by area. Drop duplicates and null values.\n\n    overlay = overlay.sort_values(by=area_col, ascending=True)\n    overlay = overlay.drop_duplicates(subset=[uid_col], keep=\"last\")\n    overlay = overlay.dropna(subset=[uid_col])\n    assert not overlay[uid_col].duplicated().any()\n    overlay = overlay.sort_values(by=[uid_col], ascending=True)\n\nDrop geometry from the overlay dataframe and merge the original geometry from gdf1. Also drop additional columns (uid_col, area_col) used to accomplish calculate overlapping area for the function.\n\n    overlay_merge = overlay.drop(\"geometry\", axis=1)\n\n    output = pd.merge(\n        left=gdf1[[uid_col, \"geometry\"]],\n        right=overlay_merge,\n        on=uid_col,\n        how=\"left\",\n        validate=\"one_to_one\",\n    )\n\n    output = output.drop(columns=auxiliary_cols)\n\nDrop the additional columns (uid_col, area_col) and return the final output.\n\n    return output"
  },
  {
    "objectID": "tutorial.spatialjoin_highest_intersection.html#sample-use-case---labeling-grid-with-administrative-boundaries",
    "href": "tutorial.spatialjoin_highest_intersection.html#sample-use-case---labeling-grid-with-administrative-boundaries",
    "title": "Spatial Join Using Highest Intersection Tutorial",
    "section": "Sample use case - Labeling grid with administrative boundaries",
    "text": "Sample use case - Labeling grid with administrative boundaries\nInput: - grid - GeoDataFrame that will become the basis of geometries for the output - adm_bounds - GeoDataFrame containing attributes that we want to append to the grid - proj_crs - metric coordinate reference system (e.g., “EPSG:32651” for the Philippines)\nOutput - grid with one province name per cell\n\nStep 1: Import package\n\nimport geopandas as gpd\nimport geowrangler2.grids as grids\n\n\nimport geowrangler2.spatialjoin_highest_intersection as spatial_join\n\n\n\nStep 2: Load the first dataset (grid)\nThis dataset will become the basis of geometry for the output.\n\ngrid\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n3\n3\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n\n\n1\n2\n3\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n\n\n2\n3\n4\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n\n\n3\n3\n5\nPOLYGON ((118.27581 6.82146, 118.72497 6.82146...\n\n\n4\n0\n6\nPOLYGON ((116.92834 7.26723, 117.37749 7.26723...\n\n\n...\n...\n...\n...\n\n\n318\n19\n1\nPOLYGON ((125.46233 5.03451, 125.91149 5.03451...\n\n\n319\n19\n12\nPOLYGON ((125.46233 9.93163, 125.91149 9.93163...\n\n\n320\n19\n13\nPOLYGON ((125.46233 10.37375, 125.91149 10.373...\n\n\n321\n20\n12\nPOLYGON ((125.91149 9.93163, 126.36065 9.93163...\n\n\n322\n20\n13\nPOLYGON ((125.91149 10.37375, 126.36065 10.373...\n\n\n\n\n323 rows × 3 columns\n\n\n\n\ngrid.plot(facecolor=\"none\", edgecolor=\"blue\");\n\n\n\n\n\n# grid.explore()\n\n\n\nStep 3: Load the second dataset (admin_bounds)\nInfo from this dataset (apart from geometry) will be appended to the output based on highest spatial intersection.\n\nadmin_bounds\n\n\n\n\n\n\n\n\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\ngeometry\n\n\n\n\n0\nAbra\nNone\nPHL-ADM2-3_0_0-B1\nPHL\nADM2\nMULTIPOLYGON (((120.96795 17.95706, 120.97803 ...\n\n\n1\nAgusan del Norte\nNone\nPHL-ADM2-3_0_0-B2\nPHL\nADM2\nMULTIPOLYGON (((125.57724 9.45679, 125.59687 9...\n\n\n2\nAgusan del Sur\nNone\nPHL-ADM2-3_0_0-B3\nPHL\nADM2\nMULTIPOLYGON (((125.91087 8.85625, 125.91461 8...\n\n\n3\nAklan\nNone\nPHL-ADM2-3_0_0-B4\nPHL\nADM2\nMULTIPOLYGON (((122.43667 11.59833, 122.43667 ...\n\n\n4\nAlbay\nNone\nPHL-ADM2-3_0_0-B5\nPHL\nADM2\nMULTIPOLYGON (((123.28764 13.04923, 123.28686 ...\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n76\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\nMULTIPOLYGON (((119.46694 4.58694, 119.46639 4...\n\n\n77\nZambales\nNone\nPHL-ADM2-3_0_0-B78\nPHL\nADM2\nMULTIPOLYGON (((120.08285 14.75048, 120.08222 ...\n\n\n78\nZamboanga del Norte\nNone\nPHL-ADM2-3_0_0-B79\nPHL\nADM2\nMULTIPOLYGON (((122.09467 7.53152, 122.09467 7...\n\n\n79\nZamboanga del Sur\nNone\nPHL-ADM2-3_0_0-B80\nPHL\nADM2\nMULTIPOLYGON (((122.06223 6.87278, 122.06250 6...\n\n\n80\nZamboanga Sibugay\nNone\nPHL-ADM2-3_0_0-B81\nPHL\nADM2\nMULTIPOLYGON (((122.84063 7.27694, 122.84048 7...\n\n\n\n\n81 rows × 6 columns\n\n\n\n\nadmin_bounds.plot(facecolor=\"none\", edgecolor=\"blue\");\n\n\n\n\n\n# admin_bounds.explore()\n\n\n\nStep 4: Get spatial join with highest intersection\n\noutput = spatial_join.get_highest_intersection(grid, admin_bounds, \"EPSG:32651\")\n\n\nNote that each grid now has admin bounds columns (shapeName, shapeISO, shapeID, … etc.) based on the intersection with the admin boundaries with the highest overlapping area over each grid.\n\n\noutput\n\n\n\n\n\n\n\n\ngeometry\nx\ny\nshapeName\nshapeISO\nshapeID\nshapeGroup\nshapeType\n\n\n\n\n0\nPOLYGON ((118.27581 5.92871, 118.72497 5.92871...\n3\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n1\nPOLYGON ((117.82665 5.92871, 118.27581 5.92871...\n2\n3\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n2\nPOLYGON ((118.27581 6.37528, 118.72497 6.37528...\n3\n4\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n3\nPOLYGON ((118.27581 6.82146, 118.72497 6.82146...\n3\n5\nTawi-Tawi\nNone\nPHL-ADM2-3_0_0-B77\nPHL\nADM2\n\n\n4\nPOLYGON ((116.92834 7.26723, 117.37749 7.26723...\n0\n6\nPalawan\nNone\nPHL-ADM2-3_0_0-B59\nPHL\nADM2\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n318\nPOLYGON ((125.46233 5.03451, 125.91149 5.03451...\n19\n1\nDavao del Sur\nNone\nPHL-ADM2-3_0_0-B28\nPHL\nADM2\n\n\n319\nPOLYGON ((125.46233 9.93163, 125.91149 9.93163...\n19\n12\nDinagat Islands\nNone\nPHL-ADM2-3_0_0-B30\nPHL\nADM2\n\n\n320\nPOLYGON ((125.46233 10.37375, 125.91149 10.373...\n19\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n321\nPOLYGON ((125.91149 9.93163, 126.36065 9.93163...\n20\n12\nSurigao del Norte\nNone\nPHL-ADM2-3_0_0-B74\nPHL\nADM2\n\n\n322\nPOLYGON ((125.91149 10.37375, 126.36065 10.373...\n20\n13\nEastern Samar\nNone\nPHL-ADM2-3_0_0-B31\nPHL\nADM2\n\n\n\n\n323 rows × 8 columns\n\n\n\n\noutput.plot(facecolor=\"none\", edgecolor=\"blue\");\n\n\n\n\n\n# output.explore()"
  },
  {
    "objectID": "raster_zonal_stats.html",
    "href": "raster_zonal_stats.html",
    "title": "Raster Zonal Stats",
    "section": "",
    "text": "generating zonal stats from raster data\n\nNote: This module is a thin layer on top of the rasterstats package to make its interface more compatible with the other geowrangler2 modules (e.g. vector zonal stats)\n\nsource\n\ncreate_raster_zonal_stats\n\n create_raster_zonal_stats\n                            (aoi:Union[str,geopandas.geodataframe.GeoDataF\n                            rame], data:Union[str,pathlib.Path],\n                            aggregation:Dict[str,Any],\n                            extra_args:Dict[str,Any]={'layer': 0,\n                            'band_num': 1, 'nodata': None, 'affine': None,\n                            'all_touched': False})\n\nCompute zonal stats with a vector areas of interest (aoi) from raster data sources. This is a thin layer over the zonal_stats method from the rasterstats python package for compatibility with other geowrangler2 modules. This method currently only supports 1 band for each call, so if you want to create zonal stats for multiple bands with the same raster data, you can call this method for each band (make sure to specify the correct band_num in the extra_args parameter). See https://pythonhosted.org/rasterstats/manual.html#zonal-statistics for more details\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\ntyping.Union[str, geopandas.geodataframe.GeoDataFrame]\n\nThe area of interest geodataframe, or path to the vector file\n\n\ndata\ntyping.Union[str, pathlib.Path]\n\nThe path to the raster data file\n\n\naggregation\ntyping.Dict[str, typing.Any]\n\nA dict specifying the aggregation. See create_zonal_stats from the geowrangler2.vector_zonal_stats module for more details\n\n\nextra_args\ntyping.Dict[str, typing.Any]\n{‘layer’: 0, ‘band_num’: 1, ‘nodata’: None, ‘affine’: None, ‘all_touched’: False}\nExtra arguments passed to rasterstats.zonal_stats method\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport rasterio\n\n\nwith rasterio.open(terrain_file) as src:\n    data = src.read(1)\n    data_crs = src.crs\n    data_bounds = src.bounds\nprint(data.shape, data_crs, data_bounds)\n\n(707, 707) EPSG:3857 BoundingBox(left=-20.0, bottom=-19.994, right=19.994, top=20.0)\n\n\n\nsimple_aoi.total_bounds\n\narray([0., 0., 3., 1.])\n\n\n\nax = plt.imshow(data, cmap=\"pink\")\n\n\n\n\n\nax = simple_aoi.plot(facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\nresults = create_raster_zonal_stats(\n    simple_aoi,\n    terrain_file,\n    aggregation=dict(func=[\"mean\", \"max\", \"min\", \"std\"], column=\"elevation\"),\n    extra_args=dict(nodata=np.nan),\n)\n\nCPU times: user 18.5 ms, sys: 39.4 ms, total: 58 ms\nWall time: 19 ms\n\n\n\nresults\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nelevation_min\nelevation_max\nelevation_mean\nelevation_std\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n1238.734161\n1444.722213\n1339.126726\n64.362218\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1.00000 0.00000, 1.00000 1.00000, 2....\n1222.409102\n1425.920852\n1311.903997\n51.286449\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2.00000 0.00000, 2.00000 1.00000, 3....\n1231.569771\n1402.859628\n1319.624868\n45.298326\n\n\n\n\n\n\n\nCheck that create_raster_zonal_stats uses the nodata attribute set in the tif file if extra_args.nodata is set to None\n\n# Load in admin bounds\nphl_adm = gpd.read_file(\"../data/region3_admin.geojson\")\n\nIf the nodata parameter is explicitly set to -999999, the Population count should be &gt; 0.\n\ngrid_aoi_results = create_raster_zonal_stats(\n    phl_adm,\n    \"../data/phl_ppp_2020_constrained.tif\",\n    aggregation=dict(\n        func=[\"sum\"],\n        column=\"population\",\n        output=[\"population_count\"],\n        fillna=[True],\n    ),\n    extra_args=dict(nodata=-99999),\n)\n\n\ngrid_aoi_results\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\npopulation_count\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n10983338.0\n\n\n\n\n\n\n\nIf the nodata parameter is not set, create_raster_zonal_stats should use the nodata attribute set by the geotiff file so that population count should still be &gt; 0.\n\ngrid_aoi_results = create_raster_zonal_stats(\n    phl_adm,\n    \"../data/phl_ppp_2020_constrained.tif\",\n    aggregation=dict(\n        func=[\"sum\"],\n        column=\"population\",\n        output=[\"population_count\"],\n        fillna=[True],\n    ),\n)\n\n\ngrid_aoi_results\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\npopulation_count\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n10983338.0"
  },
  {
    "objectID": "tutorial.tile_clustering.html",
    "href": "tutorial.tile_clustering.html",
    "title": "Tile Clustering Tutorial",
    "section": "",
    "text": "A basic introduction to using tile clustering"
  },
  {
    "objectID": "tutorial.tile_clustering.html#summary",
    "href": "tutorial.tile_clustering.html#summary",
    "title": "Tile Clustering Tutorial",
    "section": "Summary",
    "text": "Summary\nClusters adjacent grid tiles together. Usage of this function assumes that the input is a grid dataset."
  },
  {
    "objectID": "tutorial.tile_clustering.html#how-does-it-work",
    "href": "tutorial.tile_clustering.html#how-does-it-work",
    "title": "Tile Clustering Tutorial",
    "section": "How does it work?",
    "text": "How does it work?\nTile clustering works by assigning the same ID to grid cells belonging to the same cluster. There are options to: (a) cluster adjacent cells by category, (b) cluster grid cells via adjacent edges or corners.\n\nTileClustering().cluster_tiles(df, category_col)\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/required\ndetails\n\n\n\n\ncluster_type\nString\nfour_way\noptional\nLeave blank () if using four_way cluster_type (top, bottom, left, right sides of a cell). Put in eight_way if preference is to cluster via four sides and corners of a cell.\n\n\ndf\nGeoDataFrame\nnone\nrequired\ndataframe for clustering\n\n\ncategory_col\nString\nnone\noptional\ncolumn for category if need to cluster adjacent cells by category\n\n\n\nA technical step-by-step explanation of how TileClustering().cluster_tiles works is detailed in the cell blocks below. An example on how to use it with its arguments is shown in the sample use case section thereafter.\n\nDefine the class.\n\nclass TileClustering:\n    def __init__(\n        self,\n        cluster_type: str = \"four_way\",\n    ) -&gt; None:\n\n        assert cluster_type in [\"four_way\", \"eight_way\"]\n        self.cluster_type = cluster_type\n        self.tile_cluster_col = \"tile_cluster\"\n\nDefine the function.\n\n@patch\ndef cluster_tiles(\n    self: TileClustering,\n    df: pd.DataFrame,\n    grid_x_col=\"x\",\n    grid_y_col=\"y\",\n    category_col: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Appends the cluster ID for each square grid cell\n    \"\"\"\n\n    if category_col is None:\n        cluster_df = self._cluster_tiles_single(df, grid_x_col, grid_y_col)\n    else:\n        assert (\n            not df[category_col].isnull().any()\n        ), f\"There shouldn't be null values for {category_col}\"\n        unique_categories = df[category_col].unique().tolist()\n\n        cluster_df_list = []\n        for i, category in enumerate(unique_categories, start=1):\n            bool_mask = df[category_col] == category\n            filtered_df = df.loc[bool_mask, :].copy()\n            cluster_filtered_df = self._cluster_tiles_single(\n                filtered_df, grid_x_col, grid_y_col\n            )\n            cluster_filtered_df[self.tile_cluster_col] = cluster_filtered_df[\n                self.tile_cluster_col\n            ].apply(lambda key: f\"{key}-{i}\")\n            cluster_df_list.append(cluster_filtered_df)\n        cluster_df = pd.concat(cluster_df_list, axis=0, ignore_index=True)\n\n    df = pd.merge(left=df, right=cluster_df, on=[grid_x_col, grid_y_col], how=\"left\")\n\n    return df\n\nCategorize commands depending on input of category_col. Append cluster ID for each grid cell.\n\n    # no entry in category_col - run the patched function _cluster_tiles_single\n    if category_col is None:\n        cluster_df = self._cluster_tiles_single(df, grid_x_col, grid_y_col)\n\n    # entry in category_col - make sure that all rows have values\n    else:\n        assert (\n            not df[category_col].isnull().any()\n        ), f\"There shouldn't be null values for {category_col}\"\n        unique_categories = df[category_col].unique().tolist()\n\n    # append cluster ID for each grid cell\n        cluster_df_list = []\n        for i, category in enumerate(unique_categories, start=1):\n            bool_mask = df[category_col] == category\n            filtered_df = df.loc[bool_mask, :].copy()\n            cluster_filtered_df = self._cluster_tiles_single(\n                filtered_df, grid_x_col, grid_y_col\n            )\n            cluster_filtered_df[self.tile_cluster_col] = cluster_filtered_df[\n                self.tile_cluster_col\n            ].apply(lambda key: f\"{key}-{i}\")\n            cluster_df_list.append(cluster_filtered_df)\n        cluster_df = pd.concat(cluster_df_list, axis=0, ignore_index=True)\n\nMerge grid cells with same cluster ID.\n\n    df = pd.merge(left=df, right=cluster_df, on=[grid_x_col, grid_y_col], how=\"left\")\n\nReturn output dataframe.\n\n    return df\n\nOther @patch functions\n\n_cluster_tiles_single - called when there is no entry in category_col\n@patch\ndef _cluster_tiles_single(\n    self: TileClustering,\n    df: pd.DataFrame,\n    grid_x_col=\"x\",\n    grid_y_col=\"y\",\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Performs tile clustering on a single category\n    \"\"\"\n\n    if self.tile_cluster_col in df.columns:\n        raise ValueError(\n            f\"{self.tile_cluster_col} already exists as a column. Please rename\"\n        )\n\n    grid_x = df[grid_x_col]\n    grid_y = df[grid_y_col]\n\n    self.grid_idx = set(zip(grid_x, grid_y))\n\n    self.tile_cluster_dict = {}\n    self.cluster_id = 0\n\n    for key in self.grid_idx:\n        if key not in self.tile_cluster_dict.keys():\n            self.cluster_id += 1\n\n            # reset the call stack per iteration\n            self.call_stack = deque()\n            self._dfs_connected_components(key)\n\n    cluster_df = pd.DataFrame.from_dict(\n        self.tile_cluster_dict, orient=\"index\", columns=[self.tile_cluster_col]\n    )\n    cluster_df = cluster_df.reset_index()\n    cluster_df[grid_x_col] = cluster_df[\"index\"].apply(lambda idx: idx[0])\n    cluster_df[grid_y_col] = cluster_df[\"index\"].apply(lambda idx: idx[1])\n    cluster_df = cluster_df.drop(columns=\"index\")\n\n    return cluster_df\n_get_adjacent_keys - defines how four_way and eight_way clustering works\n@patch\ndef _get_adjacent_keys(\n    self: TileClustering,\n    key: Tuple[int, int],\n) -&gt; List[Tuple[int, int]]:\n\n    x_idx = key[0]\n    y_idx = key[1]\n\n    east_key = (x_idx + 1, y_idx)\n    west_key = (x_idx - 1, y_idx)\n    south_key = (x_idx, y_idx - 1)\n    north_key = (x_idx, y_idx + 1)\n\n    if self.cluster_type == \"four_way\":\n        adjacent_keys = [east_key, west_key, south_key, north_key]\n\n    if self.cluster_type == \"eight_way\":\n        northeast_key = (x_idx + 1, y_idx + 1)\n        northwest_key = (x_idx - 1, y_idx + 1)\n        southeast_key = (x_idx + 1, y_idx - 1)\n        southwest_key = (x_idx - 1, y_idx - 1)\n\n        adjacent_keys = [\n            east_key,\n            west_key,\n            south_key,\n            north_key,\n            northeast_key,\n            northwest_key,\n            southeast_key,\n            southwest_key,\n        ]\n\n    return adjacent_keys\n_dfs_connected_components - a non-recursive depth-first search implementation of connected components\n@patch\ndef _dfs_connected_components(\n    self: TileClustering,\n    key: Tuple[int, int],\n) -&gt; None:\n\n    self.call_stack.append(key)\n    while self.call_stack:\n        ref_key = self.call_stack.pop()\n\n        # check if key exists in the first place\n        if ref_key in self.grid_idx:\n            # check if adjacent key has already been assigned\n            if ref_key not in self.tile_cluster_dict.keys():\n                self.tile_cluster_dict[ref_key] = self.cluster_id\n\n                adjacent_keys = self._get_adjacent_keys(ref_key)\n                for adjacent_key in adjacent_keys:\n                    self.call_stack.append(adjacent_key)"
  },
  {
    "objectID": "tutorial.tile_clustering.html#sample-use-case--clustering-areas-based-on-scores",
    "href": "tutorial.tile_clustering.html#sample-use-case--clustering-areas-based-on-scores",
    "title": "Tile Clustering Tutorial",
    "section": "Sample use case- Clustering areas based on scores",
    "text": "Sample use case- Clustering areas based on scores\nInput: - grid_gdf5k - GeoDataFrame of randomly scored 5km x 5km grid cells - class - category column for basis of of clustering\nOutput: - clustered grid based on class\n\nStep 1: Import packages\n\nimport geopandas as gpd\nimport numpy as np\n\nimport geowrangler2.grids as grids\n\nimport geowrangler2.tile_clustering as tile_clustering\n\n\n\nStep 2: Load GeoDataFrame and generate grid\n\ngrid_generator5k = grids.SquareGridGenerator(5_000)\ngrid_gdf5k = grid_generator5k.generate_grid(region3_gdf)\n\n\n# no_test\ngrid_gdf5k\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.44910, 119.92058 15.449...\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n\n\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.25620 16.313...\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.25620 16.356...\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.25620 16.399...\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.44240, 122.25620 16.442...\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.25620 16.485...\n\n\n\n\n1074 rows × 3 columns\n\n\n\n\n# no_test\ngrid_gdf5k.plot();\n\n\n\n\n\n\nStep 3: Assign scores\n\n# no_test\ngrid_gdf5k\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.154930\nFalse\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.953133\nTrue\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.719994\nTrue\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.44910, 119.92058 15.449...\n0.283082\nFalse\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n0.626144\nFalse\n\n\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.25620 16.313...\n0.862839\nTrue\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.25620 16.356...\n0.659405\nFalse\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.25620 16.399...\n0.863707\nTrue\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.44240, 122.25620 16.442...\n0.246483\nFalse\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.25620 16.485...\n0.785704\nTrue\n\n\n\n\n1074 rows × 5 columns\n\n\n\n\n\nStep 4: Tile clustering\n\n# no_test\noutput = tile_clustering.TileClustering().cluster_tiles(\n    df=grid_gdf5k, category_col=\"class\"\n)\n\n\n# no_test\noutput\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nscore\nclass\ntile_cluster\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n0.154930\nFalse\n1-1\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n0.953133\nTrue\n123-2\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n0.719994\nTrue\n2-2\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.44910, 119.92058 15.449...\n0.283082\nFalse\n1-1\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n0.626144\nFalse\n1-1\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((122.21128 16.31312, 122.25620 16.313...\n0.862839\nTrue\n73-2\n\n\n1070\n54\n45\nPOLYGON ((122.21128 16.35623, 122.25620 16.356...\n0.659405\nFalse\n2-1\n\n\n1071\n54\n46\nPOLYGON ((122.21128 16.39932, 122.25620 16.399...\n0.863707\nTrue\n36-2\n\n\n1072\n54\n47\nPOLYGON ((122.21128 16.44240, 122.25620 16.442...\n0.246483\nFalse\n2-1\n\n\n1073\n54\n48\nPOLYGON ((122.21128 16.48548, 122.25620 16.485...\n0.785704\nTrue\n74-2\n\n\n\n\n1074 rows × 6 columns\n\n\n\n\n# no_test\noutput.plot(column=\"class\", categorical=True, cmap=\"Spectral\");"
  },
  {
    "objectID": "core.html#objectives",
    "href": "core.html#objectives",
    "title": "Sample Core",
    "section": "Objectives",
    "text": "Objectives\n\nMake it easy to maintain code by placing source inside notebooks\n\nview, explore, debug code within the notebook.\ncan optionally display source code in documentation\n\nProvide good API documentation\n\nnice API documentation always kept in sync via auto doc generation\neasily check if doc is in sync or if code still runs\ntutorials can be run as notebooks locally or run in Google Colab in one click\n\nMake it easy to add explanations as to what the code is doing\nAdd pytest-like tests using ipytest package\nSplit class methods into their method sections using fastcore.patch decorator\n\neach class method can be extensively be explained and tested in their section\n\nAdditional explanations can be added in the end"
  },
  {
    "objectID": "core.html#module-api",
    "href": "core.html#module-api",
    "title": "Sample Core",
    "section": "Module API",
    "text": "Module API\n\nsource\n\nfoo\n\n foo (bar:str='baz')\n\nFunction that returns the value of the input argument.\nParameters:\nbar (str): Input string. Defaults to ‘baz’.\nReturns:\nstr: The input string.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbar\nstr\nbaz\ninput string\n\n\nReturns\nstr\n\nreturn same input string or ‘baz’ by default\n\n\n\n\nfoo tests\n\nA simple assert check\n\nUsing assert in a test\n\n\n\n\nCode\ndef test_assert_values():\n    assert  1 == 1\n\n\n\nA more extensive test of foo functions!\n\ntest that default value for no arg call is baz\ntest that using the first positional var returns the same value\ntest that using the kwarg bar returns the kwarg.\n\n\n\n\nCode\ndef test_foo():\n    assert foo() == \"baz\"\n    assert foo(\"bar\") == \"bar\"\n    assert foo(bar=\"foo\") == \"foo\"\n\n\nExample where bar shows source included in doc\n\ndef bar(\n    foo:str='baz' # input string\n) -&gt; str: # return same input string or 'baz' by default\n    \"\"\"\n    Function that returns the value of the input argument.\n\n    Parameters:\n    \n    foo (str): Input string. Defaults to 'baz'.\n\n    Returns:\n    \n    str: The input string.\n    \"\"\"\n    return foo\n\n\nsource\n\n\n\nbar\n\n bar (foo:str='baz')\n\nFunction that returns the value of the input argument.\nParameters:\nfoo (str): Input string. Defaults to ‘baz’.\nReturns:\nstr: The input string.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfoo\nstr\nbaz\ninput string\n\n\nReturns\nstr\n\nreturn same input string or ‘baz’ by default\n\n\n\n\nbar tests\n\nA more extensive test of bar functions!\n\ntest that default value for no arg call is baz\ntest that using the first positional var returns the same value\ntest that using the kwarg foo returns the kwarg.\n\n\n\ndef test_bar():\n    assert bar() == \"baz\"\n    assert bar(\"bar\") == \"bar\"\n    assert bar(foo=\"foo\") == \"foo\"\n\n\nsource\n\n\n\nDummy\n\n Dummy (*args:[], **kwargs:dict)\n\nDummy class example\nDummy class example for documentation purposes. Goal is to showcase how to split class methods into their own sections\nParameters:\nargs(list): list of args\nkwargs(dict): dict of kwargs\n\nsource\n\n\nDummy.dummyfoo\n\n Dummy.dummyfoo (bar:str='baz')\n\nMethod that returns the value of the input argument.\nParameters: bar (str): Input string. Defaults to ‘baz’.\nReturns: str: The input string.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nbar\nstr\nbaz\ninput string\n\n\nReturns\nstr\n\nreturn the input string\n\n\n\n\nDummy.dummyfoo tests\n\n\nCode\n@pytest.fixture\ndef dummy():\n    yield Dummy()\n\n\n\n\nCode\ndef test_dummyfoo(dummy):\n    assert dummy.dummyfoo() == \"baz\"\n    assert dummy.dummyfoo(\"bar\") == \"bar\"\n    assert dummy.dummyfoo(bar=\"foo\") == \"foo\""
  },
  {
    "objectID": "core.html#additional-explanations",
    "href": "core.html#additional-explanations",
    "title": "Sample Core",
    "section": "Additional Explanations",
    "text": "Additional Explanations\nA sample exposition of code including explanatory graphs\n\n# always separate imports from rest of code\nimport geopandas as gpd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n\nregionfile = Path('../data/region34ncr_admin.geojson'); \nregionfile.exists()\n\nTrue\n\n\n\nif regionfile.exists():\n    aoi = gpd.read_file(regionfile)\n    aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],);"
  },
  {
    "objectID": "datasets_ookla.html",
    "href": "datasets_ookla.html",
    "title": "Datasets Ookla",
    "section": "",
    "text": "source\n\nlist_ookla_files\n\n list_ookla_files ()\n\nGet list of ookla data\n\nookla_files = list_ookla_files()\nassert ookla_files.get(OoklaFile(\"fixed\", \"2021\", \"2\"), None) is not None\n\n\nsource\n\n\ndownload_ookla_file\n\n download_ookla_file (type_:str, year:str, quarter:str,\n                      directory:str='data/', overwrite:bool=False,\n                      show_progress=True, chunksize=8192, reporthook=None)\n\nDownload ookla file to path\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ntype_\nstr\n\nInternet connection type: ‘fixed’ or ‘mobile’\n\n\nyear\nstr\n\nYear (e.g. ‘2020’)\n\n\nquarter\nstr\n\nQuarter (valid values: ‘1’,‘2’,‘3’,‘4’)\n\n\ndirectory\nstr\ndata/\nDownload directory\n\n\noverwrite\nbool\nFalse\nOverwrite if existing\n\n\nshow_progress\nbool\nTrue\nshow progres bar\n\n\nchunksize\nint\n8192\nDownload chunksize\n\n\nreporthook\nNoneType\nNone\nUse custom progress bar\n\n\nReturns\ntyping.Optional[pathlib.Path]\n\n\n\n\n\n\nsource\n\n\nparallel_download\n\n parallel_download (item)\n\n\nsource\n\n\ndownload_ookla_parallel\n\n download_ookla_parallel (num_expected_ookla_files, type_, year,\n                          directory, overwrite, show_progress, chunksize,\n                          reporthook)\n\n\nsource\n\n\ndownload_ookla_year_data\n\n download_ookla_year_data (type_, year, cache_dir, use_cache=True,\n                           show_progress=True, chunksize=8192,\n                           reporthook=None)\n\nDownload ookla data for a specifed type (fixed or mobile) and year. Data for all 4 quarters will be downloaded.\n\nsource\n\n\nlookup_ookla_file\n\n lookup_ookla_file (filename)\n\nGet OoklaFile for the given filename\n\nassert lookup_ookla_file(\"2021-04-01_performance_fixed_tiles.parquet\") == OoklaFile(\n    \"fixed\", \"2021\", \"2\"\n)\n\n\nsource\n\n\ncompute_datakey\n\n compute_datakey (aoi_bounds, type_, year, return_geometry)\n\n\nsource\n\n\nwrite_ookla_metajson\n\n write_ookla_metajson (cache_dir, data_key, total_bounds, type_, year,\n                       return_geometry)\n\n\nsource\n\n\nOoklaDataManager\n\n OoklaDataManager (cache_dir='~/.cache/geowrangler2')\n\nAn instance of this class provides convenience functoins for loading and caching Ookla data\n\nsource\n\n\nOoklaDataManager.reinitialize_processed_cache\n\n OoklaDataManager.reinitialize_processed_cache ()\n\nReinitialize processed_cache_dir to start over from scratch.\n\nsource\n\n\nOoklaDataManager.reinitialize_aggregated_cache\n\n OoklaDataManager.reinitialize_aggregated_cache ()\n\nReinitialize aggregated_cache_dir to start over from scratch.\n\nsource\n\n\nOoklaDataManager.load_type_year_data\n\n OoklaDataManager.load_type_year_data\n                                       (aoi:geopandas.geodataframe.GeoData\n                                       Frame, type_:str, year:str,\n                                       use_cache=True,\n                                       return_geometry=False,\n                                       show_progress=True, chunksize=8192,\n                                       reporthook=None)\n\nLoad Ookla data across all quarters for a specified aoi, type (fixed, mobile) and year\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nGeoDataFrame\n\narea of interest\n\n\ntype_\nstr\n\nookla data type: fixed or mobile\n\n\nyear\nstr\n\nyear\n\n\nuse_cache\nbool\nTrue\nuse cache dir\n\n\nreturn_geometry\nbool\nFalse\ninclude geometry in returned values\n\n\nshow_progress\nbool\nTrue\ndisplay progress bar\n\n\nchunksize\nint\n8192\ndownload buffer size\n\n\nreporthook\nNoneType\nNone\ncustom progress bar\n\n\n\n\nsource\n\n\nOoklaDataManager.aggregate_ookla_features\n\n OoklaDataManager.aggregate_ookla_features\n                                            (aoi:geopandas.geodataframe.Ge\n                                            oDataFrame, type_:str,\n                                            year:str, use_cache=True,\n                                            return_geometry=False,\n                                            output_crs='epsg:4326', aggreg\n                                            ations:Dict[str,Any]={'mean_av\n                                            g_d_kbps': ('avg_d_kbps',\n                                            'mean'), 'mean_avg_u_kbps':\n                                            ('avg_u_kbps', 'mean'),\n                                            'mean_avg_lat_ms':\n                                            ('avg_lat_ms', 'mean'),\n                                            'mean_num_tests': ('tests',\n                                            'mean'), 'mean_num_devices':\n                                            ('devices', 'mean')},\n                                            show_progress=True,\n                                            chunksize=8192,\n                                            reporthook=None)\n\nGenerates yearly aggregate features for the AOI based on Ookla data for a given type (fixed, mobile) and year.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nGeoDataFrame\n\nArea of interest\n\n\ntype_\nstr\n\nOokla speed type: ’fixedormobile`\n\n\nyear\nstr\n\nYear to aggregate (over 4 quarters)\n\n\nuse_cache\nbool\nTrue\nUse cached data in cache dir as specified in ookla_data_manager\n\n\nreturn_geometry\nbool\nFalse\nSave aggregated data as geojson\n\n\noutput_crs\nstr\nepsg:4326\ncrs to use in creating aggregated geodataframe\n\n\naggregations\ntyping.Dict[str, typing.Any]\n{‘mean_avg_d_kbps’: (‘avg_d_kbps’, ‘mean’), ‘mean_avg_u_kbps’: (‘avg_u_kbps’, ‘mean’), ‘mean_avg_lat_ms’: (‘avg_lat_ms’, ‘mean’), ‘mean_num_tests’: (‘tests’, ‘mean’), ‘mean_num_devices’: (‘devices’, ‘mean’)}\nAggregation functions on ookla data (see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html)\n\n\nshow_progress\nbool\nTrue\ndisplay progress bar\n\n\nchunksize\nint\n8192\ndownload buffer size\n\n\nreporthook\nNoneType\nNone\ncustom progress bar"
  },
  {
    "objectID": "tutorial.grids.html",
    "href": "tutorial.grids.html",
    "title": "Grid Generation Tutorial",
    "section": "",
    "text": "A basic introduction to Geospatial Grids"
  },
  {
    "objectID": "tutorial.grids.html#basic-usage",
    "href": "tutorial.grids.html#basic-usage",
    "title": "Grid Generation Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nCreating a grid from a geojson file\n\nImport geopandas and the geowrangler2.grids module\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler2 import grids\n\n\n\nLoad a sample geojson file into pandas\nIn our case, we are loading the Region 3 (Central Luzon Administrative Region) of the Philippines.\n\nregion3_gdf = gpd.read_file(\"../data/region3_admin.geojson\")\n\nThis geopandas dataframe has the size:\n\n\nlength of region3_gdf: 1 row(s)\n\n\n\ndisplay(region3_gdf)\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\n\n\n\n\n0\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n\n\n\n\n\n\n\nShow the original plot\n\nimport matplotlib.pyplot as plt\n\nax = region3_gdf.plot(ax=plt.axes())\n\n\n\n\n\nregion3_gdf.crs  # CRS info\n\n&lt;Geographic 2D CRS: EPSG:4326&gt;\nName: WGS 84\nAxis Info [ellipsoidal]:\n- Lat[north]: Geodetic latitude (degree)\n- Lon[east]: Geodetic longitude (degree)\nArea of Use:\n- name: World.\n- bounds: (-180.0, -90.0, 180.0, 90.0)\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\naoi_total_bounds = region3_gdf.total_bounds\naoi_total_bounds\n\narray([119.7858332,  14.4075257, 122.2429921,  16.5092548])"
  },
  {
    "objectID": "tutorial.grids.html#square-grid-generator",
    "href": "tutorial.grids.html#square-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "Square Grid Generator",
    "text": "Square Grid Generator\n\nCreating Grids\nCreate a grid generator with a size of 5,000 m. The units of the grid size are dependent on the projection parameter\nof the grid generator. In this case, the default is EPSG:3857.\n\ngrids.SquareGridGenerator?\n\nInit signature:\ngrids.SquareGridGenerator(\n    cell_size: float,\n    grid_projection: str = 'EPSG:3857',\n    boundary: Union[geowrangler2.grids.SquareGridBoundary, List[float]] = None,\n)\nDocstring:      &lt;no docstring&gt;\nFile:           ~/geowrangler2/geowrangler2/grids.py\nType:           type\nSubclasses:     \n\n\n\ngrid_generator5k = grids.SquareGridGenerator(5_000)  # 5 km x 5 km square cells\n\nGenerate square grids &gt; Notice the time taken to grid the multi polygon at 5K resolution\n\n# slow\ngrid_gdf5k = grid_generator5k.generate_grid(region3_gdf)\n\nCPU times: user 614 ms, sys: 0 ns, total: 614 ms\nWall time: 617 ms\n\n\n\ngrid_gdf5k.plot()\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\nShow gridded version of sample geojson file at 5K resolution\n\n\nlength of grid_gdf5k: 1074 row(s)\n\n\n\n# slow\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = grid_gdf5k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\nIn addition to the grid cells, there are 2 extra columns x and y when combined are unique per grid. It can also tell us which grids are adjacent to each other.\n\n# slow\ngrid_gdf5k.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n7\n8\nPOLYGON ((120.10024 14.75528, 120.14516 14.755...\n\n\n1\n6\n8\nPOLYGON ((120.05533 14.75528, 120.10024 14.755...\n\n\n2\n9\n8\nPOLYGON ((120.19008 14.75528, 120.23499 14.755...\n\n\n3\n2\n24\nPOLYGON ((119.87566 15.44910, 119.92058 15.449...\n\n\n4\n2\n25\nPOLYGON ((119.87566 15.49239, 119.92058 15.492...\n\n\n\n\n\n\n\n\n# slow\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = grid_gdf5k[grid_gdf5k[\"x\"] == 10].plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\nGridding at a coarser resolution\nLet’s try the same process but with a bigger grid (15K)\n\ngrid_generator15k = grids.SquareGridGenerator(15_000)  # 15 km x 15 km grids\n\nGenerate square grids &gt; Notice the time taken to grid the multi polygon at 15K resolution (compared to 5K resolution)\n\ngrid_gdf15k = grid_generator15k.generate_grid(region3_gdf)\n\nCPU times: user 548 ms, sys: 0 ns, total: 548 ms\nWall time: 547 ms\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\ngrid_gdf15k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\nShow gridded version of sample geojson file at 15K resolution\n\n\nlength of grid_gdf15k: 154 row(s)\n\n\n\n\nReusing boundaries\nIf you have 2 polygons that are far from each other but wish to have them follow the reference same reference x and y, you can use pass in custom boudaries.\nLet’s load some grids that are from each other\n\ncell1 = grid_gdf15k.head(1)\ncell2 = grid_gdf15k.tail(1)\n\n\npd.concat([cell1, cell2])\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n2\n2\nPOLYGON ((120.05533 14.66839, 120.19008 14.668...\n\n\n153\n18\n16\nPOLYGON ((122.21128 16.48548, 122.34603 16.485...\n\n\n\n\n\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"red\")\nax = grid_gdf15k.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\nax = pd.concat([cell1, cell2]).plot(ax=ax)\n\n\n\n\n\ngrid_generator1k = grids.SquareGridGenerator(1_000, boundary=aoi_total_bounds)\n\n\ngridcell1 = grid_generator1k.generate_grid(cell1)\n\nCPU times: user 27.1 ms, sys: 0 ns, total: 27.1 ms\nWall time: 27.8 ms\n\n\n\nlen(gridcell1)\n\n272\n\n\n\ngridcell1.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n29\n30\nPOLYGON ((120.04634 14.66839, 120.05533 14.668...\n\n\n1\n29\n31\nPOLYGON ((120.04634 14.67708, 120.05533 14.677...\n\n\n2\n29\n32\nPOLYGON ((120.04634 14.68577, 120.05533 14.685...\n\n\n3\n29\n33\nPOLYGON ((120.04634 14.69446, 120.05533 14.694...\n\n\n4\n29\n34\nPOLYGON ((120.04634 14.70315, 120.05533 14.703...\n\n\n\n\n\n\n\n\nax = gridcell1.plot(facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\ngridcell2 = grid_generator1k.generate_grid(cell2)\n\nCPU times: user 20.2 ms, sys: 0 ns, total: 20.2 ms\nWall time: 18.7 ms\n\n\n\nlen(gridcell2)\n\n20\n\n\n\ngridcell2.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\n\n\n\n\n0\n269\n239\nPOLYGON ((122.20230 16.47686, 122.21128 16.476...\n\n\n1\n269\n240\nPOLYGON ((122.20230 16.48548, 122.21128 16.485...\n\n\n2\n269\n241\nPOLYGON ((122.20230 16.49409, 122.21128 16.494...\n\n\n3\n269\n242\nPOLYGON ((122.20230 16.50270, 122.21128 16.502...\n\n\n4\n270\n239\nPOLYGON ((122.21128 16.47686, 122.22027 16.476...\n\n\n\n\n\n\n\n\nax = gridcell2.plot(facecolor=\"none\", edgecolor=\"red\")\n\n\n\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = gridcell1.plot(ax=ax, color=\"green\")\nax = gridcell2.plot(ax=ax, color=\"red\")"
  },
  {
    "objectID": "tutorial.grids.html#generating-grids-for-multiple-distant-areas",
    "href": "tutorial.grids.html#generating-grids-for-multiple-distant-areas",
    "title": "Grid Generation Tutorial",
    "section": "Generating grids for multiple distant areas",
    "text": "Generating grids for multiple distant areas\nIf you are using AOIs that are vary far from each other, Grid Generator already optmizes the implementation for you\n\nsparse_aois = grid_gdf15k.iloc[\n    0:1000:3,\n]  # Get areas that far from each other\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = sparse_aois.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\nsparse_grid = grid_generator1k.generate_grid(sparse_aois)\n\n\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = sparse_grid.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\nIt is a bit hard to see the grids so, we get a subset to verify.\n\nax = sparse_grid.head(1000).plot(facecolor=\"none\", edgecolor=\"green\")"
  },
  {
    "objectID": "tutorial.grids.html#h3-grid-generator",
    "href": "tutorial.grids.html#h3-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "H3 Grid Generator",
    "text": "H3 Grid Generator\n\nGenerating grids\nLet us generate grids of resolution 5. To learn more about the different resolution, visit: https://h3geo.org/docs/core-library/restable/\n\nh3_generator = grids.H3GridGenerator(resolution=5)\n\n\nh3_5_gdf = h3_generator.generate_grid(region3_gdf)\n\nCPU times: user 2.79 s, sys: 6.39 ms, total: 2.8 s\nWall time: 2.81 s\n\n\n\nax = region3_gdf.plot(aspect=\"equal\")\nax = h3_5_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\", aspect=\"equal\")\n\n\n\n\n\n\nNot exporting geometry\nIf you do not plan to use use geometry, you can pass return_geometry=False to just get a normal pandas DataFrame with the ids.\n\nh3_generator_no_geom = grids.H3GridGenerator(resolution=5, return_geometry=False)\n\n\nh3_region3_no_geom = h3_generator_no_geom.generate_grid(region3_gdf)\n\nCPU times: user 2.75 s, sys: 26.9 ms, total: 2.78 s\nWall time: 2.78 s\n\n\n\nlen(h3_region3_no_geom)\n\n84\n\n\n\nh3_region3_no_geom.head()\n\n\n\n\n\n\n\n\nhex_id\n\n\n\n\n0\n85694103fffffff\n\n\n1\n856941d7fffffff\n\n\n2\n85694e83fffffff\n\n\n3\n85694e93fffffff\n\n\n4\n85694387fffffff"
  },
  {
    "objectID": "tutorial.grids.html#bing-tile-grid-generator",
    "href": "tutorial.grids.html#bing-tile-grid-generator",
    "title": "Grid Generation Tutorial",
    "section": "Bing Tile Grid Generator",
    "text": "Bing Tile Grid Generator\n\nGenerating grids\nLet us generate grids of zoom_level 12. To learn more about the different resolution, visit: https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system\n\nbing_tile_grid_generator = grids.BingTileGridGenerator(12)\n\n\n# slow\nbing_tile_gdf = bing_tile_grid_generator.generate_grid(region3_gdf)\n\nCPU times: user 7.37 s, sys: 0 ns, total: 7.37 s\nWall time: 7.37 s\n\n\n\n# no_test\nax = region3_gdf.plot(facecolor=\"none\", edgecolor=\"blue\")\nax = bing_tile_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\nNot exporting geometry\nIf you do not plan to use use geometry, you can pass return_geometry=False to just get a normal pandas DataFrame with the ids.\n\nbing_tile_grid_generator_no_geom = grids.BingTileGridGenerator(\n    12, return_geometry=False\n)\n\n\n# slow\nbing_region3_keys = bing_tile_grid_generator_no_geom.generate_grid(region3_gdf)\n\nCPU times: user 7.45 s, sys: 7.19 ms, total: 7.45 s\nWall time: 7.45 s\n\n\n\n# no_test\nbing_region3_keys.head()\n\n\n\n\n\n\n\n\nquadkey\n\n\n\n\n0\n132303030330\n\n\n1\n132303030331\n\n\n2\n132303030313\n\n\n3\n132303012302\n\n\n4\n132303012031\n\n\n\n\n\n\n\n\n\nConverting quadkey to x,y,z format\nIf you need to convert the quadkey to x,y format, you can pass add_xyz_cols=True to add the x and y columns to the returned dataframe.\n\nbing_tile_grid_generator_add_xyz = grids.BingTileGridGenerator(12, add_xyz_cols=True)\n\n\n# slow\nbing_region3_keys = bing_tile_grid_generator_add_xyz.generate_grid(region3_gdf)\n\nCPU times: user 8.85 s, sys: 20 ms, total: 8.87 s\nWall time: 8.87 s\n\n\n\n# no_test\nbing_region3_keys.head()\n\n\n\n\n\n\n\n\nquadkey\nx\ny\nz\ngeometry\n\n\n\n\n0\n132303030330\n3414\n1878\n12\nPOLYGON ((120.05859 14.68988, 120.05859 14.774...\n\n\n1\n132303030331\n3415\n1878\n12\nPOLYGON ((120.14648 14.68988, 120.14648 14.774...\n\n\n2\n132303030313\n3415\n1877\n12\nPOLYGON ((120.14648 14.77488, 120.14648 14.859...\n\n\n3\n132303012302\n3412\n1869\n12\nPOLYGON ((119.88281 15.45368, 119.88281 15.538...\n\n\n4\n132303012031\n3411\n1866\n12\nPOLYGON ((119.79492 15.70766, 119.79492 15.792..."
  },
  {
    "objectID": "grids.html",
    "href": "grids.html",
    "title": "Grids",
    "section": "",
    "text": "source\n\nSquareGridBoundary\n\n SquareGridBoundary (x_min:float, y_min:float, x_max:float, y_max:float)\n\nReusing Boundary. x_min, y_min, x_max, and y_max are in the the target crs\n\nsource\n\n\nSquareGridGenerator\n\n SquareGridGenerator (cell_size:float, grid_projection:str='EPSG:3857',\n                      boundary:Union[__main__.SquareGridBoundary,List[floa\n                      t]]=None)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncell_size\nfloat\n\nheight and width of a square cell in meters\n\n\ngrid_projection\nstr\nEPSG:3857\nprojection of grid output\n\n\nboundary\ntyping.Union[main.SquareGridBoundary, typing.List[float]]\nNone\noriginal boundary\n\n\n\n\nsource\n\n\nSquareGridGenerator.create_cell\n\n SquareGridGenerator.create_cell (x:float, y:float)\n\nCreate a square cell based on the top left coordinates and cell_size\n\n\n\n\nType\nDetails\n\n\n\n\nx\nfloat\nx coord of top left\n\n\ny\nfloat\ny coord of top left\n\n\nReturns\nPolygon\n\n\n\n\n\nsource\n\n\nSquareGridGenerator.create_grid_for_polygon\n\n SquareGridGenerator.create_grid_for_polygon (boundary, geometry)\n\n\nsource\n\n\nSquareGridGenerator.generate_grid\n\n SquareGridGenerator.generate_grid\n                                    (gdf:geopandas.geodataframe.GeoDataFra\n                                    me)\n\n\n\nTests for Square Grid Generator\n\ndef test_create_grids(sample_gdf):\n    grid_generator = SquareGridGenerator(cell_size=100)\n    assert grid_generator.create_cell(0, 0) == Polygon(\n        [\n            (0, 0),\n            (100, 0),\n            (100, 100),\n            (0, 100),\n        ]\n    )\n\n\ndef test_generate_grids(sample_gdf):\n    grid_generator = SquareGridGenerator(15000)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert len(grids_gdf) == 240\n    # Check if area of each grid is what we expect\n    assert grids_gdf.to_crs(\"EPSG:3857\").area.apply(np.isclose, b=15000**2).all()\n\n\ndef test_generate_grids_w_custom_boundary(sample_gdf):\n    grid_generator = SquareGridGenerator(15000, boundary=(0, 0, 10, 10))\n    grids_gdf = grid_generator.generate_grid(\n        sample_gdf,\n    )\n\n    assert len(grids_gdf) == 240\n    # Check if area of each grid is what we expect\n    assert grids_gdf.to_crs(\"EPSG:3857\").area.apply(np.isclose, b=15000**2).all()\n\n\ndef test_generate_grids_w_custom_boundary_2(sample_gdf):\n    boundary = SquareGridBoundary(\n        0, 0, 5000000, 5000000\n    )  # SquareGridBoundary used the target projection\n    grid_generator = SquareGridGenerator(15000, boundary=boundary)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert len(grids_gdf) == 240\n    # Check if area of each grid is what we expect\n    assert grids_gdf.to_crs(\"EPSG:3857\").area.apply(np.isclose, b=15000**2).all()\n\n\ndef test_boundary_smaller_then_a_cell():\n    boundary = SquareGridBoundary(0, 0, 5000000, 5000000)\n    _, xrange, _, yrange = boundary.get_range_subset(2.5, 2.5, 5, 5, 10)\n    # 2 because we add a boundary\n    assert len(xrange) == 2\n    assert len(yrange) == 2\n\n\ndef test_generate_grids_aoi_outside_boundary(sample_gdf):\n    grid_generator = SquareGridGenerator(15000, boundary=(10, 10, 20, 20))\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n\n    assert len(grids_gdf) == 0\n\n\nsource\n\n\nH3GridGenerator\n\n H3GridGenerator (resolution:int, return_geometry:bool=True)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nresolution\nint\n\nResolution of hexagon. See: https://h3geo.org/docs/core-library/restable/ for more info\n\n\nreturn_geometry\nbool\nTrue\nIf geometry should be returned. Setting this to false will only return hex_ids\n\n\n\n\nsource\n\n\nH3GridGenerator.get_hexes_for_polygon\n\n H3GridGenerator.get_hexes_for_polygon\n                                        (poly:shapely.geometry.polygon.Pol\n                                        ygon)\n\n\nsource\n\n\nH3GridGenerator.generate_grid\n\n H3GridGenerator.generate_grid (gdf:geopandas.geodataframe.GeoDataFrame)\n\n\nsource\n\n\nBingTileGridGenerator\n\n BingTileGridGenerator (zoom_level:int, return_geometry:bool=True,\n                        add_xyz_cols:bool=False)\n\nInitialize self. See help(type(self)) for accurate signature.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nzoom_level\nint\n\nZoom level of tile. See: https://docs.microsoft.com/en-us/bingmaps/articles/bing-maps-tile-system for more info\n\n\nreturn_geometry\nbool\nTrue\nIf geometry should be returned. Setting this to false will only return quadkeys\n\n\nadd_xyz_cols\nbool\nFalse\nIf quadkey should be converted to their xy values.\n\n\n\n\nsource\n\n\nBingTileGridGenerator.get_all_tiles_for_polygon\n\n BingTileGridGenerator.get_all_tiles_for_polygon\n                                                  (polygon:shapely.geometr\n                                                  y.polygon.Polygon)\n\nGet the interseting tiles with polygon for a zoom level. Polygon should be in EPSG:4326\n\nsource\n\n\nBingTileGridGenerator.generate_grid\n\n BingTileGridGenerator.generate_grid\n                                      (gdf:geopandas.geodataframe.GeoDataF\n                                      rame)\n\n\nsource\n\n\nBingTileGridGenerator.generate_grid_join\n\n BingTileGridGenerator.generate_grid_join\n                                           (gdf:geopandas.geodataframe.Geo\n                                           DataFrame, filter:bool=True,\n                                           n_workers=4, progress=True)\n\n\n\nTests\n\ndef test_h3_grid_generator(sample_gdf):\n    grid_generator = H3GridGenerator(5)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert \"geometry\" in grids_gdf\n    assert isinstance(grids_gdf, gpd.GeoDataFrame)\n    assert len(grids_gdf) == 262\n\n\ndef test_h3_grid_generator_mutliple_polygons(sample_gdf):\n    grid_generator = H3GridGenerator(5)\n    gdf2 = gpd.GeoDataFrame(\n        geometry=[\n            Polygon(\n                [\n                    (3, 3),\n                    (3, 4),\n                    (4, 3),\n                ]\n            )\n        ],\n        crs=\"EPSG:4326\",\n    )\n    grids_gdf = grid_generator.generate_grid(pd.concat([gdf2, sample_gdf]))\n    assert \"geometry\" in grids_gdf\n    assert isinstance(grids_gdf, gpd.GeoDataFrame)\n    assert len(grids_gdf) == 292\n\n\ndef test_h3_grid_generator_return_geometry_false(\n    sample_gdf,\n):\n    grid_generator = H3GridGenerator(5, return_geometry=False)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert \"geometry\" not in grids_gdf\n    assert isinstance(grids_gdf, pd.DataFrame)\n    assert len(grids_gdf) == 262\n\n\ndef test_h3_grid_generator_get_hexes_for_polygon():\n    grid_generator = H3GridGenerator(\n        5,\n    )\n    hex_ids = grid_generator.get_hexes_for_polygon(Polygon([(0, 0.0), (0, 1), (1, 1)]))\n    assert len(hex_ids) == 31\n\n\ndef test_bing_tile_grid_generator(sample_gdf):\n    grid_generator = BingTileGridGenerator(10)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert \"geometry\" in grids_gdf\n    assert isinstance(grids_gdf, gpd.GeoDataFrame)\n    assert len(grids_gdf) == 36\n\n\ndef test_bing_tile_grid_generator_mutliple_polygons(sample_gdf):\n    grid_generator = BingTileGridGenerator(10)\n    gdf2 = gpd.GeoDataFrame(\n        geometry=[\n            Polygon(\n                [\n                    (3, 3),\n                    (3, 4),\n                    (4, 3),\n                ]\n            )\n        ],\n        crs=\"EPSG:4326\",\n    )\n    grids_gdf = grid_generator.generate_grid(pd.concat([gdf2, sample_gdf]))\n    assert \"geometry\" in grids_gdf\n    assert isinstance(grids_gdf, gpd.GeoDataFrame)\n    assert len(grids_gdf) == 46\n\n\ndef test_bing_tile_grid_generator_return_geometry_false(\n    sample_gdf,\n):\n    grid_generator = BingTileGridGenerator(10, return_geometry=False)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert \"geometry\" not in grids_gdf\n    assert isinstance(grids_gdf, pd.DataFrame)\n    assert len(grids_gdf) == 36\n\n\ndef test_bing_tile_grid_generator_add_xyz_true(\n    sample_gdf,\n):\n    grid_generator = BingTileGridGenerator(10, add_xyz_cols=True)\n    grids_gdf = grid_generator.generate_grid(sample_gdf)\n    assert \"x\" in grids_gdf\n    assert \"y\" in grids_gdf\n    assert \"z\" in grids_gdf\n    assert isinstance(grids_gdf, pd.DataFrame)\n    assert len(grids_gdf) == 36\n\n\ndef test_bing_tile_grid_generator_join(sample_gdf):\n    grid_generator = BingTileGridGenerator(10)\n    grids_gdf = grid_generator.generate_grid_join(sample_gdf)\n    assert \"geometry\" in grids_gdf\n    assert isinstance(grids_gdf, gpd.GeoDataFrame)\n    assert len(grids_gdf) == 36\n\n\ndef test_bing_tile_grid_generator_join_mutliple_polygons(sample_gdf):\n    grid_generator = BingTileGridGenerator(10)\n    gdf2 = gpd.GeoDataFrame(\n        geometry=[\n            Polygon(\n                [\n                    (3, 3),\n                    (3, 4),\n                    (4, 3),\n                ]\n            )\n        ],\n        crs=\"EPSG:4326\",\n    )\n    grids_gdf = grid_generator.generate_grid_join(pd.concat([gdf2, sample_gdf]))\n    assert \"geometry\" in grids_gdf\n    assert isinstance(grids_gdf, gpd.GeoDataFrame)\n    assert len(grids_gdf) == 46\n\n\ndef test_bing_tile_grid_generator_join_return_geometry_false(\n    sample_gdf,\n):\n    grid_generator = BingTileGridGenerator(10, return_geometry=False)\n    grids_gdf = grid_generator.generate_grid_join(sample_gdf)\n    assert \"geometry\" not in grids_gdf\n    assert isinstance(grids_gdf, pd.DataFrame)\n    assert len(grids_gdf) == 36"
  },
  {
    "objectID": "tutorial.raster_process.html",
    "href": "tutorial.raster_process.html",
    "title": "Raster Processing Tutorial",
    "section": "",
    "text": "A basic introduction to raster processing"
  },
  {
    "objectID": "tutorial.raster_process.html#summary",
    "href": "tutorial.raster_process.html#summary",
    "title": "Raster Processing Tutorial",
    "section": "Summary",
    "text": "Summary\nCropping rasters based on the borders of a polygon. Usage of this function assumes an input raster and a geodataframe from which to extract bounds. There is also an option to crop multiple geometries at once (e.g., crop raster using bounds of each cell in a grid)."
  },
  {
    "objectID": "tutorial.raster_process.html#how-does-it-work",
    "href": "tutorial.raster_process.html#how-does-it-work",
    "title": "Raster Processing Tutorial",
    "section": "How does it work?",
    "text": "How does it work?\nReturns a subset of a rasterio dataset. This function assumes that the bounding coordinates for the desired cropped rasters are present in the input geodataframe’s geometry column.\n\nquery_window_by_polygon(raster, output_folder, gdf, mask)\nFor cropping a raster based on boundaries of a single polygon. A technical step-by-step explanation of how query_window_by_polygon works is detailed in the cell blocks below.\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/ required\ndetails\n\n\n\n\nraster\nString\nnone\nrequired\nlocal filename of raster or open raster dataset\n\n\noutput_folder\nString\nnone\nrequired\nfile path where cropped raster outputs will be saved\n\n\ngdf\nGeoDataFrame\nnone\nrequired\npolygon that will become basis of boundaries for cropping\n\n\nmask\nBoolean\nnone\nrequired\nTrue- Assign NULL to areas outside borders of a non-rectangular polygon  False- Retain values outside borders of a non-rectangular polygon\n\n\n\n\nDefine the function and its arguments.\n\ndef query_window_by_polygon(\n    input_raster: Union[str, DatasetReader, PosixPath],\n    output_path: str,\n    geometry: Polygon,\n    mask=False,\n) -&gt; None:\n\nCheck if raster is specified as PosixPath and convert to String.\n\n    if isinstance(input_raster, PosixPath):\n        input_raster = str(input_raster)\n\nCheck if raster is path to a file or an open raster dataset.\n\n    if isinstance(input_raster,str):\n         input_dset = rio.open(input_raster)\n    else:\n         input_dset = input_raster\n\nGet the window bounds (left, right, top, bottom coordinates) from polygon geometry and check if it has the correct number of elements.\n\n    window_bounds = geometry.bounds\n    assert (\n        len(window_bounds) == 4\n    ), \n\nUnroll window bounds.\n\n    left, bottom, right, top = window_bounds\n\nOpen raster as input.\n\n    with rio.open(input_raster) as input_dst:\n\nGet profile of input_dst:\n\n        input_profile = input_dst.profile\n\nSpecify window and query subset.\n\n        window = rio.windows.from_bounds(left, bottom, right, top, input_dst.transform)\n        subset = input_dst.read(window=window)\n\nGet the shape of the output subset.\n\n        number_of_bands, height, width = subset.shape\n\nGet the transformation of the subset based on the window.\n\n        win_transform = input_dst.window_transform(window)\n\nUpdate metadata for the output.\n\n        output_profile = input_profile.copy()\n        update_params = {\n            \"count\": number_of_bands,\n            \"height\": height,\n            \"width\": width,\n            \"transform\": win_transform,\n        }\n        output_profile.update(update_params)\n\nWrite image to output file.\n\n        with rio.open(output_path, \"w\", **output_profile) as output_dst:\n            output_dst.write(subset)\n            output_dst.colorinterp = input_dst.colorinterp\n\nApply mask according to shape of the polygon.\n\n    if mask:\n        with rio.open(output_path) as dst:\n            masked_image, masked_transform = rio.mask.mask(dst, [geometry], crop=True)\n        with rio.open(output_path, \"w\", **output_profile) as output_dst:\n            update_params = {\n                \"height\": masked_image.shape[1],\n                \"width\": masked_image.shape[2],\n                \"transform\": masked_transform,\n            }\n            output_profile.update(update_params)\n            output_dst.write(masked_image)\n\nReturn output.\n\n    return \n\n\nquery_window_by_gdf(raster, output_folder, gdf, name_col, mask)\nFor cropping a raster based on boundaries of multiple polygons. A step-by-step explanation of how query_window_by_gdf works is detailed in the cell blocks below.\n\n\n\n\n\n\n\n\n\n\n\ntype\ndefault\noptional/ required\ndetails\n\n\n\n\nraster\nString\nnone\nrequired\nlocal filename of raster or open raster dataset\n\n\noutput_folder\nString\nnone\nrequired\nfile path where cropped raster outputs will be saved\n\n\ngdf\nGeoDataFrame\nnone\nrequired\npolygon that will become basis of boundaries for cropping\n\n\nname_col\nString\nnone\noptional\ncolumn name to base output filepath on. if left blank, outputs will be name sequentially as ‘output_0.tif’\n\n\nmask\nBoolean\nnone\nrequired\nTrue- Assign NULL to areas outside borders of a non-rectangular polygon  False- Retain values outside borders of a non-rectangular polygon\n\n\n\n\nDefine the function and create a copy of the geodataframe.\n\ndef query_window_by_gdf(\n    input_raster: Union[str, DatasetReader, PosixPath],\n    output_folder: str,\n    gdf,\n    name_col=None,\n    mask=False,\n) -&gt; None:\n    gdf = gdf.copy()\n\nCheck if the coordinate reference systems of the raster and geodataframe match.\n\n    with rio.open(input_raster) as dst:\n        assert dst.meta[\"crs\"] == gdf.crs, \"input_raster and gdf CRS must match!\"\n\nName outputs based on values from name_col.\n\n    if name_col is None:\n        name_col = \"name\"\n        gdf[name_col] = \"output_\" + gdf.reset_index().index.astype(str) + \".tif\"\n    else:\n        gdf[name_col] = gdf[name_col] + \".tif\"\n\n    for i, row in gdf.iterrows():\n        polygon = row.geometry\n        output_name = row[name_col]\n        output_path = output_folder / output_name\n        print(output_path)\n        query_window_by_polygon(input_raster, output_path, polygon, mask)"
  },
  {
    "objectID": "tutorial.raster_process.html#sample-use-case-1--crop-raster-with-single-circular-polygon",
    "href": "tutorial.raster_process.html#sample-use-case-1--crop-raster-with-single-circular-polygon",
    "title": "Raster Processing Tutorial",
    "section": "Sample use case 1- Crop raster with single circular polygon",
    "text": "Sample use case 1- Crop raster with single circular polygon\nInput: - input_image - raster of 2020 Philippine population - output_folder - filepath to where output raster will be saved - circle_gdf - GeoDataFrame containining single circular polygon - mask - True- to assign NULL values to cells outside the circular polygon\nOutput: - cropped raster (GeoTiff) containing only values within circular polygon\n\nStep 1: Import packages\n\nimport rasterio as rio\n\nimport geowrangler2.raster_process as raster_process\n\n\n\nStep 2: Load raster\n\ninput_image\n\n'../data/phl_ppp_2020_constrained.tif'\n\n\n\nraster = rio.open(input_image)\n\n\n# no_test\nshow(raster.read(1), cmap=\"plasma\", transform=raster.transform);\n\n\n\n\n\n\nStep 3: Load polygon\n\ncircle_gdf\n\n\n\n\n\n\n\n\nlat\nlon\ngeometry\n\n\n\n\n0\n14.599512\n120.984222\nPOLYGON ((121.98422 14.59951, 121.97941 14.501...\n\n\n\n\n\n\n\n\n\nStep 4: Check if the polygon is within bounds of the raster.\n\n# no_test\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ncircle_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\nax;\n\n\n\n\n\n\nStep 5: State filepath of output folder.\n\noutput_folder = Path(\"../data\")\n\n\n\nStep 6: Crop raster\n\n# no_test\nraster_process.query_window_by_gdf(input_image, output_folder, circle_gdf, mask=True)\n\n../data/output_0.tif\n\n\n\n# no_test\nwith rio.open(output_folder / \"output_0.tif\") as dst:\n    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n\n    show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)\n    circle_gdf.plot(facecolor=\"none\", edgecolor=\"yellow\", ax=ax)\n    print(dst.read(1))\nax;\n\n[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n ...\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]]"
  },
  {
    "objectID": "tutorial.raster_process.html#sample-use-case-2--crop-raster-with-multiple-cells-from-a-grid",
    "href": "tutorial.raster_process.html#sample-use-case-2--crop-raster-with-multiple-cells-from-a-grid",
    "title": "Raster Processing Tutorial",
    "section": "Sample use case 2- Crop raster with multiple cells from a grid",
    "text": "Sample use case 2- Crop raster with multiple cells from a grid\nInput: - input_image - raster of 2020 Philippine population - output_folder - filepath to where output rasters will be saved - grid_gdf - GeoDataFrame containining multiple polygons (grid cells) - mask - False- no need to assign NULL values because grid cells occupy full space from image center to boundaries\nOutput: - multiple cropped rasters (GeoTiff) split according to grid cell polygons\n\nStep 1: Import packages\n\nimport rasterio as rio\n\nimport geowrangler2.raster_process\n\n\n\nStep 2: Load raster\n\ninput_image\n\n'../data/phl_ppp_2020_constrained.tif'\n\n\n\n# no_test\nraster = rio.open(input_image)\nshow(raster.read(1), cmap=\"plasma\", transform=raster.transform)\n\n\n\n\n&lt;AxesSubplot:&gt;\n\n\n\n\nStep 3: Load grid\n\n# no_test\ngrid_gdf\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nname\n\n\n\n\n0\n0\n0\nPOLYGON ((119.98422 13.59951, 120.88254 13.599...\ngridxy-0-0\n\n\n1\n0\n1\nPOLYGON ((119.98422 14.47100, 120.88254 14.471...\ngridxy-0-1\n\n\n2\n0\n2\nPOLYGON ((119.98422 15.33908, 120.88254 15.339...\ngridxy-0-2\n\n\n3\n1\n0\nPOLYGON ((120.88254 13.59951, 121.78085 13.599...\ngridxy-1-0\n\n\n4\n1\n1\nPOLYGON ((120.88254 14.47100, 121.78085 14.471...\ngridxy-1-1\n\n\n5\n1\n2\nPOLYGON ((120.88254 15.33908, 121.78085 15.339...\ngridxy-1-2\n\n\n6\n2\n0\nPOLYGON ((121.78085 13.59951, 122.67917 13.599...\ngridxy-2-0\n\n\n7\n2\n1\nPOLYGON ((121.78085 14.47100, 122.67917 14.471...\ngridxy-2-1\n\n\n\n\n\n\n\n\n\nStep 4: Check if the grid is within bounds of the raster.\n\n# no_test\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ngrid_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\nax\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\n\nStep 5: State filepath of output folder.\n\n# no_test\noutput_folder = Path(\"../data\")\n\n\n\nStep 6: Crop raster\n\n# no_test\nraster_process.query_window_by_gdf(\n    input_image, output_folder, grid_gdf, name_col=\"name\", mask=False\n)\n\n../data/gridxy-0-0.tif\n../data/gridxy-0-1.tif\n../data/gridxy-0-2.tif\n../data/gridxy-1-0.tif\n../data/gridxy-1-1.tif\n../data/gridxy-1-2.tif\n../data/gridxy-2-0.tif\n../data/gridxy-2-1.tif\n\n\n\n# no_test\nfor name in grid_gdf[\"name\"]:\n    image_path = output_folder / (name + \".tif\")\n    with rio.open(image_path) as dst:\n        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n        ax.set_title(image_path)\n        show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)"
  },
  {
    "objectID": "vector_zonal_stats.html",
    "href": "vector_zonal_stats.html",
    "title": "Vector Zonal Stats",
    "section": "",
    "text": "Aggregations\nIn order to generate zonal stats for an area (or areas) of interest (aoi) , we have come up with the concept of an aggregation specification or agg spec, which is a way to specify what aggregation functions (such as count,sum, mean,std etc.) are to be applied to columns in the source dataframe (data).\nThe method create_zonal_stats can then take in a list of these agg specs and apply them to create zonal stats from the data for the aoi.\nEach agg spec consists of a dict with the following keys:\n\nfunc: (Required) a str or a list [str] of aggregation functions. See the pandas documentation for agg\ncolumn: (Optional) an existing column in the data to generate the zonal statistic from. If not specified, the grouping key based on the index of the aoi applied to the data is used as default.\noutput: (Optional) a str or a list [str] of the name(s) of the output zonal statistic column. If not specified it is concatenated from the column and func i.e. {column}_{func} (e.g. 'func':'mean' on 'column':'population' has a default value 'output':'population_mean')\nfillna: (Optional) a bool or a list [bool] of the flag(s) that indicates whether to to a fillna(0) step for the new zonal column, True meaning it will set any NA values in the resulting zonal stat to 0, and False will retain any NA values. The default value of the flag(s) is False.\n\nExamples\n\nThe simplest aggregation spec. This will result in an output column named index_count as it will use the aoi index as the default column.\n\n{\"func\":\"count\"}\n\nThe sum function is applied to the data column population which will create an output column named total_population.\n\n{\n \"func:\"sum\",\n \"column\": \"population\",\n \"output\": \"total_population\"\n}\n\nCompute the zonal stats mean,sum,max on the population column and rename the output columns (by default) to population_mean, population_sum and population_max.\n\n{\n \"func\": [\"mean\",\"sum\",\"max\"],\n \"column\": \"population\",\n}\n\nA full aggregation spec with fillna. fillna == False for std means it will remain an NA if there is no data for the column in the group. The default value for fillna is True which means that 0 is used to replace any NA in the output column.\n\n{\n \"func\": [\"mean\", \"sum\", \"std\"],\n \"column\":\"population\",\n \"output\": [\"avg_pop\", \"total_pop\", \"std_dev\"],\n \"fillna\": [True,True,False],\n}\nThe agg spec in the list of aggregations can contain the same columns, but the output columns must be unique since they will added as columns in the results.\n\n\nRegular and Grid Zonal Stats\n\nVector zonal stats for user defined areas and grids (e.g. Admin areas)\n\n\nsource\n\n\ncreate_zonal_stats\n\n create_zonal_stats (aoi:geopandas.geodataframe.GeoDataFrame,\n                     data:geopandas.geodataframe.GeoDataFrame,\n                     aggregations:List[Dict[str,Any]],\n                     overlap_method:str='intersects')\n\nCreate zonal stats for area of interest from data using aggregration operations on data columns. Returns the same aoi with additional columns containing the computed zonal features.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nGeoDataFrame\n\nArea of interest for which zonal stats are to be computed for\n\n\ndata\nGeoDataFrame\n\nSource gdf containing data to compute zonal stats from\n\n\naggregations\ntyping.List[typing.Dict[str, typing.Any]]\n\nList of agg specs, with each agg spec applied to a data column\n\n\noverlap_method\nstr\nintersects\nspatial predicate to used in spatial join of aoi and data geopandas.sjoin for more details\n\n\nReturns\nGeoDataFrame\n\ncategorical_column_options: str = None,\n\n\n\n\nsimple_aoi  # sample aoi\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1.00000 0.00000, 1.00000 1.00000, 2....\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2.00000 0.00000, 2.00000 1.00000, 3....\n\n\n\n\n\n\n\n\nsimple_data  # sample data\n\n\n\n\n\n\n\n\ncol1\nlat\nlon\ngeometry\n\n\n\n\n0\n1\n0.50\n0.50\nPOINT (0.50000 0.50000)\n\n\n1\n2\n1.50\n0.50\nPOINT (1.50000 0.50000)\n\n\n2\n3\n2.50\n0.50\nPOINT (2.50000 0.50000)\n\n\n3\n4\n0.45\n0.50\nPOINT (0.45000 0.50000)\n\n\n4\n5\n1.45\n0.50\nPOINT (1.45000 0.50000)\n\n\n5\n6\n2.45\n0.50\nPOINT (2.45000 0.50000)\n\n\n6\n7\n0.45\n0.45\nPOINT (0.45000 0.45000)\n\n\n7\n8\n1.45\n0.45\nPOINT (1.45000 0.45000)\n\n\n8\n9\n2.45\n0.45\nPOINT (2.45000 0.45000)\n\n\n9\n10\n0.45\n1.45\nPOINT (0.45000 1.45000)\n\n\n10\n11\n1.45\n1.45\nPOINT (1.45000 1.45000)\n\n\n11\n12\n2.45\n1.45\nPOINT (2.45000 1.45000)\n\n\n\n\n\n\n\n\nax = simple_aoi.plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=[\"red\", \"blue\", \"green\"]\n)\nax = simple_data.plot(ax=ax, color=\"purple\")\n\n\n\n\n\nresults = create_zonal_stats(simple_aoi, simple_data, aggregations=[{\"func\": \"count\"}])\nresults\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nindex_count\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n3\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1.00000 0.00000, 1.00000 1.00000, 2....\n3\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2.00000 0.00000, 2.00000 1.00000, 3....\n3\n\n\n\n\n\n\n\nIndex name is not none\n\nnamed_index_aoi = simple_aoi.copy()\nnamed_index_aoi.index.name = \"myindex\"\n\n\nnamed_index_aoi\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\n\n\nmyindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1.00000 0.00000, 1.00000 1.00000, 2....\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2.00000 0.00000, 2.00000 1.00000, 3....\n\n\n\n\n\n\n\n\nnamed_index_results = create_zonal_stats(\n    named_index_aoi, simple_data, aggregations=[{\"func\": \"count\"}]\n)\n\n\nnamed_index_results.head()\n\n\n\n\n\n\n\n\ncol1\nlat0\nlon0\nlat1\nlon1\nlat2\nlon2\nlat3\nlon3\ngeometry\nindex_count\n\n\nmyindex\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0\n1\n0.0\n0.0\n0.0\n1.0\n1.0\n1.0\n1.0\n0.0\nPOLYGON ((0.00000 0.00000, 0.00000 1.00000, 1....\n3\n\n\n1\n2\n1.0\n0.0\n1.0\n1.0\n2.0\n1.0\n2.0\n0.0\nPOLYGON ((1.00000 0.00000, 1.00000 1.00000, 2....\n3\n\n\n2\n3\n2.0\n0.0\n2.0\n1.0\n3.0\n1.0\n3.0\n0.0\nPOLYGON ((2.00000 0.00000, 2.00000 1.00000, 3....\n3\n\n\n\n\n\n\n\n\n\nBing Map Tile Grid Zonal Stats\n\nGenerating zonal stats for Bing tile grid AOIs\n\n\nsource\n\n\ncompute_quadkey\n\n compute_quadkey (data:geopandas.geodataframe.GeoDataFrame,\n                  zoom_level:int, inplace:bool=False,\n                  quadkey_column:str='quadkey')\n\nComputes the quadkeys for the geometries of the data. If geometries are not points, the quadkeys are computed from the centroids of the geometries.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nGeoDataFrame\n\nThe geodataframe\n\n\nzoom_level\nint\n\nThe quadkey zoom level (1-23)\n\n\ninplace\nbool\nFalse\nWhether to change data inplace or not\n\n\nquadkey_column\nstr\nquadkey\nThe name of the quadkey output column\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\nIf our existing data geodataframe doesn’t have quadkeys, we can use the compute_quadkey to generate the quadkeys for the centroid of the data’s geometries.\n\nDATA_ZOOM_LEVEL = 19\nAOI_ZOOM_LEVEL = 9\nsimple_data_quadkey = compute_quadkey(simple_data, DATA_ZOOM_LEVEL)\n\nCPU times: user 102 ms, sys: 21.4 ms, total: 124 ms\nWall time: 129 ms\n\n\n\nsimple_data_quadkey.head()\n\n\n\n\n\n\n\n\ncol1\nlat\nlon\ngeometry\nquadkey\n\n\n\n\n0\n1\n0.50\n0.5\nPOINT (0.50000 0.50000)\n1222222221211211222\n\n\n1\n2\n1.50\n0.5\nPOINT (1.50000 0.50000)\n1222222320210201222\n\n\n2\n3\n2.50\n0.5\nPOINT (2.50000 0.50000)\n1222222331200311222\n\n\n3\n4\n0.45\n0.5\nPOINT (0.45000 0.50000)\n1222222221210201333\n\n\n4\n5\n1.45\n0.5\nPOINT (1.45000 0.50000)\n1222222320200311333\n\n\n\n\n\n\n\n\nsource\n\n\ncreate_bingtile_zonal_stats\n\n create_bingtile_zonal_stats (aoi:pandas.core.frame.DataFrame,\n                              data:pandas.core.frame.DataFrame,\n                              aggregations:List[Dict[str,Any]],\n                              aoi_quadkey_column:str='quadkey',\n                              data_quadkey_column:str='quadkey')\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\naoi\nDataFrame\n\nAn aoi with quadkey column\n\n\ndata\nDataFrame\n\nData with quadkey column\n\n\naggregations\ntyping.List[typing.Dict[str, typing.Any]]\n\nList of agg specs, with each agg spec applied to a data column\n\n\naoi_quadkey_column\nstr\nquadkey\nColumn name of aoi quadkey\n\n\ndata_quadkey_column\nstr\nquadkey\nColumn name of data quadkey\n\n\nReturns\nDataFrame\n\n\n\n\n\nTo create bingtile zonal stats, we need to compute the quadkeys for the areas of interest (AOI) and the data.\nThe geowrangler2.grids module provides a BingTileGridGenerator that will generate the quadkeys for the areas covered by your AOIs.\n\nimport geowrangler2.grids as gr\n\n\nbgtile_generator = gr.BingTileGridGenerator(AOI_ZOOM_LEVEL)\nsimple_aoi_bingtiles = bgtile_generator.generate_grid(simple_aoi)\n\nUsing the data with the computed quadkeys, we can generate zonal stats for our bingtile grid aois. This just uses the regular pandas grouping and merging function and skips any geospatial joins which results in faster computation.\n\nbingtile_results = create_bingtile_zonal_stats(\n    simple_aoi_bingtiles,\n    simple_data_quadkey,\n    aggregations=[dict(func=\"count\", fillna=True)],\n)\n\nCPU times: user 65.4 ms, sys: 8.03 ms, total: 73.4 ms\nWall time: 71.1 ms\n\n\n\nbingtile_results\n\n\n\n\n\n\n\n\nquadkey\ngeometry\nindex_count\n\n\n\n\n0\n122222220\nPOLYGON ((-0.00000 0.70311, -0.00000 1.40611, ...\n0.0\n\n\n1\n122222221\nPOLYGON ((0.70312 0.70311, 0.70312 1.40611, 1....\n0.0\n\n\n2\n122222230\nPOLYGON ((1.40625 0.70311, 1.40625 1.40611, 2....\n0.0\n\n\n3\n122222231\nPOLYGON ((2.10937 0.70311, 2.10937 1.40611, 2....\n0.0\n\n\n4\n122222320\nPOLYGON ((2.81250 0.70311, 2.81250 1.40611, 3....\n0.0\n\n\n5\n122222222\nPOLYGON ((-0.00000 0.00000, -0.00000 0.70311, ...\n3.0\n\n\n6\n122222223\nPOLYGON ((0.70312 0.00000, 0.70312 0.70311, 1....\n0.0\n\n\n7\n122222232\nPOLYGON ((1.40625 0.00000, 1.40625 0.70311, 2....\n3.0\n\n\n8\n122222233\nPOLYGON ((2.10937 0.00000, 2.10937 0.70311, 2....\n3.0\n\n\n9\n122222322\nPOLYGON ((2.81250 0.00000, 2.81250 0.70311, 3....\n0.0\n\n\n\n\n\n\n\nWe can also use any bingtile grid for any zoom level lower than the data’s zoom level\n\nbgtile_generator10 = gr.BingTileGridGenerator(AOI_ZOOM_LEVEL + 1)\nsimple_aoi_bingtiles10 = bgtile_generator10.generate_grid(simple_aoi)\n\n\nbingtile_results10 = create_bingtile_zonal_stats(\n    simple_aoi_bingtiles10,\n    simple_data_quadkey,\n    aggregations=[dict(func=\"count\", fillna=True)],\n)\n\n\nbingtile_results10[bingtile_results10.index_count &gt; 0]\n\n\n\n\n\n\n\n\nquadkey\ngeometry\nindex_count\n\n\n\n\n10\n1222222221\nPOLYGON ((0.35156 0.35156, 0.35156 0.70311, 0....\n3.0\n\n\n13\n1222222320\nPOLYGON ((1.40625 0.35156, 1.40625 0.70311, 1....\n3.0\n\n\n15\n1222222330\nPOLYGON ((2.10937 0.35156, 2.10937 0.70311, 2....\n2.0\n\n\n16\n1222222331\nPOLYGON ((2.46094 0.35156, 2.46094 0.70311, 2....\n1.0\n\n\n\n\n\n\n\n\nax = results.plot(ax=plt.axes(), column=\"index_count\", edgecolor=\"blue\", alpha=0.2)\nax = simple_data.plot(ax=ax, color=\"purple\")\nax = bingtile_results.plot(ax=ax, column=\"index_count\", edgecolor=\"black\", alpha=0.4)\nax = bingtile_results10.plot(ax=ax, column=\"index_count\", edgecolor=\"red\", alpha=0.4)"
  },
  {
    "objectID": "tutorial.vector_zonal_stats.html",
    "href": "tutorial.vector_zonal_stats.html",
    "title": "Vector Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to Vector Zonal Stats"
  },
  {
    "objectID": "tutorial.vector_zonal_stats.html#basic-usage",
    "href": "tutorial.vector_zonal_stats.html#basic-usage",
    "title": "Vector Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate zonal stats for a GeoDataframe containing areas of interest\nTerms:\n\naoi - (area of interest) a geodataframe which we are interested in generating zonal statistics for\ndata - the source geodataframe containing the features which are interested in collecting zonal stats for our aoi.\n\n\nUse case 1 - Count POIs (Points of Interest)\n\nExample 1: Count POIs for Regions\n\nInput:\n\naoi - region3,4,ncr regions (Admin Level 1) (Central Luzon) geometry (geom_type - polygon, multipolygon\ndata - Philippine pois (geom_type - points)\noverlap_method = ‘intersects’\naggregations:\n\ncount - number of pois within aoi\n\n\nOutput\n\naoi with pois count (default output column: index_count)\n\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport geowrangler2.vector_zonal_stats as vzs\n\n\n# area multipolygons for regions 3,4,ncr of the philippines\naoi = gpd.read_file(\"../data/region34ncr_admin.geojson\")\n\nCPU times: user 3 s, sys: 219 ms, total: 3.22 s\nWall time: 3.21 s\n\n\n\n# no_test\nax = aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],\n)\n\n\n\n\n\n# no_test\naoi\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n\n\n\n\n\n\n\n\n# raw pois from osm data (subset of region3,4, ncr only)\nraw_data = gpd.read_file(\"../data/region34ncr_osm_pois.geojson\")\n\nCPU times: user 94.6 ms, sys: 4.12 ms, total: 98.7 ms\nWall time: 96.1 ms\n\n\n\n# no_test\nraw_data.columns.values\n\narray(['osm_id', 'code', 'fclass', 'name', 'BARANGAY_CODE', 'geometry'],\n      dtype=object)\n\n\n\n# no_test\nraw_data.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n0\n311568428\n2701\ntourist_info\nManila American Cemetery and Memorial Visitor ...\n137602022\nPOINT (121.04852 14.54398)\n\n\n1\n672565496\n2701\ntourist_info\necopark paging and first aid station\n137404141\nPOINT (121.07479 14.71173)\n\n\n2\n672565498\n2701\ntourist_info\nEcopark ticket counter\n137404141\nPOINT (121.07326 14.71291)\n\n\n3\n1585389544\n2701\ntourist_info\nArea Formerly Occupied by Fort Bonifacio Museum\n137602021\nPOINT (121.05837 14.55071)\n\n\n4\n1834855424\n2701\ntourist_info\nLotto Booth\n137601020\nPOINT (120.99216 14.42312)\n\n\n\n\n\n\n\n\n# no_test\nax = aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],\n)\nax = raw_data.plot(ax=ax)\n\n\n\n\nCompute POIs count per region\n\naoi = vzs.create_zonal_stats(\n    aoi,\n    raw_data,\n    overlap_method=\"intersects\",\n    aggregations=[{\"func\": \"count\"}],\n)\n\nCPU times: user 274 ms, sys: 0 ns, total: 274 ms\nWall time: 272 ms\n\n\nNew aoi with pois count in the column index_count. (The column name can be overridden as shown in the next example)\n\n# no_test\naoi\n\nCPU times: user 2 µs, sys: 0 ns, total: 2 µs\nWall time: 4.29 µs\n\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nindex_count\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n880\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n701\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n1253\n\n\n\n\n\n\n\n\n\nExample 2: Count attractions for Regions\n\nInput:\n\naoi - region3,4,ncr regions (Admin Level 1) (Central Luzon, NCR, Calabarzon) geometry (geom_type - polygon, multipolygon)\ndata - attractions: filtered Philippine pois (Central Luzon, NCR, Calabarzon only) (geom_type - points) with fclass == ‘attraction’\noverlap_method = ‘intersects’\naggregations:\n\ncount\n\nnumber of pois within aoi\noutput column name attractions\n\n\n\nOutput\n\naoi with attractions count\n\n\nFilter the raw data\n\n# select only 'attraction' pois\nattractions = raw_data[raw_data.fclass == \"attraction\"]\n\n\n# no_test\nattractions.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n49\n159473554\n2721\nattraction\nChinatown Arch\n133902005\nPOINT (120.97671 14.59672)\n\n\n50\n622413978\n2721\nattraction\nPeace Bell\n137404020\nPOINT (121.04934 14.65026)\n\n\n51\n625180701\n2721\nattraction\nThe Glass Garden\n137403027\nPOINT (121.08194 14.61932)\n\n\n52\n681222977\n2721\nattraction\nLa Madre Filipina\n133908008\nPOINT (120.97773 14.58172)\n\n\n53\n820634039\n2721\nattraction\nIndependence Flag Pole\n133908008\nPOINT (120.97659 14.58155)\n\n\n\n\n\n\n\nCreate zonal stats for filtered data. Add output key to specify output column name for count\n\naoi_attr = vzs.create_zonal_stats(\n    aoi, attractions, aggregations=[{\"func\": \"count\", \"output\": \"attractions\"}]\n)\n\nCPU times: user 290 ms, sys: 0 ns, total: 290 ms\nWall time: 288 ms\n\n\n\n# no_test\naoi_attr\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nattractions\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n136\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n205\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n312\n\n\n\n\n\n\n\n\n\nExample 3: Grid Tiles over POIs\n\nInput:\n\naoi - gridded tiles for Region 3 (Central Luzon) at 15km x 15km size\ndata - region 3 data filtered from philippine pois (geom_type - points)\noverlap_method = ‘intersects’\naggregations:\n\ncount\n\nnumber of pois within aoi\noutput column name:: pois_count\n\n\n\nOutput\n\naoi with pois count\n\n\n\n# load gridded tiles\ngrid_aoi = gpd.read_file(\"../data/region3_admin_grids.geojson\")\n\nCPU times: user 96.3 ms, sys: 0 ns, total: 96.3 ms\nWall time: 87.4 ms\n\n\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"#C62828\"\n)\nax = grid_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\nregion3_pois = gpd.read_file(\"../data/region3_osm_pois.geojson\")\n\nCPU times: user 50.4 ms, sys: 0 ns, total: 50.4 ms\nWall time: 48 ms\n\n\n\n# no_test\nregion3_pois.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n0\n560410986\n2701\ntourist_info\nGawad Kalinga Office\n031420009\nPOINT (121.08516 14.83601)\n\n\n1\n1244301672\n2701\ntourist_info\nN 15deg 26' 11.1\", E 120deg 25' 50.2\", El...\n036918006\nPOINT (120.43045 15.43663)\n\n\n2\n1666684393\n2701\ntourist_info\nEco Park Tourist Information & DENR Environmen...\n036918006\nPOINT (120.44958 15.46446)\n\n\n3\n1679992929\n2701\ntourist_info\nLa Paz Tarlac - Zaragoza Nueva Ecija Boundary\n034932027\nPOINT (120.75832 15.44284)\n\n\n4\n1714645729\n2701\ntourist_info\nLucy Pineda\n035409019\nPOINT (120.61452 15.23359)\n\n\n\n\n\n\n\n\nlen(region3_pois)\n\n701\n\n\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"#C62828\"\n)\nax = region3_pois.plot(ax=ax)\n\n\n\n\nCompute pois count per grid\n\ngrid_aoi = vzs.create_zonal_stats(\n    grid_aoi,\n    region3_pois,\n    overlap_method=\"intersects\",\n    aggregations=[{\"func\": \"count\", \"output\": \"pois_count\"}],\n)\n\nCPU times: user 33.9 ms, sys: 0 ns, total: 33.9 ms\nWall time: 31.5 ms\n\n\n\n# no_test\ngrid_aoi[grid_aoi.pois_count &gt; 0].head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npois_count\n\n\n\n\n11\n2\n28\nPOLYGON ((119.87566 15.62220, 119.92058 15.622...\n1.0\n\n\n14\n2\n31\nPOLYGON ((119.87566 15.75193, 119.92058 15.751...\n1.0\n\n\n18\n3\n23\nPOLYGON ((119.92058 15.40581, 119.96550 15.405...\n1.0\n\n\n21\n3\n26\nPOLYGON ((119.92058 15.53567, 119.96550 15.535...\n4.0\n\n\n22\n3\n27\nPOLYGON ((119.92058 15.57894, 119.96550 15.578...\n1.0\n\n\n\n\n\n\n\n\n# no_test\ngrid_aoi.pois_count.sum()\n\n701.0\n\n\n\n# no_test\n# show grids with at least 1 poi\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n    ],\n)\nax = grid_aoi[grid_aoi.pois_count &gt; 0].plot(ax=ax, facecolor=\"none\", edgecolor=\"green\")\n\n\n\n\n\n\n\nUse case 2 - Stats on a metric column\n\nExample 1 Regions over Population per Bgy Level\n\nInput:\n\naoi - region3,4,ncr geometry (geom_type - polygon, multipolygon)\ndata - region3,4, ncr population data (geom_type - pois)\ndata_type: ‘individual_pois’\noverlap_method = ‘intersects’\naggregations:\n\nmetric_columns: ‘population’,‘men’, etc.\n\neach row in the data has a column: population, men, women, etc. with numeric value\naggregation_functions - ‘min’,‘max’, ‘mean’, ‘sum’, etc.\noutput_columns - ‘pop_min’, ‘pop_max’, for each column\n\n\n\nOutput:\n\naoi with new output columns pop_min, pop_max etc\n\n\nLoad 2020 Region3,4,NCR Population Data at Barangay level (Admin Level 4) :::{.callout-note}\nThe population data came from the 2020 Facebook HRSL Dataset filtered for barangays covering Regions 3,4, NCR and converted the geometries from polygons to points by computing their centroids (projected to EPSG:3969). The land area was computed by projecting to EPSG:3123 and getting the geometry.area .\n:::\n\n# load region3,4,ncr population data at barangay level\nregion34ncr_pop_data = gpd.read_file(\"../data/region34ncr_population_land.geojson\")\n\nCPU times: user 543 ms, sys: 9.45 ms, total: 552 ms\nWall time: 548 ms\n\n\n\n# no_test\nregion34ncr_pop_data.head()\n\n\n\n\n\n\n\n\nBARANGAY_CODE\npopulation\nmen\nwomen\nchildren_under_five\nyouth_15_24\nwomen_of_reproductive_age_15_49\nelderly_60_plus\nland_area\ngeometry\n\n\n\n\n0\n31420020.0\n1807\n920\n887\n202\n359\n468\n77\n2.183518e+05\nPOINT (121.05919 14.85825)\n\n\n1\n34915006.0\n3093\n1594\n1499\n352\n658\n826\n159\n7.327482e+06\nPOINT (120.99590 15.62242)\n\n\n2\n35403009.0\n4241\n2158\n2083\n474\n821\n1112\n256\n8.740450e+05\nPOINT (120.77730 15.14580)\n\n\n3\n35409023.0\n3373\n1750\n1623\n296\n611\n895\n244\n6.484611e+05\nPOINT (120.58052 15.22315)\n\n\n4\n35413009.0\n20884\n10539\n10344\n2198\n3893\n5589\n1260\n2.015571e+06\nPOINT (120.68523 15.09163)\n\n\n\n\n\n\n\n\n# no_test\nregion34ncr_pop_data.columns.values\n\narray(['BARANGAY_CODE', 'population', 'men', 'women',\n       'children_under_five', 'youth_15_24',\n       'women_of_reproductive_age_15_49', 'elderly_60_plus', 'land_area',\n       'geometry'], dtype=object)\n\n\nCompute zonal stats for regions 3,4,NCR * barangay count per region (bgy_count) * sum and mean for each population statistic (population, men, women, etc) * sum, mean, std, min, max for land area statistic\n\naoi = vzs.create_zonal_stats(\n    aoi,\n    region34ncr_pop_data,\n    aggregations=[\n        {\"func\": \"count\", \"output\": \"bgy_count\"},\n        {\n            \"column\": \"population\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"pop_total\", \"pop_avg\"],\n        },\n        {\"column\": \"men\", \"func\": [\"sum\", \"mean\"], \"output\": [\"men_total\", \"men_avg\"]},\n        {\n            \"column\": \"women\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_total\", \"women_avg\"],\n        },\n        {\n            \"column\": \"children_under_five\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"under5_total\", \"under5_avg\"],\n        },\n        {\n            \"column\": \"youth_15_24\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"youth_total\", \"youth_avg\"],\n        },\n        {\n            \"column\": \"women_of_reproductive_age_15_49\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_repro_total\", \"women_repro_avg\"],\n        },\n        {\n            \"column\": \"elderly_60_plus\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"elderly_total\", \"elderly_avg\"],\n        },\n        {\n            \"column\": \"land_area\",\n            \"func\": [\"sum\", \"mean\", \"min\", \"max\", \"std\"],\n            \"output\": [\"land_total\", \"land_avg\", \"land_min\", \"land_max\", \"land_std\"],\n        },\n    ],\n    overlap_method=\"intersects\",\n)\n\nCPU times: user 313 ms, sys: 9.88 ms, total: 322 ms\nWall time: 320 ms\n\n\n\n# no_test\naoi.columns.values\n\narray(['Reg_Code', 'Reg_Name', 'Reg_Alt_Name', 'geometry', 'bgy_count',\n       'pop_total', 'pop_avg', 'men_total', 'men_avg', 'women_total',\n       'women_avg', 'under5_total', 'under5_avg', 'youth_total',\n       'youth_avg', 'women_repro_total', 'women_repro_avg',\n       'elderly_total', 'elderly_avg', 'land_total', 'land_avg',\n       'land_min', 'land_max', 'land_std'], dtype=object)\n\n\n\naoi.head()\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nbgy_count\npop_total\npop_avg\nmen_total\nmen_avg\nwomen_total\n...\nyouth_avg\nwomen_repro_total\nwomen_repro_avg\nelderly_total\nelderly_avg\nland_total\nland_avg\nland_min\nland_max\nland_std\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n1707\n12484535\n7313.728764\n6132828\n3592.752197\n6350844\n...\n1468.077329\n3699839\n2167.451084\n653306\n382.721734\n5.945955e+08\n3.483277e+05\n2890.947906\n2.750653e+07\n1.065422e+06\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n3099\n10581859\n3414.604389\n5353309\n1727.431107\n5227035\n...\n655.773475\n2808810\n906.360116\n664150\n214.311068\n2.120885e+10\n6.843771e+06\n9589.467114\n3.496501e+08\n1.826504e+07\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n4010\n14081857\n3511.685037\n7035334\n1754.447382\n7044548\n...\n671.226185\n3857217\n961.899501\n780294\n194.587032\n1.551525e+10\n3.869139e+06\n3087.452331\n4.310269e+08\n1.119929e+07\n\n\n\n\n3 rows × 24 columns\n\n\n\n\n\nExample 2 : Grids over Population per Bgy Level\n\nInput:\n\naoi - region3 grids geometry (geom_type - polygon)\ndata - population data (geom_type - pois)\ndata_type: ‘individual_pois’\noverlap_method = ‘intersects’\naggregations:\n\nmetric_columns: ‘population’,‘men’, ‘land_area’\n\neach row in the data has a column population, men, women, including land with numeric value\naggregation_functions - ‘min’,‘max’, ‘mean’, ‘sum’, etc.\noutput_columns - ‘pop_min’, ‘pop_max’, for each\n\n\n\nOutput:\n\naoi with new columns pop_min, pop_max etc.\n\n\nLoad population and land POIs (Bgy level) :::{.callout-note}\nThe dataset is similar to the previous one (Region3,4,NCR) except that it has been filtered only data for the Region 3.\n:::\n\nregion3_pop_pois = gpd.read_file(\"../data/region3_population_pois.geojson\")\n\nCPU times: user 372 ms, sys: 0 ns, total: 372 ms\nWall time: 370 ms\n\n\n\n# no_test\nregion3_pop_pois.head()\n\n\n\n\n\n\n\n\nBARANGAY_CODE\npopulation\nmen\nwomen\nchildren_under_five\nyouth_15_24\nwomen_of_reproductive_age_15_49\nelderly_60_plus\nland_area\nReg_Name\ngeometry\n\n\n\n\n0\n31420020.0\n1807\n920\n887\n202\n359\n468\n77\n2.183518e+05\nRegion III\nPOINT (121.05919 14.85825)\n\n\n1\n34915006.0\n3093\n1594\n1499\n352\n658\n826\n159\n7.327482e+06\nRegion III\nPOINT (120.99590 15.62242)\n\n\n2\n35403009.0\n4241\n2158\n2083\n474\n821\n1112\n256\n8.740450e+05\nRegion III\nPOINT (120.77730 15.14580)\n\n\n3\n35409023.0\n3373\n1750\n1623\n296\n611\n895\n244\n6.484611e+05\nRegion III\nPOINT (120.58052 15.22315)\n\n\n4\n35413009.0\n20884\n10539\n10344\n2198\n3893\n5589\n1260\n2.015571e+06\nRegion III\nPOINT (120.68523 15.09163)\n\n\n\n\n\n\n\n\n# no_test\nregion3_pop_pois.columns.values\n\narray(['BARANGAY_CODE', 'population', 'men', 'women',\n       'children_under_five', 'youth_15_24',\n       'women_of_reproductive_age_15_49', 'elderly_60_plus', 'land_area',\n       'Reg_Name', 'geometry'], dtype=object)\n\n\nCreate zonal stats (same as previous example, but now for a more granular level for region 3 only)\n\ngrid_aoi = vzs.create_zonal_stats(\n    grid_aoi,\n    region3_pop_pois,\n    aggregations=[\n        {\"func\": \"count\", \"output\": \"bgy_count\"},\n        {\n            \"column\": \"population\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"pop_total\", \"pop_avg\"],\n        },\n        {\"column\": \"men\", \"func\": [\"sum\", \"mean\"], \"output\": [\"men_total\", \"men_avg\"]},\n        {\n            \"column\": \"women\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_total\", \"women_avg\"],\n        },\n        {\n            \"column\": \"children_under_five\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"under5_total\", \"under5_avg\"],\n        },\n        {\n            \"column\": \"youth_15_24\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"youth_total\", \"youth_avg\"],\n        },\n        {\n            \"column\": \"women_of_reproductive_age_15_49\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_repro_total\", \"women_repro_avg\"],\n        },\n        {\n            \"column\": \"elderly_60_plus\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"elderly_total\", \"elderly_avg\"],\n        },\n        {\n            \"column\": \"land_area\",\n            \"func\": [\"sum\", \"mean\", \"min\", \"max\", \"std\"],\n            \"output\": [\"land_total\", \"land_avg\", \"land_min\", \"land_max\", \"land_std\"],\n        },\n    ],\n    overlap_method=\"intersects\",\n)\n\nCPU times: user 115 ms, sys: 10.5 ms, total: 126 ms\nWall time: 121 ms\n\n\n\n# no_test\ngrid_aoi.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npois_count\nbgy_count\npop_total\npop_avg\nmen_total\nmen_avg\nwomen_total\n...\nyouth_avg\nwomen_repro_total\nwomen_repro_avg\nelderly_total\nelderly_avg\nland_total\nland_avg\nland_min\nland_max\nland_std\n\n\n\n\n0\n0\n30\nPOLYGON ((119.78583 15.70870, 119.83075 15.708...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n1\n0\n31\nPOLYGON ((119.78583 15.75193, 119.83075 15.751...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n0\n32\nPOLYGON ((119.78583 15.79516, 119.83075 15.795...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n3\n1\n30\nPOLYGON ((119.83075 15.70870, 119.87566 15.708...\nNaN\n1.0\n3415.0\n3415.0\n1744.0\n1744.0\n1670.0\n...\n648.0\n848.0\n848.0\n229.0\n229.0\n5.552401e+06\n5.552401e+06\n5.552401e+06\n5.552401e+06\nNaN\n\n\n4\n1\n32\nPOLYGON ((119.83075 15.79516, 119.87566 15.795...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n...\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n5 rows × 24 columns\n\n\n\nShow grids with bgy_count &gt; 0 and bgy_count == 0\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = grid_aoi[grid_aoi.bgy_count.notna()].plot(\n    ax=ax, facecolor=\"none\", edgecolor=\"blue\"\n)\nax = grid_aoi[grid_aoi.bgy_count.isna()].plot(ax=ax, facecolor=\"none\", edgecolor=\"red\")"
  },
  {
    "objectID": "tutorial.vector_zonal_stats.html#generating-bing-tile-grid-zonal-stats",
    "href": "tutorial.vector_zonal_stats.html#generating-bing-tile-grid-zonal-stats",
    "title": "Vector Zonal Stats Tutorial",
    "section": "Generating Bing Tile Grid Zonal Stats",
    "text": "Generating Bing Tile Grid Zonal Stats\nIf our areas of interest use Bing Tile Grids (with the associated quadkeys),\nwe can use a much faster way of generating zonal stats by pre-computing the quadkeys for our data.\n\n\n\n\n\n\nNote\n\n\n\nyou can use the geowrangler2.grids modules BingTileGridGenerator to convert your AOI into a Bing Tile Grid AOI.\n\n\n\nExample 1: Count POIs for Region 3 Bing Tile Grid AOI\n\nInput:\n\naoi bing tile grids zoom level 13 - region3 (Admin Level 1) (Central Luzon) geometry (geom_type - polygon, multipolygon)\ndata - Region 3 pois (geom_type - points)\naggregations:\n\ncount - number of pois within aoi\n\n\nOutput\n\naoi with pois count (default output column: index_count)\n\n\nLoad our bing tile grid aoi\n\n# load region3_admin area in bing tile grid ('ADM level 1 - Philippines, region 3, zoom level13')\n\nregion3_bingtile_grid = gpd.read_file(\"../data/region3_bingtile_grid13.geojson\")\n\n\n# no_test\nregion3_bingtile_grid.head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\n\n\n\n\n0\n1323030303301\nPOLYGON ((120.10254 14.73239, 120.10254 14.774...\n\n\n1\n1323030303300\nPOLYGON ((120.05859 14.73239, 120.05859 14.774...\n\n\n2\n1323030303311\nPOLYGON ((120.19043 14.73239, 120.19043 14.774...\n\n\n3\n1323030303133\nPOLYGON ((120.19043 14.77488, 120.19043 14.817...\n\n\n4\n1323030303131\nPOLYGON ((120.19043 14.81737, 120.19043 14.859...\n\n\n\n\n\n\n\n\n# no_test\nax = plt.axes()\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\nax = region3_bingtile_grid.plot(ax=ax, facecolor=\"none\", edgecolor=\"red\")\n\n\n\n\nLets compute the quadkeys for our Region3 pois\n\nDATA_ZOOM_LEVEL = 23  # for pois, it can be as high as 24\n\n\nregion3_pois_quadkeys = vzs.compute_quadkey(region3_pois, DATA_ZOOM_LEVEL)\n\nCPU times: user 236 ms, sys: 320 µs, total: 236 ms\nWall time: 233 ms\n\n\n\nregion3_pois_quadkeys.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\nquadkey\n\n\n\n\n0\n560410986\n2701\ntourist_info\nGawad Kalinga Office\n031420009\nPOINT (121.08516 14.83601)\n13230312020312101332220\n\n\n1\n1244301672\n2701\ntourist_info\nN 15deg 26' 11.1\", E 120deg 25' 50.2\", El...\n036918006\nPOINT (120.43045 15.43663)\n13230301323000331033200\n\n\n2\n1666684393\n2701\ntourist_info\nEco Park Tourist Information & DENR Environmen...\n036918006\nPOINT (120.44958 15.46446)\n13230301321223132232132\n\n\n3\n1679992929\n2701\ntourist_info\nLa Paz Tarlac - Zaragoza Nueva Ecija Boundary\n034932027\nPOINT (120.75832 15.44284)\n13230301332111310110220\n\n\n4\n1714645729\n2701\ntourist_info\nLucy Pineda\n035409019\nPOINT (120.61452 15.23359)\n13230303110021032011230\n\n\n\n\n\n\n\nLets compute the zonal stats for each grid as the pois_count. &gt; Notice the computation time is pretty fast\n\nregion3_bingtile_pois = vzs.create_bingtile_zonal_stats(\n    region3_bingtile_grid,\n    region3_pois_quadkeys,\n    aggregations=[dict(func=\"count\", output=\"pois_count\", fillna=True)],\n)\n\nCPU times: user 71.6 ms, sys: 0 ns, total: 71.6 ms\nWall time: 69.3 ms\n\n\n\n# no_test\nregion3_bingtile_pois[region3_bingtile_pois.pois_count &gt; 0].head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\npois_count\n\n\n\n\n5\n1323030312020\nPOLYGON ((120.23438 14.81737, 120.23438 14.859...\n8.0\n\n\n8\n1323030121200\nPOLYGON ((119.88281 15.74996, 119.88281 15.792...\n1.0\n\n\n11\n1323030121222\nPOLYGON ((119.88281 15.62304, 119.88281 15.665...\n1.0\n\n\n13\n1323030123002\nPOLYGON ((119.88281 15.53838, 119.88281 15.580...\n1.0\n\n\n22\n1323030123001\nPOLYGON ((119.92676 15.58071, 119.92676 15.623...\n1.0\n\n\n\n\n\n\n\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = region3_bingtile_pois[region3_bingtile_pois.pois_count &gt; 0].plot(\n    column=\"pois_count\", ax=ax, edgecolor=\"blue\", alpha=0.4\n)\nax = region3_bingtile_pois[region3_bingtile_pois.pois_count == 0].plot(\n    ax=ax, facecolor=\"none\", edgecolor=\"red\", alpha=0.4\n)\n\n\n\n\n\n\nExample 2: Population stats for Region 3 Bing Tile Grid AOI\n\nInput:\n\naoi bing tile grids zoom level 13 - region3 (Admin Level 1) (Central Luzon) geometry (geom_type - polygon, multipolygon)\ndata - Region 3 pop data (geom_type - points)\naggregations:\n\npop totals, avg, men total and avg, etc , barangay counts, etc.\n\n\nOutput\n\naoi bing tile grids zoom level 13 with additional stats\n\n\nWe can also reuse the region34ncr population data to add more zonal statistics to our region3 bingtile pois\n\n# Add quadkeys to region34ncr population data\nregion34ncr_pop_data = vzs.compute_quadkey(\n    region34ncr_pop_data, DATA_ZOOM_LEVEL, inplace=True\n)  # inplace saves copying\n\nCPU times: user 1.5 s, sys: 0 ns, total: 1.5 s\nWall time: 1.5 s\n\n\n\n# no_test\nregion34ncr_pop_data.head()\n\n\n\n\n\n\n\n\nBARANGAY_CODE\npopulation\nmen\nwomen\nchildren_under_five\nyouth_15_24\nwomen_of_reproductive_age_15_49\nelderly_60_plus\nland_area\ngeometry\nquadkey\n\n\n\n\n0\n31420020.0\n1807\n920\n887\n202\n359\n468\n77\n2.183518e+05\nPOINT (121.05919 14.85825)\n13230312020301100210231\n\n\n1\n34915006.0\n3093\n1594\n1499\n352\n658\n826\n159\n7.327482e+06\nPOINT (120.99590 15.62242)\n13230310220010101012220\n\n\n2\n35403009.0\n4241\n2158\n2083\n474\n821\n1112\n256\n8.740450e+05\nPOINT (120.77730 15.14580)\n13230303111220301103213\n\n\n3\n35409023.0\n3373\n1750\n1623\n296\n611\n895\n244\n6.484611e+05\nPOINT (120.58052 15.22315)\n13230303101131332000021\n\n\n4\n35413009.0\n20884\n10539\n10344\n2198\n3893\n5589\n1260\n2.015571e+06\nPOINT (120.68523 15.09163)\n13230303112102100203003\n\n\n\n\n\n\n\n\nregion3_bingtile_pois_pop_data = vzs.create_bingtile_zonal_stats(\n    region3_bingtile_pois,  # reuse from previous example\n    region34ncr_pop_data,  # updated with quadkeys\n    aggregations=[\n        {\"func\": \"count\", \"output\": \"bgy_count\"},\n        {\n            \"column\": \"population\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"pop_total\", \"pop_avg\"],\n        },\n        {\"column\": \"men\", \"func\": [\"sum\", \"mean\"], \"output\": [\"men_total\", \"men_avg\"]},\n        {\n            \"column\": \"women\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_total\", \"women_avg\"],\n        },\n        {\n            \"column\": \"children_under_five\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"under5_total\", \"under5_avg\"],\n        },\n        {\n            \"column\": \"youth_15_24\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"youth_total\", \"youth_avg\"],\n        },\n        {\n            \"column\": \"women_of_reproductive_age_15_49\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"women_repro_total\", \"women_repro_avg\"],\n        },\n        {\n            \"column\": \"elderly_60_plus\",\n            \"func\": [\"sum\", \"mean\"],\n            \"output\": [\"elderly_total\", \"elderly_avg\"],\n        },\n        {\n            \"column\": \"land_area\",\n            \"func\": [\"sum\", \"mean\", \"min\", \"max\", \"std\"],\n            \"output\": [\"land_total\", \"land_avg\", \"land_min\", \"land_max\", \"land_std\"],\n        },\n    ],\n)\n\nCPU times: user 528 ms, sys: 0 ns, total: 528 ms\nWall time: 526 ms\n\n\n\n# no_test\nregion3_bingtile_pois_pop_data[region3_bingtile_pois_pop_data.bgy_count.notna()].head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\npois_count\nbgy_count\npop_total\npop_avg\nmen_total\nmen_avg\nwomen_total\nwomen_avg\n...\nyouth_avg\nwomen_repro_total\nwomen_repro_avg\nelderly_total\nelderly_avg\nland_total\nland_avg\nland_min\nland_max\nland_std\n\n\n\n\n5\n1323030312020\nPOLYGON ((120.23438 14.81737, 120.23438 14.859...\n8.0\n5.0\n40890.0\n8178.000000\n20398.0\n4079.600000\n20490.0\n4098.000000\n...\n1662.000000\n11493.0\n2298.600000\n2337.0\n467.4\n4.156777e+06\n8.313554e+05\n1.319242e+05\n2.503691e+06\n9.727404e+05\n\n\n6\n1323030120313\nPOLYGON ((119.83887 15.70766, 119.83887 15.749...\n0.0\n1.0\n3415.0\n3415.000000\n1744.0\n1744.000000\n1670.0\n1670.000000\n...\n648.000000\n848.0\n848.000000\n229.0\n229.0\n5.552401e+06\n5.552401e+06\n5.552401e+06\n5.552401e+06\nNaN\n\n\n7\n1323030121022\nPOLYGON ((119.88281 15.79225, 119.88281 15.834...\n0.0\n1.0\n4742.0\n4742.000000\n2438.0\n2438.000000\n2304.0\n2304.000000\n...\n828.000000\n1114.0\n1114.000000\n370.0\n370.0\n5.485826e+06\n5.485826e+06\n5.485826e+06\n5.485826e+06\nNaN\n\n\n8\n1323030121200\nPOLYGON ((119.88281 15.74996, 119.88281 15.792...\n1.0\n7.0\n21755.0\n3107.857143\n11047.0\n1578.142857\n10707.0\n1529.571429\n...\n587.857143\n5364.0\n766.285714\n1631.0\n233.0\n1.343751e+07\n1.919645e+06\n5.222719e+05\n4.416378e+06\n1.395113e+06\n\n\n9\n1323030121202\nPOLYGON ((119.88281 15.70766, 119.88281 15.749...\n0.0\n5.0\n10146.0\n2029.200000\n5257.0\n1051.400000\n4887.0\n977.400000\n...\n376.600000\n2393.0\n478.600000\n668.0\n133.6\n1.836666e+07\n3.673332e+06\n2.364678e+06\n5.247429e+06\n1.068957e+06\n\n\n\n\n5 rows × 23 columns\n\n\n\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = region3_bingtile_pois_pop_data[\n    region3_bingtile_pois_pop_data.bgy_count.notna()\n].plot(column=\"pop_total\", ax=ax, edgecolor=\"blue\", alpha=0.4)\nax = region3_bingtile_pois_pop_data[\n    region3_bingtile_pois_pop_data.bgy_count.isna()\n].plot(ax=ax, facecolor=\"none\", edgecolor=\"red\", alpha=0.4)"
  },
  {
    "objectID": "tutorial.dhs.html",
    "href": "tutorial.dhs.html",
    "title": "DHS Wealth Index",
    "section": "",
    "text": "Note: This data is mocked data\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler2 import dhs\n\n\ndhs_household_data_path = \"../data/ph.DTA\"\ndhs_gps_coordinates = \"../data/ph_gps.shp\"\n\n\ndhs_df = dhs.load_dhs_file(dhs_household_data_path)\n\nCPU times: user 23.6 ms, sys: 3.92 ms, total: 27.5 ms\nWall time: 26.8 ms\n\n\n\ndhs_df.head()\n\n\n\n\n\n\n\n\n\ncountry code and phase\ncluster number\nsource of drinking water\ntype of toilet facility\nhas electricity\nhas radio\nhas television\nhas refrigerator\nhas motorcycle/scooter\nhas car/truck\nmain floor material\nnumber of rooms used for sleeping\nhas mobile telephone\nwealth index factor score combined (5 decimals)\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758"
  },
  {
    "objectID": "tutorial.dhs.html#loading-dhs-data",
    "href": "tutorial.dhs.html#loading-dhs-data",
    "title": "DHS Wealth Index",
    "section": "",
    "text": "Note: This data is mocked data\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler2 import dhs\n\n\ndhs_household_data_path = \"../data/ph.DTA\"\ndhs_gps_coordinates = \"../data/ph_gps.shp\"\n\n\ndhs_df = dhs.load_dhs_file(dhs_household_data_path)\n\nCPU times: user 23.6 ms, sys: 3.92 ms, total: 27.5 ms\nWall time: 26.8 ms\n\n\n\ndhs_df.head()\n\n\n\n\n\n\n\n\n\ncountry code and phase\ncluster number\nsource of drinking water\ntype of toilet facility\nhas electricity\nhas radio\nhas television\nhas refrigerator\nhas motorcycle/scooter\nhas car/truck\nmain floor material\nnumber of rooms used for sleeping\nhas mobile telephone\nwealth index factor score combined (5 decimals)\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758"
  },
  {
    "objectID": "tutorial.dhs.html#renaming-columns-to-match",
    "href": "tutorial.dhs.html#renaming-columns-to-match",
    "title": "DHS Wealth Index",
    "section": "Renaming columns to match",
    "text": "Renaming columns to match\nDHS files do not have uniform column names. To make analysis easier, we rename commonnly ones. Feel free to extend the config to your usecase.\n\nph_config = dhs.load_column_config(\"ph\")\nph_config\n\n{'cluster number': 'DHSCLUST',\n 'wealth index factor score combined (5 decimals)': 'Wealth Index',\n 'country code and phase': 'country code and phase',\n 'number of rooms used for sleeping': 'rooms',\n 'has electricity': 'electric',\n 'has mobile telephone': 'mobile telephone',\n 'has radio': 'radio',\n 'has television': 'television',\n 'has car/truck': 'car/truck',\n 'has refrigerator': 'refrigerator',\n 'has motorcycle/scooter': 'motorcycle',\n 'main floor material': 'floor',\n 'type of toilet facility': 'toilet',\n 'source of drinking water': 'drinking water'}\n\n\n\nrenamed_dhs_df = dhs_df.rename(columns=ph_config)\n\n\nrenamed_dhs_df.head()\n\n\n\n\n\n\n\n\n\ncountry code and phase\nDHSCLUST\ndrinking water\ntoilet\nelectric\nradio\ntelevision\nrefrigerator\nmotorcycle\ncar/truck\nfloor\nrooms\nmobile telephone\nWealth Index\n\n\n\n\n0\n0\nPH7\n725\n80\n61\n0\n1\n0\n1\n1\n1\n74\n20\n0\n-168581\n\n\n1\n1\nPH7\n1009\n19\n92\n1\n1\n1\n1\n1\n0\n51\n15\n1\n127550\n\n\n2\n2\nPH7\n1072\n91\n58\n1\n1\n0\n1\n1\n1\n26\n5\n0\n32616\n\n\n3\n3\nPH7\n242\n39\n93\n0\n1\n0\n0\n0\n1\n76\n11\n0\n80338\n\n\n4\n4\nPH7\n102\n11\n27\n0\n0\n1\n1\n1\n0\n56\n15\n0\n-178758"
  },
  {
    "objectID": "tutorial.dhs.html#cluster-summaries",
    "href": "tutorial.dhs.html#cluster-summaries",
    "title": "DHS Wealth Index",
    "section": "Cluster Summaries",
    "text": "Cluster Summaries\n\nwealth_col_name = \"Wealth Index\"\ncluster_col_name = \"DHSCLUST\"\n\n\nsummarized = (\n    renamed_dhs_df[[wealth_col_name, cluster_col_name]].groupby(cluster_col_name).mean()\n)\nsummarized.reset_index(inplace=True)\n\n\nsummarized.head()\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\n\n\n\n\n0\n3\n-232188.0\n\n\n1\n4\n228860.0\n\n\n2\n5\n157620.0\n\n\n3\n6\n40308.5\n\n\n4\n7\n-37595.5\n\n\n\n\n\n\n\n\nlen(summarized)\n\n679\n\n\n\nsummarized.DHSCLUST.isna().sum()\n\n0\n\n\n\nsummarized.DHSCLUST.isna().sum()\n\n0\n\n\n\ndhs_shp = gpd.read_file(dhs_gps_coordinates)\n\n\ndhs_shp.head()\n\n\n\n\n\n\n\n\nDHSID\nDHSCC\nDHSYEAR\nDHSCLUST\nLATNUM\nLONGNUM\ngeometry\n\n\n\n\n0\nPH20XX725\nPH\n0\n725\n0.409441\n0.220510\nPOINT (0.22051 0.40944)\n\n\n1\nPH20XX1009\nPH\n0\n1009\n0.333693\n0.332499\nPOINT (0.33250 0.33369)\n\n\n2\nPH20XX1072\nPH\n0\n1072\n0.378053\n0.089852\nPOINT (0.08985 0.37805)\n\n\n3\nPH20XX242\nPH\n0\n242\n0.306277\n0.431677\nPOINT (0.43168 0.30628)\n\n\n4\nPH20XX102\nPH\n0\n102\n0.535456\n0.716025\nPOINT (0.71602 0.53546)\n\n\n\n\n\n\n\n\nsurvey_geo = pd.merge(summarized, dhs_shp, on=\"DHSCLUST\")\nsurvey_geo\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nDHSCC\nDHSYEAR\nLATNUM\nLONGNUM\ngeometry\n\n\n\n\n0\n3\n-232188.000000\nPH20XX003\nPH\n0\n0.609945\n0.350830\nPOINT (0.35083 0.60995)\n\n\n1\n4\n228860.000000\nPH20XX004\nPH\n0\n0.363843\n0.281563\nPOINT (0.28156 0.36384)\n\n\n2\n5\n157620.000000\nPH20XX005\nPH\n0\n0.715438\n0.145014\nPOINT (0.14501 0.71544)\n\n\n3\n6\n40308.500000\nPH20XX006\nPH\n0\n0.758501\n0.628373\nPOINT (0.62837 0.75850)\n\n\n4\n6\n40308.500000\nPH20XX006\nPH\n0\n0.669415\n0.479379\nPOINT (0.47938 0.66942)\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n995\n1247\n90273.333333\nPH20XX1247\nPH\n0\n0.214682\n0.419448\nPOINT (0.41945 0.21468)\n\n\n996\n1248\n212729.500000\nPH20XX1248\nPH\n0\n0.189401\n0.152806\nPOINT (0.15281 0.18940)\n\n\n997\n1248\n212729.500000\nPH20XX1248\nPH\n0\n0.563460\n0.023900\nPOINT (0.02390 0.56346)\n\n\n998\n1250\n101508.500000\nPH20XX1250\nPH\n0\n0.166465\n0.617584\nPOINT (0.61758 0.16646)\n\n\n999\n1250\n101508.500000\nPH20XX1250\nPH\n0\n0.252438\n0.668243\nPOINT (0.66824 0.25244)\n\n\n\n\n1000 rows × 8 columns"
  },
  {
    "objectID": "tutorial.dhs.html#recalculating-wealth-index-for-a-single-country",
    "href": "tutorial.dhs.html#recalculating-wealth-index-for-a-single-country",
    "title": "DHS Wealth Index",
    "section": "Recalculating wealth index for a single country",
    "text": "Recalculating wealth index for a single country\n\nfeatures = [\n    \"rooms\",\n    \"electric\",\n    \"mobile telephone\",\n    \"radio\",\n    \"television\",\n    \"car/truck\",\n    \"refrigerator\",\n    \"motorcycle\",\n    \"floor\",\n    \"toilet\",\n    \"drinking water\",\n]\n\n\n# apply a threshold\ndhs.apply_threshold(renamed_dhs_df, columns=features, config={\"rooms\": [0, 25]})\n\n\nrenamed_dhs_df[\"Recomputed Wealth Index\"] = dhs.assign_wealth_index(\n    renamed_dhs_df[features], features\n)\nrenamed_dhs_df.head()"
  },
  {
    "objectID": "tutorial.dhs.html#recalculating-wealth-index-for-multiple-countries",
    "href": "tutorial.dhs.html#recalculating-wealth-index-for-multiple-countries",
    "title": "DHS Wealth Index",
    "section": "Recalculating wealth index for multiple countries",
    "text": "Recalculating wealth index for multiple countries\n\ndhs_ph_path = \"../data/ph.DTA\"\ndhs_kh_path = \"../data/kh.DTA\"\ndhs_mm_path = \"../data/mm.DTA\"\ndhs_tl_path = \"../data/tl.DTA\"\nph_config = dhs.load_column_config(\"ph\")\nkh_config = dhs.load_column_config(\"kh\")\nmm_config = dhs.load_column_config(\"mm\")\ntl_config = dhs.load_column_config(\"tl\")\ndhs_ph_df = dhs.load_dhs_file(dhs_ph_path).rename(columns=ph_config)\ndhs_kh_df = dhs.load_dhs_file(dhs_kh_path).rename(columns=kh_config)\ndhs_mm_df = dhs.load_dhs_file(dhs_mm_path).rename(columns=mm_config)\ndhs_tl_df = dhs.load_dhs_file(dhs_tl_path).rename(columns=tl_config)\n\n\ncols = list(ph_config.values()) + [\"country code and phase\"]\nmerged_df = pd.concat(\n    [\n        dhs_ph_df[cols],\n        dhs_kh_df[cols],\n        dhs_mm_df[cols],\n        dhs_tl_df[cols],\n    ]\n)\nmerged_df = merged_df.fillna(0)\n\n\nmerged_df[\"Recomputed Wealth Index\"] = dhs.assign_wealth_index(merged_df[features])\nmerged_df.head()\n\n\nimport matplotlib.pyplot as plt  # noqa\n\nmerged_df.hist(\"Recomputed Wealth Index\")\n\n\nmerged_df[\"Recomputed Wealth Index Not PCA\"] = dhs.assign_wealth_index(\n    merged_df[features], use_pca=False\n)\nmerged_df.head()\n\n\nmerged_df.hist(\"Recomputed Wealth Index Not PCA\")"
  },
  {
    "objectID": "tutorial.datasets.html",
    "href": "tutorial.datasets.html",
    "title": "Datasets Download",
    "section": "",
    "text": "import geopandas as gpd\n\nfrom geowrangler2.datasets import geofabrik\n\n\n\n\nregions = geofabrik.list_geofabrik_regions()\n# list down regions in asia\n{k: v for k, v in regions.items() if \"asia\" in v}\n\n{'afghanistan': 'https://download.geofabrik.de/asia/afghanistan-latest-free.shp.zip',\n 'armenia': 'https://download.geofabrik.de/asia/armenia-latest-free.shp.zip',\n 'azerbaijan': 'https://download.geofabrik.de/asia/azerbaijan-latest-free.shp.zip',\n 'bangladesh': 'https://download.geofabrik.de/asia/bangladesh-latest-free.shp.zip',\n 'bhutan': 'https://download.geofabrik.de/asia/bhutan-latest-free.shp.zip',\n 'cambodia': 'https://download.geofabrik.de/asia/cambodia-latest-free.shp.zip',\n 'central-zone': 'https://download.geofabrik.de/asia/india/central-zone-latest-free.shp.zip',\n 'china': 'https://download.geofabrik.de/asia/china-latest-free.shp.zip',\n 'chubu': 'https://download.geofabrik.de/asia/japan/chubu-latest-free.shp.zip',\n 'chugoku': 'https://download.geofabrik.de/asia/japan/chugoku-latest-free.shp.zip',\n 'east-timor': 'https://download.geofabrik.de/asia/east-timor-latest-free.shp.zip',\n 'eastern-zone': 'https://download.geofabrik.de/asia/india/eastern-zone-latest-free.shp.zip',\n 'gcc-states': 'https://download.geofabrik.de/asia/gcc-states-latest-free.shp.zip',\n 'hokkaido': 'https://download.geofabrik.de/asia/japan/hokkaido-latest-free.shp.zip',\n 'iran': 'https://download.geofabrik.de/asia/iran-latest-free.shp.zip',\n 'iraq': 'https://download.geofabrik.de/asia/iraq-latest-free.shp.zip',\n 'israel-and-palestine': 'https://download.geofabrik.de/asia/israel-and-palestine-latest-free.shp.zip',\n 'java': 'https://download.geofabrik.de/asia/indonesia/java-latest-free.shp.zip',\n 'jordan': 'https://download.geofabrik.de/asia/jordan-latest-free.shp.zip',\n 'kalimantan': 'https://download.geofabrik.de/asia/indonesia/kalimantan-latest-free.shp.zip',\n 'kansai': 'https://download.geofabrik.de/asia/japan/kansai-latest-free.shp.zip',\n 'kanto': 'https://download.geofabrik.de/asia/japan/kanto-latest-free.shp.zip',\n 'kazakhstan': 'https://download.geofabrik.de/asia/kazakhstan-latest-free.shp.zip',\n 'kyrgyzstan': 'https://download.geofabrik.de/asia/kyrgyzstan-latest-free.shp.zip',\n 'kyushu': 'https://download.geofabrik.de/asia/japan/kyushu-latest-free.shp.zip',\n 'laos': 'https://download.geofabrik.de/asia/laos-latest-free.shp.zip',\n 'lebanon': 'https://download.geofabrik.de/asia/lebanon-latest-free.shp.zip',\n 'malaysia-singapore-brunei': 'https://download.geofabrik.de/asia/malaysia-singapore-brunei-latest-free.shp.zip',\n 'maldives': 'https://download.geofabrik.de/asia/maldives-latest-free.shp.zip',\n 'maluku': 'https://download.geofabrik.de/asia/indonesia/maluku-latest-free.shp.zip',\n 'mongolia': 'https://download.geofabrik.de/asia/mongolia-latest-free.shp.zip',\n 'myanmar': 'https://download.geofabrik.de/asia/myanmar-latest-free.shp.zip',\n 'nepal': 'https://download.geofabrik.de/asia/nepal-latest-free.shp.zip',\n 'north-eastern-zone': 'https://download.geofabrik.de/asia/india/north-eastern-zone-latest-free.shp.zip',\n 'north-korea': 'https://download.geofabrik.de/asia/north-korea-latest-free.shp.zip',\n 'northern-zone': 'https://download.geofabrik.de/asia/india/northern-zone-latest-free.shp.zip',\n 'nusa-tenggara': 'https://download.geofabrik.de/asia/indonesia/nusa-tenggara-latest-free.shp.zip',\n 'pakistan': 'https://download.geofabrik.de/asia/pakistan-latest-free.shp.zip',\n 'papua': 'https://download.geofabrik.de/asia/indonesia/papua-latest-free.shp.zip',\n 'philippines': 'https://download.geofabrik.de/asia/philippines-latest-free.shp.zip',\n 'shikoku': 'https://download.geofabrik.de/asia/japan/shikoku-latest-free.shp.zip',\n 'south-korea': 'https://download.geofabrik.de/asia/south-korea-latest-free.shp.zip',\n 'southern-zone': 'https://download.geofabrik.de/asia/india/southern-zone-latest-free.shp.zip',\n 'sri-lanka': 'https://download.geofabrik.de/asia/sri-lanka-latest-free.shp.zip',\n 'sulawesi': 'https://download.geofabrik.de/asia/indonesia/sulawesi-latest-free.shp.zip',\n 'sumatra': 'https://download.geofabrik.de/asia/indonesia/sumatra-latest-free.shp.zip',\n 'syria': 'https://download.geofabrik.de/asia/syria-latest-free.shp.zip',\n 'taiwan': 'https://download.geofabrik.de/asia/taiwan-latest-free.shp.zip',\n 'tajikistan': 'https://download.geofabrik.de/asia/tajikistan-latest-free.shp.zip',\n 'thailand': 'https://download.geofabrik.de/asia/thailand-latest-free.shp.zip',\n 'tohoku': 'https://download.geofabrik.de/asia/japan/tohoku-latest-free.shp.zip',\n 'turkmenistan': 'https://download.geofabrik.de/asia/turkmenistan-latest-free.shp.zip',\n 'uzbekistan': 'https://download.geofabrik.de/asia/uzbekistan-latest-free.shp.zip',\n 'vietnam': 'https://download.geofabrik.de/asia/vietnam-latest-free.shp.zip',\n 'western-zone': 'https://download.geofabrik.de/asia/india/western-zone-latest-free.shp.zip',\n 'yemen': 'https://download.geofabrik.de/asia/yemen-latest-free.shp.zip'}\n\n\n\n\n\n\n# no_test\ndownloaded_file = geofabrik.download_geofabrik_region(\"laos\", \"../test_dir\")\ndownloaded_file\n\n2023-02-01 17:00:04.495 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/laos-latest-free.shp.zip into ../test_dir/laos-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.00% [97345536/97341916 00:17&lt;00:00]\n    \n    \n\n\nCPU times: user 1.58 s, sys: 980 ms, total: 2.56 s\nWall time: 18 s\n\n\nPath('../test_dir/laos-latest-free.shp.zip')\n\n\n\n\n\n\ngdf = gpd.read_file(downloaded_file)\ngdf.head()\n\nCPU times: user 19.4 s, sys: 528 ms, total: 19.9 s\nWall time: 19.9 s\n\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ntype\ngeometry\n\n\n\n\n0\n36192811\n1500\nbuilding\nDon Chan Palace\nNone\nPOLYGON ((102.61392 17.95514, 102.61419 17.955...\n\n\n1\n36195671\n1500\nbuilding\nຕະຫລາດເຊົ້າ. 早市塲\nNone\nPOLYGON ((102.61382 17.96520, 102.61393 17.965...\n\n\n2\n36195973\n1500\nbuilding\nMercure Hotel Laotel\nNone\nPOLYGON ((102.59386 17.96890, 102.59432 17.968...\n\n\n3\n36784437\n1500\nbuilding\nNone\nNone\nPOLYGON ((105.79786 15.11905, 105.79838 15.119...\n\n\n4\n37886432\n1500\nbuilding\nPresidential Palace\nNone\nPOLYGON ((102.60940 17.96246, 102.60951 17.962...\n\n\n\n\n\n\n\nYou can also list the contents of the zipped shape file as well as load the shape file within it\n\n!unzip -l {downloaded_file.as_posix()}\n\nArchive:  ../test_dir/laos-latest-free.shp.zip\n  Length      Date    Time    Name\n---------  ---------- -----   ----\n      647  2023-02-01 09:00   README\n        6  2023-02-01 09:00   gis_osm_buildings_a_free_1.cpg\n 68322734  2023-02-01 09:00   gis_osm_buildings_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_buildings_a_free_1.prj\n 60089724  2023-02-01 09:00   gis_osm_buildings_a_free_1.shp\n  3312708  2023-02-01 09:00   gis_osm_buildings_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_landuse_a_free_1.cpg\n  2845642  2023-02-01 09:00   gis_osm_landuse_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_landuse_a_free_1.prj\n 14407732  2023-02-01 09:00   gis_osm_landuse_a_free_1.shp\n   157092  2023-02-01 09:00   gis_osm_landuse_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_natural_a_free_1.cpg\n     7702  2023-02-01 09:00   gis_osm_natural_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_natural_a_free_1.prj\n    15556  2023-02-01 09:00   gis_osm_natural_a_free_1.shp\n      516  2023-02-01 09:00   gis_osm_natural_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_natural_free_1.cpg\n   753872  2023-02-01 09:00   gis_osm_natural_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_natural_free_1.prj\n   145644  2023-02-01 09:00   gis_osm_natural_free_1.shp\n    41684  2023-02-01 09:00   gis_osm_natural_free_1.shx\n        6  2023-02-01 09:00   gis_osm_places_a_free_1.cpg\n    26854  2023-02-01 09:00   gis_osm_places_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_places_a_free_1.prj\n   441004  2023-02-01 09:00   gis_osm_places_a_free_1.shp\n     1476  2023-02-01 09:00   gis_osm_places_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_places_free_1.cpg\n  1142544  2023-02-01 09:00   gis_osm_places_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_places_free_1.prj\n   206460  2023-02-01 09:00   gis_osm_places_free_1.shp\n    59060  2023-02-01 09:00   gis_osm_places_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pofw_a_free_1.cpg\n    39602  2023-02-01 09:00   gis_osm_pofw_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pofw_a_free_1.prj\n    49992  2023-02-01 09:00   gis_osm_pofw_a_free_1.shp\n     2276  2023-02-01 09:00   gis_osm_pofw_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pofw_free_1.cpg\n    66427  2023-02-01 09:00   gis_osm_pofw_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pofw_free_1.prj\n    12896  2023-02-01 09:00   gis_osm_pofw_free_1.shp\n     3756  2023-02-01 09:00   gis_osm_pofw_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pois_a_free_1.cpg\n   274067  2023-02-01 09:00   gis_osm_pois_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pois_a_free_1.prj\n   351936  2023-02-01 09:00   gis_osm_pois_a_free_1.shp\n    15212  2023-02-01 09:00   gis_osm_pois_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pois_free_1.cpg\n  1884292  2023-02-01 09:00   gis_osm_pois_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pois_free_1.prj\n   363932  2023-02-01 09:00   gis_osm_pois_free_1.shp\n   104052  2023-02-01 09:00   gis_osm_pois_free_1.shx\n        6  2023-02-01 09:00   gis_osm_railways_free_1.cpg\n   100110  2023-02-01 09:00   gis_osm_railways_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_railways_free_1.prj\n   101636  2023-02-01 09:00   gis_osm_railways_free_1.shp\n     5124  2023-02-01 09:00   gis_osm_railways_free_1.shx\n        6  2023-02-01 09:00   gis_osm_roads_free_1.cpg\n 20909019  2023-02-01 09:00   gis_osm_roads_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_roads_free_1.prj\n 50224636  2023-02-01 09:00   gis_osm_roads_free_1.shp\n   914140  2023-02-01 09:00   gis_osm_roads_free_1.shx\n        6  2023-02-01 09:00   gis_osm_traffic_a_free_1.cpg\n   102532  2023-02-01 09:00   gis_osm_traffic_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_traffic_a_free_1.prj\n   131304  2023-02-01 09:00   gis_osm_traffic_a_free_1.shp\n     5748  2023-02-01 09:00   gis_osm_traffic_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_traffic_free_1.cpg\n   275807  2023-02-01 09:00   gis_osm_traffic_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_traffic_free_1.prj\n    53328  2023-02-01 09:00   gis_osm_traffic_free_1.shp\n    15308  2023-02-01 09:00   gis_osm_traffic_free_1.shx\n        6  2023-02-01 09:00   gis_osm_transport_a_free_1.cpg\n    10892  2023-02-01 09:00   gis_osm_transport_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_transport_a_free_1.prj\n    28840  2023-02-01 09:00   gis_osm_transport_a_free_1.shp\n      692  2023-02-01 09:00   gis_osm_transport_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_transport_free_1.cpg\n    82522  2023-02-01 09:00   gis_osm_transport_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_transport_free_1.prj\n    16004  2023-02-01 09:00   gis_osm_transport_free_1.shp\n     4644  2023-02-01 09:00   gis_osm_transport_free_1.shx\n        6  2023-02-01 09:00   gis_osm_water_a_free_1.cpg\n   979927  2023-02-01 09:00   gis_osm_water_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_water_a_free_1.prj\n 14026044  2023-02-01 09:00   gis_osm_water_a_free_1.shp\n    54156  2023-02-01 09:00   gis_osm_water_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_waterways_free_1.cpg\n  1662494  2023-02-01 09:00   gis_osm_waterways_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_waterways_free_1.prj\n 14396164  2023-02-01 09:00   gis_osm_waterways_free_1.shp\n    88756  2023-02-01 09:00   gis_osm_waterways_free_1.shx\n---------                     -------\n259339618                     91 files\n\n\n\ngdf2 = gpd.read_file(f\"{downloaded_file.as_posix()}!gis_osm_pois_free_1.shp\")\n\nCPU times: user 745 ms, sys: 19.4 ms, total: 764 ms\nWall time: 773 ms\n\n\n\n\n\nIn addition downloading, the geofabrik module provides an unzipping and caching facility (default cache directory: ~/.cache/geowrangler2/osm ) to make it easier to access OSM data.\n\ndownload_path = geofabrik.download_osm_region_data(\"afghanistan\")\ndownload_path\n\n2023-02-01 17:00:42.767 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for afghanistan at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip? False\n2023-02-01 17:00:43.526 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip...\n2023-02-01 17:00:43.529 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip...\n2023-02-01 17:00:44.247 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/afghanistan-latest-free.shp.zip into /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip\n2023-02-01 17:01:23.951 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:159 - OSM Data: Successfully downloaded and cached OSM data for afghanistan at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip!\n\n\n\n\n\n\n\n    \n      \n      100.00% [241524736/241516716 00:39&lt;00:00]\n    \n    \n\n\nCPU times: user 3.22 s, sys: 1.76 s, total: 4.98 s\nWall time: 41.2 s\n\n\nPath('/home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip')\n\n\nDownloading it the second time around should be much faster as it only checks if its in the cache and returns the path\n\ndownload_path2 = geofabrik.download_osm_region_data(\"afghanistan\")\ndownload_path2\n\n2023-02-01 17:01:23.973 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for afghanistan at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip? True\n\n\nCPU times: user 2.22 ms, sys: 349 µs, total: 2.57 ms\nWall time: 2.08 ms\n\n\nPath('/home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip')\n\n\n\n!ls -aldh  {download_path2}\n\n-rw-r--r-- 1 butchtm butchtm 231M Feb  1 17:01 /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip\n\n\n\n\n\nWe also provide an OSM Data Manager which, in addition to using the default cache (~/.cache/geowrangler2/osm), also caches the geodataframe for either the pois or the roads datasets from OSM in memory to avoid having to reload the OSM data from disk.\n\n# Create the osm data manager\nodm = geofabrik.OsmDataManager()\n\n\npois_ph = odm.load_pois(\"philippines\")\n\n2023-02-01 17:01:24.214 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip? False\n2023-02-01 17:01:25.631 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip...\n2023-02-01 17:01:25.634 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip...\n2023-02-01 17:01:26.355 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/philippines-latest-free.shp.zip into /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip\n2023-02-01 17:09:06.368 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:159 - OSM Data: Successfully downloaded and cached OSM data for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip!\n2023-02-01 17:09:06.370 | DEBUG    | geowrangler2.datasets.geofabrik:load_pois:218 - OSM POIs for philippines being loaded from /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.08% [1185939456/1185011560 07:39&lt;00:00]\n    \n    \n\n\n\npois_ph.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry\n\n\n\n\n0\n21717820\n2907\ncamera_surveillance\nNone\nPOINT (121.02120 14.57608)\n\n\n1\n21717872\n2722\nmuseum\nAyala Museum\nPOINT (121.02324 14.55358)\n\n\n2\n24078301\n2402\nmotel\nSogo Grand Hotel\nPOINT (121.04515 14.56449)\n\n\n3\n24078959\n2907\ncamera_surveillance\nNone\nPOINT (121.05945 14.60098)\n\n\n4\n24797511\n2542\nbicycle_shop\nChristine Sports Cycle Marketing\nPOINT (120.99506 14.55224)\n\n\n\n\n\n\n\n\nroads_ph = odm.load_roads(\"philippines\")\n\n2023-02-01 17:09:10.649 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip? True\n2023-02-01 17:09:10.653 | DEBUG    | geowrangler2.datasets.geofabrik:load_roads:274 - OSM Roads for philippines being loaded from /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip\n\n\n\nroads_ph.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nref\noneway\nmaxspeed\nlayer\nbridge\ntunnel\ngeometry\n\n\n\n\n0\n267\n5115\ntertiary\nMaharlika Street\nNone\nF\n30\n0\nF\nF\nLINESTRING (121.05195 14.65011, 121.05209 14.6...\n\n\n1\n2508359\n5153\nfootway\nSagada Mission Compound\nNone\nB\n0\n0\nF\nF\nLINESTRING (120.90199 17.08090, 120.90197 17.0...\n\n\n2\n2667097\n5113\nprimary\nTaft Avenue\n170\nF\n60\n0\nF\nF\nLINESTRING (120.99682 14.55577, 120.99671 14.5...\n\n\n3\n2667099\n5113\nprimary\nLerma Street\n170\nF\n60\n0\nF\nF\nLINESTRING (120.98539 14.60460, 120.98545 14.6...\n\n\n4\n2667105\n5122\nresidential\nManalito Street\nNone\nB\n0\n0\nF\nF\nLINESTRING (120.99380 14.54125, 120.99497 14.5..."
  },
  {
    "objectID": "tutorial.datasets.html#downloading-geofabrik-data",
    "href": "tutorial.datasets.html#downloading-geofabrik-data",
    "title": "Datasets Download",
    "section": "",
    "text": "import geopandas as gpd\n\nfrom geowrangler2.datasets import geofabrik\n\n\n\n\nregions = geofabrik.list_geofabrik_regions()\n# list down regions in asia\n{k: v for k, v in regions.items() if \"asia\" in v}\n\n{'afghanistan': 'https://download.geofabrik.de/asia/afghanistan-latest-free.shp.zip',\n 'armenia': 'https://download.geofabrik.de/asia/armenia-latest-free.shp.zip',\n 'azerbaijan': 'https://download.geofabrik.de/asia/azerbaijan-latest-free.shp.zip',\n 'bangladesh': 'https://download.geofabrik.de/asia/bangladesh-latest-free.shp.zip',\n 'bhutan': 'https://download.geofabrik.de/asia/bhutan-latest-free.shp.zip',\n 'cambodia': 'https://download.geofabrik.de/asia/cambodia-latest-free.shp.zip',\n 'central-zone': 'https://download.geofabrik.de/asia/india/central-zone-latest-free.shp.zip',\n 'china': 'https://download.geofabrik.de/asia/china-latest-free.shp.zip',\n 'chubu': 'https://download.geofabrik.de/asia/japan/chubu-latest-free.shp.zip',\n 'chugoku': 'https://download.geofabrik.de/asia/japan/chugoku-latest-free.shp.zip',\n 'east-timor': 'https://download.geofabrik.de/asia/east-timor-latest-free.shp.zip',\n 'eastern-zone': 'https://download.geofabrik.de/asia/india/eastern-zone-latest-free.shp.zip',\n 'gcc-states': 'https://download.geofabrik.de/asia/gcc-states-latest-free.shp.zip',\n 'hokkaido': 'https://download.geofabrik.de/asia/japan/hokkaido-latest-free.shp.zip',\n 'iran': 'https://download.geofabrik.de/asia/iran-latest-free.shp.zip',\n 'iraq': 'https://download.geofabrik.de/asia/iraq-latest-free.shp.zip',\n 'israel-and-palestine': 'https://download.geofabrik.de/asia/israel-and-palestine-latest-free.shp.zip',\n 'java': 'https://download.geofabrik.de/asia/indonesia/java-latest-free.shp.zip',\n 'jordan': 'https://download.geofabrik.de/asia/jordan-latest-free.shp.zip',\n 'kalimantan': 'https://download.geofabrik.de/asia/indonesia/kalimantan-latest-free.shp.zip',\n 'kansai': 'https://download.geofabrik.de/asia/japan/kansai-latest-free.shp.zip',\n 'kanto': 'https://download.geofabrik.de/asia/japan/kanto-latest-free.shp.zip',\n 'kazakhstan': 'https://download.geofabrik.de/asia/kazakhstan-latest-free.shp.zip',\n 'kyrgyzstan': 'https://download.geofabrik.de/asia/kyrgyzstan-latest-free.shp.zip',\n 'kyushu': 'https://download.geofabrik.de/asia/japan/kyushu-latest-free.shp.zip',\n 'laos': 'https://download.geofabrik.de/asia/laos-latest-free.shp.zip',\n 'lebanon': 'https://download.geofabrik.de/asia/lebanon-latest-free.shp.zip',\n 'malaysia-singapore-brunei': 'https://download.geofabrik.de/asia/malaysia-singapore-brunei-latest-free.shp.zip',\n 'maldives': 'https://download.geofabrik.de/asia/maldives-latest-free.shp.zip',\n 'maluku': 'https://download.geofabrik.de/asia/indonesia/maluku-latest-free.shp.zip',\n 'mongolia': 'https://download.geofabrik.de/asia/mongolia-latest-free.shp.zip',\n 'myanmar': 'https://download.geofabrik.de/asia/myanmar-latest-free.shp.zip',\n 'nepal': 'https://download.geofabrik.de/asia/nepal-latest-free.shp.zip',\n 'north-eastern-zone': 'https://download.geofabrik.de/asia/india/north-eastern-zone-latest-free.shp.zip',\n 'north-korea': 'https://download.geofabrik.de/asia/north-korea-latest-free.shp.zip',\n 'northern-zone': 'https://download.geofabrik.de/asia/india/northern-zone-latest-free.shp.zip',\n 'nusa-tenggara': 'https://download.geofabrik.de/asia/indonesia/nusa-tenggara-latest-free.shp.zip',\n 'pakistan': 'https://download.geofabrik.de/asia/pakistan-latest-free.shp.zip',\n 'papua': 'https://download.geofabrik.de/asia/indonesia/papua-latest-free.shp.zip',\n 'philippines': 'https://download.geofabrik.de/asia/philippines-latest-free.shp.zip',\n 'shikoku': 'https://download.geofabrik.de/asia/japan/shikoku-latest-free.shp.zip',\n 'south-korea': 'https://download.geofabrik.de/asia/south-korea-latest-free.shp.zip',\n 'southern-zone': 'https://download.geofabrik.de/asia/india/southern-zone-latest-free.shp.zip',\n 'sri-lanka': 'https://download.geofabrik.de/asia/sri-lanka-latest-free.shp.zip',\n 'sulawesi': 'https://download.geofabrik.de/asia/indonesia/sulawesi-latest-free.shp.zip',\n 'sumatra': 'https://download.geofabrik.de/asia/indonesia/sumatra-latest-free.shp.zip',\n 'syria': 'https://download.geofabrik.de/asia/syria-latest-free.shp.zip',\n 'taiwan': 'https://download.geofabrik.de/asia/taiwan-latest-free.shp.zip',\n 'tajikistan': 'https://download.geofabrik.de/asia/tajikistan-latest-free.shp.zip',\n 'thailand': 'https://download.geofabrik.de/asia/thailand-latest-free.shp.zip',\n 'tohoku': 'https://download.geofabrik.de/asia/japan/tohoku-latest-free.shp.zip',\n 'turkmenistan': 'https://download.geofabrik.de/asia/turkmenistan-latest-free.shp.zip',\n 'uzbekistan': 'https://download.geofabrik.de/asia/uzbekistan-latest-free.shp.zip',\n 'vietnam': 'https://download.geofabrik.de/asia/vietnam-latest-free.shp.zip',\n 'western-zone': 'https://download.geofabrik.de/asia/india/western-zone-latest-free.shp.zip',\n 'yemen': 'https://download.geofabrik.de/asia/yemen-latest-free.shp.zip'}\n\n\n\n\n\n\n# no_test\ndownloaded_file = geofabrik.download_geofabrik_region(\"laos\", \"../test_dir\")\ndownloaded_file\n\n2023-02-01 17:00:04.495 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/laos-latest-free.shp.zip into ../test_dir/laos-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.00% [97345536/97341916 00:17&lt;00:00]\n    \n    \n\n\nCPU times: user 1.58 s, sys: 980 ms, total: 2.56 s\nWall time: 18 s\n\n\nPath('../test_dir/laos-latest-free.shp.zip')\n\n\n\n\n\n\ngdf = gpd.read_file(downloaded_file)\ngdf.head()\n\nCPU times: user 19.4 s, sys: 528 ms, total: 19.9 s\nWall time: 19.9 s\n\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ntype\ngeometry\n\n\n\n\n0\n36192811\n1500\nbuilding\nDon Chan Palace\nNone\nPOLYGON ((102.61392 17.95514, 102.61419 17.955...\n\n\n1\n36195671\n1500\nbuilding\nຕະຫລາດເຊົ້າ. 早市塲\nNone\nPOLYGON ((102.61382 17.96520, 102.61393 17.965...\n\n\n2\n36195973\n1500\nbuilding\nMercure Hotel Laotel\nNone\nPOLYGON ((102.59386 17.96890, 102.59432 17.968...\n\n\n3\n36784437\n1500\nbuilding\nNone\nNone\nPOLYGON ((105.79786 15.11905, 105.79838 15.119...\n\n\n4\n37886432\n1500\nbuilding\nPresidential Palace\nNone\nPOLYGON ((102.60940 17.96246, 102.60951 17.962...\n\n\n\n\n\n\n\nYou can also list the contents of the zipped shape file as well as load the shape file within it\n\n!unzip -l {downloaded_file.as_posix()}\n\nArchive:  ../test_dir/laos-latest-free.shp.zip\n  Length      Date    Time    Name\n---------  ---------- -----   ----\n      647  2023-02-01 09:00   README\n        6  2023-02-01 09:00   gis_osm_buildings_a_free_1.cpg\n 68322734  2023-02-01 09:00   gis_osm_buildings_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_buildings_a_free_1.prj\n 60089724  2023-02-01 09:00   gis_osm_buildings_a_free_1.shp\n  3312708  2023-02-01 09:00   gis_osm_buildings_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_landuse_a_free_1.cpg\n  2845642  2023-02-01 09:00   gis_osm_landuse_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_landuse_a_free_1.prj\n 14407732  2023-02-01 09:00   gis_osm_landuse_a_free_1.shp\n   157092  2023-02-01 09:00   gis_osm_landuse_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_natural_a_free_1.cpg\n     7702  2023-02-01 09:00   gis_osm_natural_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_natural_a_free_1.prj\n    15556  2023-02-01 09:00   gis_osm_natural_a_free_1.shp\n      516  2023-02-01 09:00   gis_osm_natural_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_natural_free_1.cpg\n   753872  2023-02-01 09:00   gis_osm_natural_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_natural_free_1.prj\n   145644  2023-02-01 09:00   gis_osm_natural_free_1.shp\n    41684  2023-02-01 09:00   gis_osm_natural_free_1.shx\n        6  2023-02-01 09:00   gis_osm_places_a_free_1.cpg\n    26854  2023-02-01 09:00   gis_osm_places_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_places_a_free_1.prj\n   441004  2023-02-01 09:00   gis_osm_places_a_free_1.shp\n     1476  2023-02-01 09:00   gis_osm_places_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_places_free_1.cpg\n  1142544  2023-02-01 09:00   gis_osm_places_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_places_free_1.prj\n   206460  2023-02-01 09:00   gis_osm_places_free_1.shp\n    59060  2023-02-01 09:00   gis_osm_places_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pofw_a_free_1.cpg\n    39602  2023-02-01 09:00   gis_osm_pofw_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pofw_a_free_1.prj\n    49992  2023-02-01 09:00   gis_osm_pofw_a_free_1.shp\n     2276  2023-02-01 09:00   gis_osm_pofw_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pofw_free_1.cpg\n    66427  2023-02-01 09:00   gis_osm_pofw_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pofw_free_1.prj\n    12896  2023-02-01 09:00   gis_osm_pofw_free_1.shp\n     3756  2023-02-01 09:00   gis_osm_pofw_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pois_a_free_1.cpg\n   274067  2023-02-01 09:00   gis_osm_pois_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pois_a_free_1.prj\n   351936  2023-02-01 09:00   gis_osm_pois_a_free_1.shp\n    15212  2023-02-01 09:00   gis_osm_pois_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_pois_free_1.cpg\n  1884292  2023-02-01 09:00   gis_osm_pois_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_pois_free_1.prj\n   363932  2023-02-01 09:00   gis_osm_pois_free_1.shp\n   104052  2023-02-01 09:00   gis_osm_pois_free_1.shx\n        6  2023-02-01 09:00   gis_osm_railways_free_1.cpg\n   100110  2023-02-01 09:00   gis_osm_railways_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_railways_free_1.prj\n   101636  2023-02-01 09:00   gis_osm_railways_free_1.shp\n     5124  2023-02-01 09:00   gis_osm_railways_free_1.shx\n        6  2023-02-01 09:00   gis_osm_roads_free_1.cpg\n 20909019  2023-02-01 09:00   gis_osm_roads_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_roads_free_1.prj\n 50224636  2023-02-01 09:00   gis_osm_roads_free_1.shp\n   914140  2023-02-01 09:00   gis_osm_roads_free_1.shx\n        6  2023-02-01 09:00   gis_osm_traffic_a_free_1.cpg\n   102532  2023-02-01 09:00   gis_osm_traffic_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_traffic_a_free_1.prj\n   131304  2023-02-01 09:00   gis_osm_traffic_a_free_1.shp\n     5748  2023-02-01 09:00   gis_osm_traffic_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_traffic_free_1.cpg\n   275807  2023-02-01 09:00   gis_osm_traffic_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_traffic_free_1.prj\n    53328  2023-02-01 09:00   gis_osm_traffic_free_1.shp\n    15308  2023-02-01 09:00   gis_osm_traffic_free_1.shx\n        6  2023-02-01 09:00   gis_osm_transport_a_free_1.cpg\n    10892  2023-02-01 09:00   gis_osm_transport_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_transport_a_free_1.prj\n    28840  2023-02-01 09:00   gis_osm_transport_a_free_1.shp\n      692  2023-02-01 09:00   gis_osm_transport_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_transport_free_1.cpg\n    82522  2023-02-01 09:00   gis_osm_transport_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_transport_free_1.prj\n    16004  2023-02-01 09:00   gis_osm_transport_free_1.shp\n     4644  2023-02-01 09:00   gis_osm_transport_free_1.shx\n        6  2023-02-01 09:00   gis_osm_water_a_free_1.cpg\n   979927  2023-02-01 09:00   gis_osm_water_a_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_water_a_free_1.prj\n 14026044  2023-02-01 09:00   gis_osm_water_a_free_1.shp\n    54156  2023-02-01 09:00   gis_osm_water_a_free_1.shx\n        6  2023-02-01 09:00   gis_osm_waterways_free_1.cpg\n  1662494  2023-02-01 09:00   gis_osm_waterways_free_1.dbf\n      144  2023-02-01 09:00   gis_osm_waterways_free_1.prj\n 14396164  2023-02-01 09:00   gis_osm_waterways_free_1.shp\n    88756  2023-02-01 09:00   gis_osm_waterways_free_1.shx\n---------                     -------\n259339618                     91 files\n\n\n\ngdf2 = gpd.read_file(f\"{downloaded_file.as_posix()}!gis_osm_pois_free_1.shp\")\n\nCPU times: user 745 ms, sys: 19.4 ms, total: 764 ms\nWall time: 773 ms\n\n\n\n\n\nIn addition downloading, the geofabrik module provides an unzipping and caching facility (default cache directory: ~/.cache/geowrangler2/osm ) to make it easier to access OSM data.\n\ndownload_path = geofabrik.download_osm_region_data(\"afghanistan\")\ndownload_path\n\n2023-02-01 17:00:42.767 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for afghanistan at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip? False\n2023-02-01 17:00:43.526 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip...\n2023-02-01 17:00:43.529 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip...\n2023-02-01 17:00:44.247 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/afghanistan-latest-free.shp.zip into /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip\n2023-02-01 17:01:23.951 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:159 - OSM Data: Successfully downloaded and cached OSM data for afghanistan at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip!\n\n\n\n\n\n\n\n    \n      \n      100.00% [241524736/241516716 00:39&lt;00:00]\n    \n    \n\n\nCPU times: user 3.22 s, sys: 1.76 s, total: 4.98 s\nWall time: 41.2 s\n\n\nPath('/home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip')\n\n\nDownloading it the second time around should be much faster as it only checks if its in the cache and returns the path\n\ndownload_path2 = geofabrik.download_osm_region_data(\"afghanistan\")\ndownload_path2\n\n2023-02-01 17:01:23.973 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for afghanistan at /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip? True\n\n\nCPU times: user 2.22 ms, sys: 349 µs, total: 2.57 ms\nWall time: 2.08 ms\n\n\nPath('/home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip')\n\n\n\n!ls -aldh  {download_path2}\n\n-rw-r--r-- 1 butchtm butchtm 231M Feb  1 17:01 /home/butchtm/.cache/geowrangler2/osm/afghanistan-latest-free.shp.zip\n\n\n\n\n\nWe also provide an OSM Data Manager which, in addition to using the default cache (~/.cache/geowrangler2/osm), also caches the geodataframe for either the pois or the roads datasets from OSM in memory to avoid having to reload the OSM data from disk.\n\n# Create the osm data manager\nodm = geofabrik.OsmDataManager()\n\n\npois_ph = odm.load_pois(\"philippines\")\n\n2023-02-01 17:01:24.214 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip? False\n2023-02-01 17:01:25.631 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip...\n2023-02-01 17:01:25.634 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip...\n2023-02-01 17:01:26.355 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/philippines-latest-free.shp.zip into /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip\n2023-02-01 17:09:06.368 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:159 - OSM Data: Successfully downloaded and cached OSM data for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip!\n2023-02-01 17:09:06.370 | DEBUG    | geowrangler2.datasets.geofabrik:load_pois:218 - OSM POIs for philippines being loaded from /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.08% [1185939456/1185011560 07:39&lt;00:00]\n    \n    \n\n\n\npois_ph.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry\n\n\n\n\n0\n21717820\n2907\ncamera_surveillance\nNone\nPOINT (121.02120 14.57608)\n\n\n1\n21717872\n2722\nmuseum\nAyala Museum\nPOINT (121.02324 14.55358)\n\n\n2\n24078301\n2402\nmotel\nSogo Grand Hotel\nPOINT (121.04515 14.56449)\n\n\n3\n24078959\n2907\ncamera_surveillance\nNone\nPOINT (121.05945 14.60098)\n\n\n4\n24797511\n2542\nbicycle_shop\nChristine Sports Cycle Marketing\nPOINT (120.99506 14.55224)\n\n\n\n\n\n\n\n\nroads_ph = odm.load_roads(\"philippines\")\n\n2023-02-01 17:09:10.649 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip? True\n2023-02-01 17:09:10.653 | DEBUG    | geowrangler2.datasets.geofabrik:load_roads:274 - OSM Roads for philippines being loaded from /home/butchtm/.cache/geowrangler2/osm/philippines-latest-free.shp.zip\n\n\n\nroads_ph.head()\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nref\noneway\nmaxspeed\nlayer\nbridge\ntunnel\ngeometry\n\n\n\n\n0\n267\n5115\ntertiary\nMaharlika Street\nNone\nF\n30\n0\nF\nF\nLINESTRING (121.05195 14.65011, 121.05209 14.6...\n\n\n1\n2508359\n5153\nfootway\nSagada Mission Compound\nNone\nB\n0\n0\nF\nF\nLINESTRING (120.90199 17.08090, 120.90197 17.0...\n\n\n2\n2667097\n5113\nprimary\nTaft Avenue\n170\nF\n60\n0\nF\nF\nLINESTRING (120.99682 14.55577, 120.99671 14.5...\n\n\n3\n2667099\n5113\nprimary\nLerma Street\n170\nF\n60\n0\nF\nF\nLINESTRING (120.98539 14.60460, 120.98545 14.6...\n\n\n4\n2667105\n5122\nresidential\nManalito Street\nNone\nB\n0\n0\nF\nF\nLINESTRING (120.99380 14.54125, 120.99497 14.5..."
  },
  {
    "objectID": "tutorial.datasets.html#loading-osm-data-from-other-years",
    "href": "tutorial.datasets.html#loading-osm-data-from-other-years",
    "title": "Datasets Download",
    "section": "Loading OSM data from other years",
    "text": "Loading OSM data from other years\nIn addition to providing access to the latest OSM shape files, we also provide an optional year parameter, which allows you to download OSM data from previous years.\n\n\n\n\n\n\nNote\n\n\n\nThe availability of data from previous years is dependent on what geofabrik has made available. Please check the Geofabrik download site for the list of available data\n\n\n\npois_ph = odm.load_pois(\"philippines\", year=\"2017\")\n\n2023-02-01 17:10:30.351 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:127 - OSM Data: Cached data available for philippines at /home/butchtm/.cache/geowrangler2/osm/philippines-170101-free.shp.zip? False\n2023-02-01 17:10:33.834 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:141 - OSM Data: Re-initializing OSM region zip file at /home/butchtm/.cache/geowrangler2/osm/philippines-170101-free.shp.zip...\n2023-02-01 17:10:33.838 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:148 - OSM Data: Downloading Geofabrik in /home/butchtm/.cache/geowrangler2/osm/philippines-170101-free.shp.zip...\n2023-02-01 17:10:35.780 | INFO     | geowrangler2.datasets.utils:urlretrieve:27 - Retrieving https://download.geofabrik.de/asia/philippines-170101-free.shp.zip into /home/butchtm/.cache/geowrangler2/osm/philippines-170101-free.shp.zip\n2023-02-01 17:12:24.933 | INFO     | geowrangler2.datasets.geofabrik:download_osm_region_data:163 - OSM Data: Successfully downloaded and cached OSM data for philippines and 2017 at /home/butchtm/.cache/geowrangler2/osm/philippines-170101-free.shp.zip!\n2023-02-01 17:12:24.935 | DEBUG    | geowrangler2.datasets.geofabrik:load_pois:220 - OSM POIs for philippines and year 2017 being loaded from /home/butchtm/.cache/geowrangler2/osm/philippines-170101-free.shp.zip\n\n\n\n\n\n\n\n    \n      \n      100.25% [412090368/411074511 01:49&lt;00:00]\n    \n    \n\n\n\npois_ph\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry\n\n\n\n\n0\n14401658\n2742\nviewpoint\nEast Point\nPOINT (120.62020 14.38562)\n\n\n1\n14446500\n2721\nattraction\nIntramuros\nPOINT (120.97533 14.59059)\n\n\n2\n21717872\n2722\nmuseum\nAyala Museum\nPOINT (121.02324 14.55358)\n\n\n3\n24078301\n2401\nhotel\nSogo Grand Hotel\nPOINT (121.04515 14.56449)\n\n\n4\n24078959\n2907\ncamera_surveillance\nNone\nPOINT (121.05945 14.60098)\n\n\n...\n...\n...\n...\n...\n...\n\n\n67400\n4584129489\n2502\nbakery\nCome-on bakery\nPOINT (123.26424 9.19066)\n\n\n67401\n4584130190\n2401\nhotel\nL-mansion\nPOINT (121.00280 14.55968)\n\n\n67402\n4584164592\n2721\nattraction\nLugnason Falls\nPOINT (123.53406 9.14808)\n\n\n67403\n4584215391\n2742\nviewpoint\nNone\nPOINT (123.53406 9.14804)\n\n\n67404\n4584253097\n2511\nconvenience\nHerlyn's Burger House\nPOINT (120.58250 14.99107)\n\n\n\n\n67405 rows × 5 columns"
  },
  {
    "objectID": "tutorial.datasets.html#downloading-ookla-data",
    "href": "tutorial.datasets.html#downloading-ookla-data",
    "title": "Datasets Download",
    "section": "Downloading Ookla Data",
    "text": "Downloading Ookla Data\n\nimport geopandas as gpd\nimport pandas as pd\n\nfrom geowrangler2.datasets import ookla\n\n\nListing down available files\n\nookla_files = ookla.list_ookla_files()\nookla_files\n\n{OoklaQuarter(type='fixed', year='2019', quarter='1'): '2019-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='2'): '2019-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='3'): '2019-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2019', quarter='4'): '2019-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='1'): '2020-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='2'): '2020-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='3'): '2020-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2020', quarter='4'): '2020-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='1'): '2021-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='2'): '2021-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='3'): '2021-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2021', quarter='4'): '2021-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='1'): '2022-01-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='2'): '2022-04-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='3'): '2022-07-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='fixed', year='2022', quarter='4'): '2022-10-01_performance_fixed_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='1'): '2019-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='2'): '2019-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='3'): '2019-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2019', quarter='4'): '2019-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='1'): '2020-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='2'): '2020-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='3'): '2020-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2020', quarter='4'): '2020-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='1'): '2021-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='2'): '2021-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='3'): '2021-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2021', quarter='4'): '2021-10-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='1'): '2022-01-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='2'): '2022-04-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='3'): '2022-07-01_performance_mobile_tiles.parquet',\n OoklaQuarter(type='mobile', year='2022', quarter='4'): '2022-10-01_performance_mobile_tiles.parquet'}\n\n\n\n\nDownloading an ookla file to a directory\n\n\n\n\n\n\nWarning\n\n\n\nOokla files are &gt;300MB and can reach ~550MB. Download with caution\n\n\n\n!mkdir -p ../test_dir\ndownloaded_file = ookla.download_ookla_file(\n    type_=\"fixed\", year=\"2019\", quarter=\"1\", directory=\"../test_dir\"\n)\ndownloaded_file\n\nPath('../test_dir/2019-01-01_performance_fixed_tiles.parquet')\n\n\n\n\nLoading ookla data\n\ndf = pd.read_parquet(downloaded_file)\ndf.head()\n\n\n\n\n\n\n\n\nquadkey\ntile\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\n\n\n\n\n0\n0022133222312322\nPOLYGON((-160.02685546875 70.6435894914449, -1...\n8763\n3646\n45\n1\n1\n\n\n1\n0022133222330013\nPOLYGON((-160.032348632812 70.6399478155463, -...\n9195\n3347\n43\n1\n1\n\n\n2\n0022133222330023\nPOLYGON((-160.043334960938 70.6363054807905, -...\n6833\n3788\n42\n1\n1\n\n\n3\n0022133222330100\nPOLYGON((-160.02685546875 70.6417687358462, -1...\n8895\n3429\n43\n2\n2\n\n\n4\n0022320121121332\nPOLYGON((-166.739501953125 68.3526207780586, -...\n4877\n935\n45\n3\n2"
  },
  {
    "objectID": "area_zonal_stats.html",
    "href": "area_zonal_stats.html",
    "title": "Area Zonal Stats",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "area_zonal_stats.html#test-data",
    "href": "area_zonal_stats.html#test-data",
    "title": "Area Zonal Stats",
    "section": "Test data",
    "text": "Test data\n\nSimple squares\nGiven an aoi (simple_aoi) and geodataframe containing sample data (simple_data)\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n\n\n3\nPOLYGON ((3.000 0.000, 3.000 1.000, 4.000 1.00...\n\n\n4\nPOLYGON ((4.000 0.000, 4.000 1.000, 5.000 1.00...\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOLYGON ((0.250 0.000, 0.250 1.000, 1.250 1.00...\n100\n20.0\n\n\n1\nPOLYGON ((1.250 0.000, 1.250 1.000, 2.250 1.00...\n200\n10.0\n\n\n2\nPOLYGON ((2.250 0.000, 2.250 1.000, 3.250 1.00...\n300\n5.0\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(\n    ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\", \"orange\", \"purple\"]\n)\n\n\n\n\nThe red,green,blue, orange and purple outlines are the 5 regions of interest (aoi) while the orange,brown, purple areas are the data areas.\n\nempty_aoi_results = create_area_zonal_stats(simple_aoi, simple_data)\n\n\nempty_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n\n\n3\nPOLYGON ((3.000 0.000, 3.000 1.000, 4.000 1.00...\n0.25\n\n\n4\nPOLYGON ((4.000 0.000, 4.000 1.000, 5.000 1.00...\n0.00\n\n\n\n\n\n\n\n\nsimple_aoi_results = create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=\"count\", output=\"sample_count\"),\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(func=[\"mean\", \"max\", \"min\", \"std\"], column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 61.4 ms, sys: 0 ns, total: 61.4 ms\nWall time: 58.1 ms\n\n\n\nsimple_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\nsample_count\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n1.0\n75.0\n1.0\n15.000\n20.0\n0.0\nNaN\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n2.0\n175.0\n2.0\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n2.0\n275.0\n2.0\n3.125\n10.0\n5.0\n3.535534\n\n\n3\nPOLYGON ((3.000 0.000, 3.000 1.000, 4.000 1.00...\n0.25\n1.0\n75.0\n1.0\n1.250\n5.0\n0.0\nNaN\n\n\n4\nPOLYGON ((4.000 0.000, 4.000 1.000, 5.000 1.00...\n0.00\nNaN\nNaN\nNaN\nNaN\nNaN\n0.0\nNaN\n\n\n\n\n\n\n\n\nsimple_aoi_results.population_sum.sum(axis=None)\n\n600.0\n\n\n\ncorrected_aoi_results = create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(\n            func=[\"mean\", \"imputed_mean\", \"raw_max\", \"raw_min\", \"raw_std\"],\n            column=\"internet_speed\",\n            output=[\n                \"internet_speed_mean\",\n                \"internet_speed_imputed_mean\",\n                \"internet_speed_max\",\n                \"internet_speed_min\",\n                \"internet_speed_std\",\n            ],\n        ),\n    ],\n    fix_min=False,\n)\n\nCPU times: user 53.9 ms, sys: 956 µs, total: 54.9 ms\nWall time: 50.1 ms\n\n\n\ncorrected_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_imputed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n75.0\n1.0\n15.000\n20.000\n20.0\n20.0\nNaN\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n175.0\n2.0\n6.250\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n275.0\n2.0\n3.125\n3.125\n10.0\n5.0\n3.535534\n\n\n3\nPOLYGON ((3.000 0.000, 3.000 1.000, 4.000 1.00...\n0.25\n75.0\n1.0\n1.250\n5.000\n5.0\n5.0\nNaN\n\n\n4\nPOLYGON ((4.000 0.000, 4.000 1.000, 5.000 1.00...\n0.00\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n\n\n\n\n\n\naois_no_nas = create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\", fillna=[True, True]),\n        dict(\n            func=[\"mean\", \"imputed_mean\", \"raw_max\", \"raw_min\", \"raw_std\"],\n            column=\"internet_speed\",\n            output=[\n                \"internet_speed_mean\",\n                \"internet_speed_imputed_mean\",\n                \"internet_speed_max\",\n                \"internet_speed_min\",\n                \"internet_speed_std\",\n            ],\n            fillna=[True, True, True, True, True],\n        ),\n    ],\n    fix_min=False,\n)\n\nCPU times: user 34 ms, sys: 12.1 ms, total: 46 ms\nWall time: 42.6 ms\n\n\n\naois_no_nas\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_imputed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n75.0\n1.0\n15.000\n20.000\n20.0\n20.0\n0.000000\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n175.0\n2.0\n6.250\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n275.0\n2.0\n3.125\n3.125\n10.0\n5.0\n3.535534\n\n\n3\nPOLYGON ((3.000 0.000, 3.000 1.000, 4.000 1.00...\n0.25\n75.0\n1.0\n1.250\n5.000\n5.0\n5.0\n0.000000\n\n\n4\nPOLYGON ((4.000 0.000, 4.000 1.000, 5.000 1.00...\n0.00\n0.0\n0.0\n0.000\n0.000\n0.0\n0.0\n0.000000"
  },
  {
    "objectID": "datasets_nightlights.html",
    "href": "datasets_nightlights.html",
    "title": "Night Lights",
    "section": "",
    "text": "source\n\nget_eog_access_token\n\n get_eog_access_token (username, password, save_token=False,\n                       save_path='~/.eog_creds/eog_access_token',\n                       set_env=True, env_token_var='EOG_ACCESS_TOKEN')\n\n\nsource\n\n\nclear_eog_access_token\n\n clear_eog_access_token (save_file='~/.eog_creds/eog_access_token',\n                         env_var='EOG_ACCESS_TOKEN', clear_file=True,\n                         clear_env=True)\n\n\nsource\n\n\nsetup_eog_auth_headers\n\n setup_eog_auth_headers (headers, access_token, env_var, creds_file)\n\n\nsource\n\n\ndownload_url\n\n download_url (url, dest=None, access_token=None, headers=None,\n               timeout=None, show_progress=True, chunksize=1048576,\n               env_var='EOG_ACCESS_TOKEN',\n               creds_file='~/.eog_creds/eog_access_token')\n\nDownload url to dest and show progress\n\nsource\n\n\nunzip_eog_gzip\n\n unzip_eog_gzip (gz_file, dest=None, delete_src=False)\n\n\nsource\n\n\nclip_raster\n\n clip_raster (input_raster_file, dest, bounds, buffer=None)\n\n\nsource\n\n\nmake_url\n\n make_url (year, viirs_data_type='average',\n           ntlights_base_url='https://eogdata.mines.edu/nighttime_light',\n           version='v21', product='annual', coverage='global',\n           process_suffix='c202205302300', vcmcfg='vcmslcfg')\n\n\nsource\n\n\nmake_clip_hash\n\n make_clip_hash (year, bounds, viirs_data_type='average', version='v21',\n                 product='annual', coverage='global',\n                 process_suffix='c202205302300', vcmcfg='vcmslcfg')\n\n\nsource\n\n\ngenerate_clipped_raster\n\n generate_clipped_raster (year, bounds, dest, viirs_data_type='average',\n                          version='v21', product='annual',\n                          coverage='global',\n                          cache_dir='~/.cache/geowrangler2/nightlights',\n                          process_suffix='c202205302300',\n                          vcmcfg='vcmslcfg')\n\n\nsource\n\n\ngenerate_clipped_metadata\n\n generate_clipped_metadata (year, bounds, viirs_data_type, version,\n                            product, coverage, clip_cache_dir,\n                            process_suffix, vcmcfg)\n\n\nsource\n\n\nget_clipped_raster\n\n get_clipped_raster (year, bounds, viirs_data_type='average',\n                     version='v21', product='annual', coverage='global',\n                     cache_dir='~/.cache/geowrangler2/nightlights',\n                     process_suffix='c202205302300', vcmcfg='vcmslcfg')"
  },
  {
    "objectID": "vector_to_raster_mask.html",
    "href": "vector_to_raster_mask.html",
    "title": "Vector to Raster mask",
    "section": "",
    "text": "from rasterio import features\nfrom rasterio.plot import show\nfrom rasterio.windows import Window, transform\nsource"
  },
  {
    "objectID": "vector_to_raster_mask.html#test-data",
    "href": "vector_to_raster_mask.html#test-data",
    "title": "Vector to Raster mask",
    "section": "Test data",
    "text": "Test data\n\nGenerating a raster mask\n\n# Get filepaths\ntiff_file = \"../data/vector_to_raster_mask_sample/cabanglasan.tif\"\nshape_file = \"../data/vector_to_raster_mask_sample/labels_20220816.gpkg\"\ntarget_file = shape_file.replace(\"gpkg\", \"tiff\")\n\nGiven a raster image of a certain area that will be masked to use as a reference and a shape file that contains that area. Note that the shape file must include a column that contains labels/categories.\n\nsgdf = gpd.read_file(shape_file)\nsgdf.head(3)\n\n\n\n\n\n\n\n\nyear\nlabel\nuid\nADM3_EN\nADM3_PCODE\nADM2_EN\nADM2_PCODE\nADM1_EN\nADM1_PCODE\ngeometry\n\n\n\n\n0\n2017.0\nmining\n72_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95961 9.03303 0.00000, 1...\n\n\n1\n2017.0\nmining\n71_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95507 9.03809 0.00000, 1...\n\n\n2\n2017.0\nmining\n70_2017_mining\nSofronio Española\nPH175324000\nPalawan\nPH175300000\nRegion IV-B\nPH170000000\nMULTIPOLYGON Z (((117.95663 9.03869 0.00000, 1...\n\n\n\n\n\n\n\nAnd a dictionary with the labels and assigned values to be used in creating a mask\n\nlabels = {\n    \"mining\": 1,\n    \"neg\": 2,\n    \"agriculture\": 3,\n    \"product_extraction\": 4,\n    \"kaingin\": 5,\n    \"biophysical\": 6,\n}\n\nInput them in the generate_mask function to create a raster mask of the same dimension as the reference raster image\n\n# Generate masks for a file\nmasks, grids, values = generate_mask(\n    tiff_file=tiff_file,\n    shape_file=shape_file,\n    output_file=target_file,\n    labels_column=\"label\",\n    labels_dict=labels,\n    plot=True,\n)\n\n\n\n\n\nmasks\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)\n\n\n\ngrids\n\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]], dtype=uint16)\n\n\n\nvalues\n\n{'mining': 1,\n 'neg': 2,\n 'agriculture': 3,\n 'product_extraction': 4,\n 'kaingin': 5,\n 'biophysical': 6}"
  },
  {
    "objectID": "tutorial.raster_to_df.html",
    "href": "tutorial.raster_to_df.html",
    "title": "Raster to Dataframe Tutorial",
    "section": "",
    "text": "A basic introduction to Vector to Raster mask and Raster to Dataframe."
  },
  {
    "objectID": "tutorial.raster_to_df.html#basic-usage",
    "href": "tutorial.raster_to_df.html#basic-usage",
    "title": "Raster to Dataframe Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate a raster mask from a reference TIF image based on the labels assigned to certain regions of the area. The generated raster mask can also be used to convert the raster to a dataframe with respect to their assigned labels.\nTerms: * raster mask - processed image wherein some parts of it are set to no value or in other words hidden * labels - parts of an area within the satellite image are categorized as such. Examples are mining, agriculture, etc.\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport geowrangler2.vector_to_raster_mask as vrm\nimport geowrangler2.raster_to_dataframe as rdf\n\n\nfrom rasterio import features\nfrom rasterio.plot import show\nfrom rasterio.windows import Window, transform\n\n\nLoad reference raster image and shape file\nThe shape file that should be loaded should contain a column that consists of labels.\n\ntiff_file = \"../data/vector_to_raster_mask_sample/cabanglasan.tif\"\nshape_file = \"../data/vector_to_raster_mask_sample/labels_20220816.gpkg\"\ntarget_file = shape_file.replace(\"gpkg\", \"tiff\")\n\nWe create a dictionary of our target labels that we want to create a raster mask for.\n\nlabels = {\n    \"mining\": 1,\n    \"neg\": 2,\n    \"agriculture\": 3,\n    \"product_extraction\": 4,\n    \"kaingin\": 5,\n    \"biophysical\": 6,\n}\n\n\n\nGenerate raster mask\nTo create the mask we input the reference raster image, shape file with labels, and the dictionary with our target labels into the function.\n\n# Generate masks for a file\nmasks, grids, values = vrm.generate_mask(\n    tiff_file=tiff_file,\n    shape_file=shape_file,\n    output_file=target_file,\n    labels_column=\"label\",\n    labels_dict=labels,\n    plot=True,\n)\n\n\n\n\n\n\nLoad rasters and the outputed raster mask\n\n# no_test\ntiff_files = [\n    \"../data/vector_to_raster_mask_sample/cabanglasan.tif\",\n]\nmask_file = \"../data/vector_to_raster_mask_sample/labels_20220816.tiff\"\n\n\n\nConvert raster to dataframe\nTo convert raster/s to a dataframe, we just need to input the images into the function and add the mask file. The mask file will be used to create the last column label in the dataframe. The result is a tabular dataset that contains the Band values per raster image and their labels.\n\ndata = rdf.read_bands(tiff_files, mask_file)\n\n\ndata\n\n\n\n\n\n\n\n\nB1_0\nB2_0\nB3_0\nB4_0\nB5_0\nB6_0\nB7_0\nB8_0\nB9_0\nB10_0\nB11_0\nB12_0\nlabel\n\n\n\n\n0\n0.1198\n0.09635\n0.09330\n0.0698\n0.10665\n0.20250\n0.2490\n0.23525\n0.28125\n0.0377\n0.19925\n0.1002\n0\n\n\n1\n0.1198\n0.09580\n0.09245\n0.0708\n0.10665\n0.20250\n0.2490\n0.23925\n0.28125\n0.0377\n0.19925\n0.1002\n0\n\n\n2\n0.1148\n0.09420\n0.09460\n0.0707\n0.10380\n0.20395\n0.2478\n0.23150\n0.27165\n0.0385\n0.18240\n0.0902\n0\n\n\n3\n0.1148\n0.09190\n0.08850\n0.0631\n0.10380\n0.20395\n0.2478\n0.23300\n0.27165\n0.0385\n0.18240\n0.0902\n0\n\n\n4\n0.1148\n0.09350\n0.09080\n0.0643\n0.10565\n0.20830\n0.2466\n0.24205\n0.26990\n0.0385\n0.18050\n0.0894\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n775824\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775825\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775826\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775827\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n775828\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.00000\n0.0000\n0.00000\n0.0000\n0\n\n\n\n\n775829 rows × 13 columns\n\n\n\nChecking the label column we can see that the TIF image that we converted does not contain the desired labels.\n\ndata[\"label\"].unique()\n\narray([0], dtype=uint16)"
  },
  {
    "objectID": "raster_process.html",
    "href": "raster_process.html",
    "title": "Raster Processing",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "raster_process.html#download-raster",
    "href": "raster_process.html#download-raster",
    "title": "Raster Processing",
    "section": "Download raster",
    "text": "Download raster\n\ninput_image = \"../data/phl_ppp_2020_constrained.tif\"\n\n\nraster = rio.open(input_image)\nraster.meta\n\n{'driver': 'GTiff',\n 'dtype': 'float32',\n 'nodata': -99999.0,\n 'width': 11613,\n 'height': 19781,\n 'count': 1,\n 'crs': CRS.from_epsg(4326),\n 'transform': Affine(0.0008333333299750276, 0.0, 116.927916214,\n        0.0, -0.0008333333300136493, 21.070416784)}\n\n\n\nshow(raster.read(1), cmap=\"plasma\", transform=raster.transform)\n\n\n\n\n&lt;AxesSubplot:&gt;"
  },
  {
    "objectID": "raster_process.html#define-bounding-box",
    "href": "raster_process.html#define-bounding-box",
    "title": "Raster Processing",
    "section": "Define bounding box",
    "text": "Define bounding box\n\nbbox = (120.888062, 14.394778, 121.199112, 14.705822)\n\n\ncircle_gdf\n\n\n\n\n\n\n\n\nlat\nlon\ngeometry\n\n\n\n\n0\n14.599512\n120.984222\nPOLYGON ((121.98422 14.59951, 121.97941 14.501...\n\n\n\n\n\n\n\n\nprint(circle_gdf.crs)\n\nepsg:4326\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ncircle_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\n\nax\n\n&lt;AxesSubplot:&gt;"
  },
  {
    "objectID": "raster_process.html#crop-a-raster-without-masking",
    "href": "raster_process.html#crop-a-raster-without-masking",
    "title": "Raster Processing",
    "section": "Crop a raster without masking",
    "text": "Crop a raster without masking\n\noutput_folder = Path(\"../data\")\n\n\nquery_window_by_gdf(input_image, output_folder, circle_gdf, mask=False)\n\n../data/output_0.tif\n\n\n\nwith rio.open(output_folder / \"output_0.tif\") as dst:\n    fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n\n    show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)\n    circle_gdf.plot(facecolor=\"none\", edgecolor=\"yellow\", ax=ax)\n    print(dst.read(1))\nax\n\n[[-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n ...\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]\n [-99999. -99999. -99999. ... -99999. -99999. -99999.]]\n\n\n&lt;AxesSubplot:&gt;"
  },
  {
    "objectID": "raster_process.html#crop-a-raster-with-masking",
    "href": "raster_process.html#crop-a-raster-with-masking",
    "title": "Raster Processing",
    "section": "Crop a raster with masking",
    "text": "Crop a raster with masking"
  },
  {
    "objectID": "raster_process.html#crop-on-multiple-geometries-at-once",
    "href": "raster_process.html#crop-on-multiple-geometries-at-once",
    "title": "Raster Processing",
    "section": "Crop on multiple geometries at once",
    "text": "Crop on multiple geometries at once\n\ngrid_generator = grids.SquareGridGenerator(100_000)\n\n\ngrid_gdf = grid_generator.generate_grid(circle_gdf)\ngrid_gdf[\"name\"] = (\n    \"gridxy-\" + grid_gdf[\"x\"].astype(str) + \"-\" + grid_gdf[\"y\"].astype(str)\n)\n\n\ngrid_gdf\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nname\n\n\n\n\n0\n0\n0\nPOLYGON ((119.98422 13.59951, 120.88254 13.599...\ngridxy-0-0\n\n\n1\n0\n1\nPOLYGON ((119.98422 14.47100, 120.88254 14.471...\ngridxy-0-1\n\n\n2\n0\n2\nPOLYGON ((119.98422 15.33908, 120.88254 15.339...\ngridxy-0-2\n\n\n3\n1\n0\nPOLYGON ((120.88254 13.59951, 121.78085 13.599...\ngridxy-1-0\n\n\n4\n1\n1\nPOLYGON ((120.88254 14.47100, 121.78085 14.471...\ngridxy-1-1\n\n\n5\n1\n2\nPOLYGON ((120.88254 15.33908, 121.78085 15.339...\ngridxy-1-2\n\n\n6\n2\n0\nPOLYGON ((121.78085 13.59951, 122.67917 13.599...\ngridxy-2-0\n\n\n7\n2\n1\nPOLYGON ((121.78085 14.47100, 122.67917 14.471...\ngridxy-2-1\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(1, 1, figsize=(4, 8))\nshow(raster.read(1), cmap=\"viridis\", ax=ax, transform=raster.transform)\ngrid_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"yellow\")\n\nax\n\n&lt;AxesSubplot:&gt;\n\n\n\n\n\n\nquery_window_by_gdf(input_image, output_folder, grid_gdf, name_col=\"name\", mask=False)\n\n../data/gridxy-0-0.tif\n../data/gridxy-0-1.tif\n../data/gridxy-0-2.tif\n../data/gridxy-1-0.tif\n../data/gridxy-1-1.tif\n../data/gridxy-1-2.tif\n../data/gridxy-2-0.tif\n../data/gridxy-2-1.tif\n\n\n\nfor name in grid_gdf[\"name\"]:\n    image_path = output_folder / (name + \".tif\")\n    with rio.open(image_path) as dst:\n        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n        ax.set_title(image_path)\n        show(dst.read(1), cmap=\"viridis\", ax=ax, transform=dst.transform)"
  },
  {
    "objectID": "raster_process.html#crop-on-cloud-optimized-geotiff",
    "href": "raster_process.html#crop-on-cloud-optimized-geotiff",
    "title": "Raster Processing",
    "section": "Crop on cloud optimized geotiff",
    "text": "Crop on cloud optimized geotiff"
  },
  {
    "objectID": "datasets_utils.html",
    "href": "datasets_utils.html",
    "title": "Datasets Utils",
    "section": "",
    "text": "source\n\nurlretrieve\n\n urlretrieve (url, filename, headers=None, reporthook=None, timeout=None,\n              chunksize=8192)\n\nSame as urllib.request.urlretrieve but also works with Request objects\n\nsource\n\n\nmake_report_hook\n\n make_report_hook (show_progress)"
  },
  {
    "objectID": "distance_zonal_stats.html",
    "href": "distance_zonal_stats.html",
    "title": "Distance Zonal Stats",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "distance_zonal_stats.html#test-data",
    "href": "distance_zonal_stats.html#test-data",
    "title": "Distance Zonal Stats",
    "section": "Test data",
    "text": "Test data\n\nSimple squares\nGiven an aoi (simple_aoi) and geodataframe containing sample data (simple_data)\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOLYGON ((0.250 0.000, 0.250 1.000, 1.250 1.00...\n100\n20.0\n\n\n1\nPOLYGON ((1.250 0.000, 1.250 1.000, 2.250 1.00...\n200\n10.0\n\n\n2\nPOLYGON ((2.250 0.000, 2.250 1.000, 3.250 1.00...\n300\n5.0\n\n\n\n\n\n\n\nWe also have simple point data which do not intersect with our AOIs.\n\nsimple_point_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOINT (0.500 3.000)\n100\n20.0\n\n\n1\nPOINT (0.500 4.000)\n600\n120.0\n\n\n2\nPOINT (0.500 5.000)\n1100\n220.0\n\n\n3\nPOINT (0.500 6.000)\n1600\n320.0\n\n\n4\nPOINT (0.500 7.000)\n2100\n420.0\n\n\n5\nPOINT (1.500 3.000)\n200\n10.0\n\n\n6\nPOINT (1.500 4.000)\n700\n110.0\n\n\n7\nPOINT (1.500 5.000)\n1200\n210.0\n\n\n8\nPOINT (1.500 6.000)\n1700\n310.0\n\n\n9\nPOINT (1.500 7.000)\n2200\n410.0\n\n\n10\nPOINT (2.500 3.000)\n300\n5.0\n\n\n11\nPOINT (2.500 4.000)\n800\n105.0\n\n\n12\nPOINT (2.500 5.000)\n1300\n205.0\n\n\n13\nPOINT (2.500 6.000)\n1800\n305.0\n\n\n14\nPOINT (2.500 7.000)\n2300\n405.0\n\n\n\n\n\n\n\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\"])\nax = simple_point_data.plot(ax=ax)\n\n\n\n\nThe red,green,blue outlines are the 3 regions of interest (aoi) while the orange,brown, purple areas are the data areas.The blue dots are data which do not intersect our AOIs.\n\nresults = create_distance_zonal_stats(\n    simple_aoi,\n    simple_point_data,\n    max_distance=7,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 32.1 ms, sys: 11 ms, total: 43.1 ms\nWall time: 36 ms\n\n\n\nresults\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n1\n100\n20.0\n2.0\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1\n200\n10.0\n2.0\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1\n300\n5.0\n2.0\n\n\n\n\n\n\n\n\nresults2 = create_distance_zonal_stats(\n    simple_aoi,\n    simple_data,\n    max_distance=1,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 38.5 ms, sys: 0 ns, total: 38.5 ms\nWall time: 35 ms\n\n\n\nresults2\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n1\n100\n20.0\n0.0\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n2\n300\n15.0\n0.0\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n2\n500\n7.5\n0.0"
  },
  {
    "objectID": "dhs.html",
    "href": "dhs.html",
    "title": "DHS Utilities",
    "section": "",
    "text": "source\n\nload_column_config\n\n load_column_config (country:str)\n\nGet predined column mapping for some countries. The following countries area supported: - ph Philippines - tl East Timor - mm Myanmar - kh Cambodia\n\n\n\n\nType\nDetails\n\n\n\n\ncountry\nstr\n2 letter character representing the country\n\n\nReturns\ndict\n\n\n\n\n\nsource\n\n\nload_dhs_file\n\n load_dhs_file (household_data:str)\n\nLoads household data and renames columns based on variable labels of the file\n\n\n\n\nType\nDetails\n\n\n\n\nhousehold_data\nstr\nstr or pathlike object to the household data\n\n\nReturns\nDataFrame\n\n\n\n\n\nsource\n\n\napply_threshold\n\n apply_threshold (df:pandas.core.frame.DataFrame, columns:List[str],\n                  config:dict)\n\nApplies a threshold to a list of columns\n\n\n\n\nType\nDetails\n\n\n\n\ndf\nDataFrame\nDataframe\n\n\ncolumns\ntyping.List[str]\nList of columns to apply the threshold\n\n\nconfig\ndict\nConfig containing the min and max of each columns\n\n\nReturns\nDataFrame\n\n\n\n\n\nsource\n\n\nassign_wealth_index\n\n assign_wealth_index (asset_df:pandas.core.frame.DataFrame, use_pca=True)\n\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nasset_df\nDataFrame\n\nDataframe containg only the features to apply wealth index\n\n\nuse_pca\nbool\nTrue\nif calculating wealth index should be done via PCA or via Sigular Value Decomposition"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html",
    "href": "overview.poverty_mapping_demo.html",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "",
    "text": "The aim of this notebook is to demonstrate how geowrangler2 can be used to make the process of generating ML-ready or analytics-ready datasets from raw geospatial data easier.\nConcretely, this shows a sample workflow for a wealth estimation model trained on a dataset constructed using: * Ground Truth - DHS household clusters + wealth indices * Features - Derived from Night Time Lights, OSM POIs, and Ookla internet speeds."
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#set-up",
    "href": "overview.poverty_mapping_demo.html#set-up",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Set-up",
    "text": "Set-up\nInstall and import some libraries.\n\nfrom pathlib import Path\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport sklearn\nfrom shapely import wkt\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport geowrangler2.area_zonal_stats as azs\nimport geowrangler2.distance_zonal_stats as dzs\nimport geowrangler2.raster_zonal_stats as rzs\nimport geowrangler2.vector_zonal_stats as vzs\nfrom geowrangler2 import grids\nfrom geowrangler2.datasets import geofabrik, ookla"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#pre-requisite-manual-data-download",
    "href": "overview.poverty_mapping_demo.html#pre-requisite-manual-data-download",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Pre-requisite: Manual Data Download",
    "text": "Pre-requisite: Manual Data Download\n\n# no_test\n# download data if not yet available\n![ ! -e ../data/phl_adm0.geojson ] && curl -s -o ../data/phl_adm0.geojson https://raw.githubusercontent.com/thinkingmachines/geowrangler2/master/data/phl_adm0.geojson\n![ ! -e ../data/phl_dhs_cluster_level.csv ] && curl -s -o ../data/phl_dhs_cluster_level.csv https://raw.githubusercontent.com/thinkingmachines/geowrangler2/master/data/phl_dhs_cluster_level.csv\n![ ! -e ../data/phl_ntl.tif ] && curl -s -o ../data/phl_ntl.tif https://raw.githubusercontent.com/thinkingmachines/geowrangler2/master/data/phl_ntl.tif\n\n\nDATA_DIR = Path(\"../data/\")\n# Auto-creates the folder if it does not exist\nDATA_DIR.mkdir(parents=True, exist_ok=True)\n\nYour data directory should look something like this.\n\n\n\ndata_dir.PNG"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#data-preparation",
    "href": "overview.poverty_mapping_demo.html#data-preparation",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nDHS Ground Truth\nThe ground truth used in this demo notebook is from a DHS 2017 on-the-ground household survey conducted in the Philippines regarding the households’ socio-demographic information.\nThe file we provide is already a pre-processed version of the data that is aggregated on a household-cluster level, meaning the information cannot be tied back to any individual household. Specifically, we only provide a list of household clusters with their corresponding (jittered) GPS coordinate and DHS-computed wealth index.\nDue to the sensitive nature of the data and the DHS program terms of use, we cannot provide the raw data. You can, however, request for access to raw data yourself on the DHS website. In that case, you can use geowrangler2’s DHS processing utils help perform the said pre-processing.\nOur first step is to create a GeoDataFrame from the data.\n\n# Load ground truth data as a DataFrame first\nGROUND_TRUTH_CSV = DATA_DIR / \"phl_dhs_cluster_level.csv\"\ndf = pd.read_csv(GROUND_TRUTH_CSV)\n\n# Some of the coordinates in the data are invalid. This filters them out.\ndf = df[(df.longitude &gt; 0) & (df.latitude &gt; 0)]\n\n# Create a GeoDataFrame from the longitude, latitude columns.\ngdf = gpd.GeoDataFrame(\n    df, geometry=gpd.points_from_xy(df.longitude, df.latitude), crs=\"epsg:4326\"\n)\n\nprint(f\"There are {len(gdf):,} clusters.\")\ngdf.head()\n\nThere are 1,213 clusters.\n\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nlongitude\nlatitude\ngeometry\n\n\n\n\n0\n1\n-31881.60870\nPH201700000001\n122.109807\n6.674652\nPOINT (122.10981 6.67465)\n\n\n1\n2\n-2855.37500\nPH201700000002\n122.132027\n6.662256\nPOINT (122.13203 6.66226)\n\n\n2\n3\n-57647.04762\nPH201700000003\n122.179496\n6.621822\nPOINT (122.17950 6.62182)\n\n\n3\n4\n-54952.66667\nPH201700000004\n122.137965\n6.485298\nPOINT (122.13796 6.48530)\n\n\n5\n6\n-80701.69565\nPH201700000006\n121.916094\n6.629457\nPOINT (121.91609 6.62946)\n\n\n\n\n\n\n\nNext, we want to create a buffer around each cluster centroid that represents the area’s neighborhood. This is so we can engineer some features and characterize these neighborhoods using open data.\nThis is a design decision, but for this demo, we’ll create a circlular area with a 2km radius following the random displacement introduced by DHS to preserve household privacy.\n\n# Make sure to convert to PH crs first for the buffer in meters, and then back to WGS84\ngdf = gdf.to_crs(\"epsg:3123\")\ngdf.geometry = gdf.geometry.buffer(2000)\ngdf = gdf.to_crs(\"epsg:4326\")\n\ngdf.head(5)\n\n\n\n\n\n\n\n\nDHSCLUST\nWealth Index\nDHSID\nlongitude\nlatitude\ngeometry\n\n\n\n\n0\n1\n-31881.60870\nPH201700000001\n122.109807\n6.674652\nPOLYGON ((122.12789 6.67461, 122.12780 6.67284...\n\n\n1\n2\n-2855.37500\nPH201700000002\n122.132027\n6.662256\nPOLYGON ((122.15011 6.66221, 122.15002 6.66044...\n\n\n2\n3\n-57647.04762\nPH201700000003\n122.179496\n6.621822\nPOLYGON ((122.19758 6.62178, 122.19749 6.62001...\n\n\n3\n4\n-54952.66667\nPH201700000004\n122.137965\n6.485298\nPOLYGON ((122.15604 6.48526, 122.15595 6.48349...\n\n\n5\n6\n-80701.69565\nPH201700000006\n121.916094\n6.629457\nPOLYGON ((121.93418 6.62942, 121.93409 6.62765...\n\n\n\n\n\n\n\nWe can visualize what we’ve done so far on a map.\n\n# Uncomment the next line to display an interactive map\n# gdf.explore()\n\n\n\nDownload data and load them into memory\nNext, we’ll download some data from Ookla (internet speeds) and OSM (points of interest), which we’ll use to generate neighborhood characteristics to be used as ML features.\n\n\nOokla\nOokla has released global open data gathered from speedtests made on their platform. This gives us access to internet speed information across various geographies. In our context, this can give us a signal predictor.\nFirst, let’s download a local copy of data on fixed internet in the 1st quarter of 2019 (earliest data available).\nWe can use geowrangler2’s Ookla data utility to automatically download and cache the desired data on your machine given the type, year, and quarter.\nThis is just a simplification for the demo. In practice, you might want to aggregate data across multiple time periods or incorporate wireless data.\n\nookla_fixed_2019_q1_filepath = ookla.download_ookla_file(\n    type_=\"fixed\", year=\"2019\", quarter=\"1\"\n)\n# This is where the downloaded file is located.\n# By default this downloads to your data/ folder, but you can customize this.\nookla_fixed_2019_q1_filepath\n\nPath('data/2019-01-01_performance_fixed_tiles.parquet')\n\n\n\n# This is a function to load and do some light pre-processing on the Ookla data.\n\n\ndef load_ookla_data(filename, mask=None):\n\n    # Ookla's parquet file doesn't seem to have geo metadata so need to read through pandas first\n    ookla_df = pd.read_parquet(filename)\n    ookla_gdf = gpd.GeoDataFrame(\n        ookla_df,\n        geometry=ookla_df[\"tile\"].apply(lambda x: wkt.loads(x)),\n        crs=\"epsg:4326\",\n    )\n    ookla_gdf.drop(columns=[\"tile\"], inplace=True)\n\n    # Ookla's data files contain data for the whole world.\n    # For our case, we're retaining only tiles that intersect with the given mask.\n    # This is to speed-up any processing we do later on.\n    if mask is not None:\n        keep_cols = ookla_gdf.columns\n        ookla_gdf = ookla_gdf.sjoin(mask, how=\"inner\", predicate=\"intersects\")\n        ookla_gdf = ookla_gdf[keep_cols]\n        ookla_gdf.head()\n\n    # Convert kbps to mbps for easier reading\n    ookla_gdf[\"avg_d_mbps\"] = ookla_gdf[\"avg_d_kbps\"] / 1000\n    ookla_gdf[\"avg_u_mbps\"] = ookla_gdf[\"avg_u_kbps\"] / 1000\n\n    return ookla_gdf\n\nThe Ookla data is quite large, and takes around 5 minutes to load.\n\nookla_gdf = load_ookla_data(ookla_fixed_2019_q1_filepath, mask=gdf)\n\nCPU times: user 1min 59s, sys: 38.7 s, total: 2min 38s\nWall time: 2min 38s\n\n\n\nprint(\n    f\"{len(ookla_gdf):,} Ookla data tiles retained that intersect with our DHS cluster neighborhoods.\"\n)\nookla_gdf.head()\n\n17,245 Ookla data tiles retained that intersect with our DHS cluster neighborhoods.\n\n\n\n\n\n\n\n\n\nquadkey\navg_d_kbps\navg_u_kbps\navg_lat_ms\ntests\ndevices\ngeometry\navg_d_mbps\navg_u_mbps\n\n\n\n\n4368240\n1323011210311031\n10\n21\n126\n1\n1\nPOLYGON ((121.96472 20.45790, 121.97021 20.457...\n0.010\n0.021\n\n\n4368241\n1323011210311033\n5931\n10633\n228\n3\n2\nPOLYGON ((121.96472 20.45275, 121.97021 20.452...\n5.931\n10.633\n\n\n4368242\n1323011210311122\n13063\n9266\n218\n5\n2\nPOLYGON ((121.97021 20.45275, 121.97571 20.452...\n13.063\n9.266\n\n\n4368243\n1323011210311211\n20\n51\n130\n1\n1\nPOLYGON ((121.96472 20.44760, 121.97021 20.447...\n0.020\n0.051\n\n\n4368245\n1323011210311230\n195\n589\n114\n1\n1\nPOLYGON ((121.95923 20.43731, 121.96472 20.437...\n0.195\n0.589\n\n\n\n\n\n\n\n\n\nOSM (Open Street Maps)\nOne source of open data on points of interest is OSM. We’ll use the version of the data provided by Geofabrik vs accessing the OSM Overpass API. This allows us to not be bottlenecked by API calls.\nSimilar to Ookla, we can also use geowrangler2’s OSM data download utils to download and cache OSM data on your machine. All you have to do is specify the country you want.\nGeofabrik’s OSM data is a zip file containing different files for POIs, waterways, roads, etc. For this demo notebook, we’ll only use the POIs.\n\n# This download can take around 1-2 minutes.\nph_osm_zip_path = geofabrik.download_geofabrik_region(\"philippines\")\n\n# This line unzips the zip file if we haven't done so yet.\n!echo 'None' | unzip $ph_osm_zip_path -d data/ph_osm/\n\nArchive:  data/philippines-latest-free.shp.zip\nreplace data/ph_osm/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n\n\n\n# Uncomment the ff line to see all the available OSM files aside from POIs.\n!ls -aldh data/ph_osm/*.shp\n\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_buildings_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_landuse_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_natural_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm 763K Jan  5 17:50 data/ph_osm/gis_osm_natural_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_places_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm 1.1M Jan  5 17:50 data/ph_osm/gis_osm_places_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_pofw_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm 102K Jan  5 17:50 data/ph_osm/gis_osm_pofw_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_pois_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm 3.5M Jan  5 17:50 data/ph_osm/gis_osm_pois_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_railways_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_roads_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_traffic_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm 1.1M Jan  5 17:50 data/ph_osm/gis_osm_traffic_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_transport_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm 177K Jan  5 17:50 data/ph_osm/gis_osm_transport_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_water_a_free_1.shp\n-rw-r--r-- 1 butchtm butchtm  100 Jan  5 17:50 data/ph_osm/gis_osm_waterways_free_1.shp\n\n\n\nph_osm_pois_filepath = \"data/gis_osm_pois_free_1.shp\"\nph_osm = gpd.read_file(ph_osm_pois_filepath)\n\n\nprint(f\"There are {len(ph_osm)} OSM POIs.\")\nph_osm.head()\n\nThere are 0 OSM POIs.\n\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\ngeometry"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#feature-engineering",
    "href": "overview.poverty_mapping_demo.html#feature-engineering",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nNow that we’ve prepared the DHS data and loaded Ookla and OSM data into memory, we’re ready to generate some neighborhood features for our ML model.\nFor convenience, we’re wrapping all the feature engineering code in functions so we can re-use them later when we apply the model to the whole country.\nNote: if you are modifying the feature engineering portions, it is recommended to run the whole section end-to-end. This ensures you’re starting fresh from a new copy of the DHS clusters GeoDataFrame. This also ensures the function definitions are up-to-date, and can be re-used properly later for model rollout.\n\n# We'll make a copy of the GDF to avoid overwriting the original DHS GeoDataFrame.\ngdf_with_features = gdf.copy()\n\n\nOSM\nOur goal with OSM data is to generate neighborhood characteristics based on counts and distance to certain POIs, such as schools, hospitals, etc.\nTo do this, we utilize geowrangler2’s vector zonal stats and distance zonal stats features.\n\n# Uncomment the ff. line if you want to see the different POI classes available\n# ph_osm.fclass.sort_values().unique()\n\n\ndef generate_osm_features(aoi, osm, metric_crs=\"epsg:3123\"):\n\n    aoi = aoi.copy()\n\n    # geowrangler2: Count number of all POIs per tile\n    aoi = vzs.create_zonal_stats(\n        aoi,\n        osm,\n        overlap_method=\"intersects\",\n        aggregations=[{\"func\": \"count\", \"output\": \"poi_count\", \"fillna\": True}],\n    )\n\n    # Count specific aoi types\n    poi_types = [\"restaurant\", \"school\", \"bank\", \"supermarket\", \"mall\", \"atm\"]\n\n    for poi_type in poi_types:\n        # geowrangler2: Count with vector zonal stats\n        aoi = vzs.create_zonal_stats(\n            aoi,\n            osm[osm[\"fclass\"] == poi_type],\n            overlap_method=\"intersects\",\n            aggregations=[\n                {\"func\": \"count\", \"output\": f\"{poi_type}_count\", \"fillna\": True}\n            ],\n        )\n\n        # geowrangler2: Distance with distance zonal stats\n        col_name = f\"{poi_type}_nearest\"\n        aoi = dzs.create_distance_zonal_stats(\n            aoi.to_crs(metric_crs),\n            osm[osm[\"fclass\"] == poi_type].to_crs(metric_crs),\n            max_distance=10_000,\n            aggregations=[],\n            distance_col=col_name,\n        ).to_crs(\"epsg:4326\")\n\n        # If no POI was found within the distance limit, set the distance to a really high value\n        aoi[col_name] = aoi[col_name].fillna(value=999999)\n\n    return aoi\n\n\ngdf_with_features = generate_osm_features(gdf_with_features, ph_osm)\n\n\ngdf_with_features.head()\n\n\n\nOokla\nOur goal with Ookla data is to generate neighborhood characteristics based on internet speeds (download, upload, latency).\nTo do this, we utilize geowrangler2’s area zonal stats feature.\n\ndef generate_ookla_features(aoi, ookla_gdf, metric_crs=\"epsg:3123\"):\n\n    aoi = aoi.copy()\n\n    orig_aoi_crs = aoi.crs\n    aoi = aoi.to_crs(metric_crs)\n    ookla_gdf = ookla_gdf.to_crs(metric_crs)\n\n    # For better formatting, rename some columns\n    ookla_gdf = ookla_gdf.rename(\n        columns={\"avg_d_mbps\": \"d_mbps\", \"avg_u_mbps\": \"u_mbps\", \"avg_lat_ms\": \"lat_ms\"}\n    )\n\n    # geowrangler2: Compute stats on the various columns\n    aoi = azs.create_area_zonal_stats(\n        aoi,\n        ookla_gdf,\n        aggregations=[\n            # Count number of devices in the area\n            dict(column=\"devices\", func=[\"raw_sum\"], fillna=True),\n            # Get stats on the download speeds\n            dict(\n                column=\"d_mbps\",\n                func=[\"imputed_mean\", \"max\", \"min\", \"std\"],\n                fillna=[True, True, True, True],\n            ),\n            # Get stats on the upload speeds\n            dict(\n                column=\"u_mbps\",\n                func=[\"imputed_mean\", \"max\", \"min\", \"std\"],\n                fillna=[True, True, True, True],\n            ),\n        ],\n        # Don't include the land area that intersected as a column\n        include_intersect=False,\n        # Don't set minimum values to 0 if the neighborhood's area doesn't fully intersect with Ookla tiles.\n        fix_min=False,\n    )\n\n    aoi = aoi.fillna(value=\"0\")\n    aoi = aoi.to_crs(orig_aoi_crs)\n\n    return aoi\n\n\ngdf_with_features = generate_ookla_features(gdf_with_features, ookla_gdf)\n\n\ngdf_with_features.head()\n\n\n\nNight Time Lights\nLastly, we’ll generate features based on night time lights. geowrangler2 provides a raster zonal stats function that acts as a thin layer on top of rasterio’s rasterstats function. It provides a little convenience in terms of formatting and automatically joins back the features to your input GeoDataFrame.\n\ndef generate_ntl_features(aoi, raster_path):\n    aoi = aoi.copy()\n\n    aoi = rzs.create_raster_zonal_stats(\n        aoi,\n        raster_path,\n        aggregation=dict(\n            func=[\"mean\", \"min\", \"max\", \"std\"],\n            column=\"ntl\",\n        ),\n        extra_args=dict(nodata=0),\n    )\n\n    aoi.fillna(0, inplace=True)\n\n    return aoi\n\n\ngdf_with_features = generate_ntl_features(gdf_with_features, DATA_DIR / \"phl_ntl.tif\")\n\n\n\nVisualize the final dataset\nFinally, let’s visualize our cluster neighborhoods now with the generated features. Hover over each cluster to see its data.\n\n\n\nDHS Cluster Features (Zoomed)\n\n\n\n# Visualize the clusters with the generated features\n# gdf_with_features.explore()"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#prepare-data-into-x-y-and-generate-traintest-partitions",
    "href": "overview.poverty_mapping_demo.html#prepare-data-into-x-y-and-generate-traintest-partitions",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Prepare data into X, y and generate train/test partitions",
    "text": "Prepare data into X, y and generate train/test partitions\n\n# For convenience, store the list of features in a variable. Remove all extraneous columns.\nfeature_cols = gdf_with_features.drop(\n    columns=[\"DHSCLUST\", \"DHSID\", \"Wealth Index\", \"longitude\", \"latitude\", \"geometry\"]\n).columns\n\n# Separate data (X) and the target (y)\nX = gdf_with_features[feature_cols]\ny = gdf_with_features[\"Wealth Index\"]\n\n# Bin y into 5 buckets for stratification when splitting the dataset\ncat_y = pd.cut(y, bins=5, labels=list(range(1, 6)))\n\n# Generate train and test partitions\nX_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n    X, y, test_size=0.2, random_state=2022, stratify=cat_y\n)\n\n\nX_train.head()\n\n\ny_train.head()"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#evaluation-function",
    "href": "overview.poverty_mapping_demo.html#evaluation-function",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Evaluation Function",
    "text": "Evaluation Function\nWe define an evaluation function that computes R^2 and makes a plot of the actual vs predicted values.\n\ndef evaluate(model, X_train, X_test, y_train, y_test):\n\n    # R^2\n    train_predictions = model.predict(X_train)\n    print(\"Train R2 score:\", sklearn.metrics.r2_score(y_train, train_predictions))\n\n    test_predictions = model.predict(X_test)\n    print(\"Test R2 score:\", sklearn.metrics.r2_score(y_test, test_predictions))\n\n    # Plot\n\n    # Train and test predictions vs actual values\n    plt.scatter(train_predictions, y_train, label=\"Train samples\", c=\"#d95f02\")\n    plt.scatter(test_predictions, y_test, label=\"Test samples\", c=\"#7570b3\")\n\n    # Identity line\n    xpoints = ypoints = plt.xlim()\n    plt.plot(\n        xpoints, ypoints, linestyle=\"--\", color=\"k\", lw=3, scalex=False, scaley=False\n    )\n\n    # Labels and legends\n    plt.xlabel(\"Predicted value\")\n    plt.ylabel(\"True value\")\n    plt.legend()\n    plt.tight_layout()\n    plt.show()"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#fit-and-evaluate-model",
    "href": "overview.poverty_mapping_demo.html#fit-and-evaluate-model",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Fit and Evaluate Model",
    "text": "Fit and Evaluate Model\nFor ML modelling, let’s fit a simple random forest regressor.\nAs mentioned, we are keeping the ML modelling as simple as possible in this notebook. This is definitely not the best-performing wealth estimation model out there, but should be decent enough for demo purposes.\n\nmodel = RandomForestRegressor()\nmodel.fit(X_train, y_train)\nevaluate(model, X_train, X_test, y_train, y_test)"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#generate-country-wide-tiles",
    "href": "overview.poverty_mapping_demo.html#generate-country-wide-tiles",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Generate country-wide tiles",
    "text": "Generate country-wide tiles\nFirst, we need to split the country up into smaller areas.\nThat usually means generating grid tiles or hex tiles for your area of interest. In this notebook, we’ll generate Bing tiles at zoom level 13 (which has the closest area to our 2km neighborhoods in training).\ngeowrangler2 provides various grid generation utilities for these different scenarios.\n\n# Read in the admin boundary for PHL.\n# This file is a simplified version of the admin boundary to make the file size smaller and load times faster.\nphl_adm = gpd.read_file(f\"{DATA_DIR}/phl_adm0.geojson\")\n\n# Uncomment this line if you want to visualize it\n# phl_adm.explore()\n\nThe generation can take around 1-2 minutes.\n\nphl_tiles = grids.BingTileGridGenerator(13).generate_grid(phl_adm)\nprint(f\"There are {len(phl_tiles):,} tiles.\")\nphl_tiles.head()"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#feature-engineering-1",
    "href": "overview.poverty_mapping_demo.html#feature-engineering-1",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Feature Engineering",
    "text": "Feature Engineering\nThis part is simpler, as we’re just re-using the feature engineering functions we previously created. Note though that we are generating features for a bigger area, so the runtime is a little longer (in total should be within 2 minutes).\n\nphl_tiles_with_features = phl_tiles.copy()\n\n\nphl_tiles_with_features = generate_osm_features(phl_tiles_with_features, ph_osm)\n\n\nphl_tiles_with_features = generate_ookla_features(phl_tiles_with_features, ookla_gdf)\n\n\nphl_tiles_with_features = generate_ntl_features(\n    phl_tiles_with_features, f\"{DATA_DIR}/phl_ntl.tif\"\n)"
  },
  {
    "objectID": "overview.poverty_mapping_demo.html#make-predictions-and-viz-output",
    "href": "overview.poverty_mapping_demo.html#make-predictions-and-viz-output",
    "title": "Explore Poverty Mapping Machine Learning Models",
    "section": "Make predictions and viz output",
    "text": "Make predictions and viz output\nFinally, we are ready to apply the model and make predictions throughout the whole country. We can also visualize it on a Cholorpleth map.\n\nphl_tiles_with_features[\"predicted_wealth_index\"] = model.predict(\n    phl_tiles_with_features[feature_cols]\n)\n\n\ndef viz_chloropleth(gdf, target_feature=\"predicted_wealth_index\"):\n\n    map = folium.Map(location=[14.6091, 121.0223], width=1000, height=800, zoom_start=7)\n    subset = gdf.copy()\n    subset[\"id\"] = list(range(len(subset)))\n\n    folium.Choropleth(\n        geo_data=subset,\n        data=subset,\n        name=\"Wealth Predictions\",\n        columns=[\"id\", target_feature],\n        key_on=\"feature.properties.id\",\n        fill_color=\"Spectral\",\n        legend_name=target_feature,\n    ).add_to(map)\n\n    return map\n\nVisualize the output\n\n\n\nPredicted Wealth Index Rollout (Philippines)\n\n\n\n# Uncomment the line below to visualize rollout\n# viz_chloropleth(phl_tiles_with_features)"
  },
  {
    "objectID": "datasets_geofabrik.html",
    "href": "datasets_geofabrik.html",
    "title": "Datasets Geofabrik",
    "section": "",
    "text": "source\n\nlist_geofabrik_regions\n\n list_geofabrik_regions ()\n\nGet list of regions from geofabrik index\n\nsource\n\n\nget_osm_download_url\n\n get_osm_download_url (region, year=None)\n\n\nsource\n\n\nget_download_filepath\n\n get_download_filepath (url, directory)\n\n\nsource\n\n\ndownload_geofabrik_region\n\n download_geofabrik_region (region:str, directory:str='data/',\n                            overwrite=False, year=None,\n                            show_progress=True, chunksize=8192)\n\nDownload geofabrik region to path\n\nsource\n\n\ndownload_osm_region_data\n\n download_osm_region_data (region, year=None,\n                           cache_dir='~/.cache/geowrangler2',\n                           use_cache=True, chunksize=8192,\n                           show_progress=True)\n\n\nsource\n\n\nOsmDataManager\n\n OsmDataManager (cache_dir='~/.cache/geowrangler2')\n\nAn instance of this class provides convenience functions for loading and caching OSM data\n\nsource\n\n\nOsmDataManager.load_pois\n\n OsmDataManager.load_pois (region, year=None, use_cache=True,\n                           chunksize=1048576, show_progress=True)\n\n\nsource\n\n\nOsmDataManager.load_roads\n\n OsmDataManager.load_roads (region, year=None, use_cache=True,\n                            chunksize=1048576, show_progress=True)"
  },
  {
    "objectID": "tutorial.distance_zonal_stats.html",
    "href": "tutorial.distance_zonal_stats.html",
    "title": "Vector Distance Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to Vector Distance Zonal Stats"
  },
  {
    "objectID": "tutorial.distance_zonal_stats.html#basic-usage",
    "href": "tutorial.distance_zonal_stats.html#basic-usage",
    "title": "Vector Distance Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate area zonal stats for a GeoDataframe containing areas of interest with a vector data source with the nearest distance.\n\n\n\n\n\n\nNote\n\n\n\nthe data geometries can be points, lines or areas with distance computed from the closest points on both the aoi and the data source. Both the aoi and the data source must be projected using a “planar” CRS.\n\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nfrom shapely.geometry import Point\n\nimport geowrangler2.distance_zonal_stats as dzs\n\n\nSimple Grid AOIs and Nearby POI/Area Data Example\n\nsimple_aoi = gpd.read_file(\"../data/simple_planar_aoi.geojson\")\nsimple_data = gpd.read_file(\"../data/simple_planar_data.geojson\")\n\n\nsimple_point_data = make_point_df(3, 5, offset_x=0.5, offset_y=3.0)\n\nGiven an aoi (simple_aoi), a sample area data source (simple_data), and a sample point data source\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\npopulation\ninternet_speed\ngeometry\n\n\n\n\n0\n100\n20.0\nPOLYGON ((0.250 0.000, 0.250 1.000, 1.250 1.00...\n\n\n1\n200\n10.0\nPOLYGON ((1.250 0.000, 1.250 1.000, 2.250 1.00...\n\n\n2\n300\n5.0\nPOLYGON ((2.250 0.000, 2.250 1.000, 3.250 1.00...\n\n\n\n\n\n\n\n\nsimple_point_data\n\n\n\n\n\n\n\n\ngeometry\npopulation\ninternet_speed\n\n\n\n\n0\nPOINT (0.500 3.000)\n100\n20.0\n\n\n1\nPOINT (0.500 4.000)\n600\n120.0\n\n\n2\nPOINT (0.500 5.000)\n1100\n220.0\n\n\n3\nPOINT (0.500 6.000)\n1600\n320.0\n\n\n4\nPOINT (0.500 7.000)\n2100\n420.0\n\n\n5\nPOINT (1.500 3.000)\n200\n10.0\n\n\n6\nPOINT (1.500 4.000)\n700\n110.0\n\n\n7\nPOINT (1.500 5.000)\n1200\n210.0\n\n\n8\nPOINT (1.500 6.000)\n1700\n310.0\n\n\n9\nPOINT (1.500 7.000)\n2200\n410.0\n\n\n10\nPOINT (2.500 3.000)\n300\n5.0\n\n\n11\nPOINT (2.500 4.000)\n800\n105.0\n\n\n12\nPOINT (2.500 5.000)\n1300\n205.0\n\n\n13\nPOINT (2.500 6.000)\n1800\n305.0\n\n\n14\nPOINT (2.500 7.000)\n2300\n405.0\n\n\n\n\n\n\n\nIn order correctly compute distances from the aoi to the data sources, we need to make sure that the aoi, data and point data geodataframes are using a planar CRS (i.e. gdf.crs.is_geographic == False)\n\nsimple_aoi.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsimple_data.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsimple_point_data.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nWe have an aoi (simple_aoi) and geodataframe containing sample data (simple_data) that overlaps the aoi. We also have simple point data which do not intersect with our AOIs.\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\"])\nax = simple_point_data.plot(ax=ax)\n\n\n\n\nThe red,green,blue outlines are the 3 regions of interest (aoi) while the orange,brown, purple areas are the data areas.The blue dots are data which do not intersect our AOIs.\n\nresults = dzs.create_distance_zonal_stats(\n    simple_aoi,\n    simple_point_data,\n    max_distance=7,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 50.6 ms, sys: 0 ns, total: 50.6 ms\nWall time: 47.8 ms\n\n\nThe zonal stats computed for the point data only includes those points nearest to each aoi. The data geometries within nearest distance (within 7.0 m) are the only ones considered.\n\n\n\n\n\n\nNote\n\n\n\nSetting the max_distance to None or a large value can cause a possible slowdown for large datasets. See this Geopandas reference for more details.\n\n\n\nresults\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n1\n100\n20.0\n2.0\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1\n200\n10.0\n2.0\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1\n300\n5.0\n2.0\n\n\n\n\n\n\n\nData areas and geometries which overlap the aoi areas have a distance of 0.0 and are always the nearest geometries.\n\nresults2 = dzs.create_distance_zonal_stats(\n    simple_aoi,\n    simple_data,\n    max_distance=1,\n    aggregations=[\n        dict(func=\"count\"),\n        dict(func=\"sum\", column=\"population\"),\n        dict(func=\"mean\", column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 33.2 ms, sys: 1.29 ms, total: 34.5 ms\nWall time: 29.5 ms\n\n\n\nresults2\n\n\n\n\n\n\n\n\ngeometry\nindex_count\npopulation_sum\ninternet_speed_mean\nnearest\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n1\n100\n20.0\n0.0\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n2\n300\n15.0\n0.0\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n2\n500\n7.5\n0.0\n\n\n\n\n\n\n\n\n\nCustom Grids and POIs Example\n\nregion3_admin_grids = gpd.read_file(\"../data/region3_admin_grids.geojson\")\n\nCPU times: user 97.8 ms, sys: 29.2 ms, total: 127 ms\nWall time: 100 ms\n\n\n\nregion34ncr_osm_pois = gpd.read_file(\"../data/region34ncr_osm_pois.geojson\")\n\nCPU times: user 115 ms, sys: 365 µs, total: 115 ms\nWall time: 113 ms\n\n\n\nax = plt.axes()\nax = region34ncr_osm_pois.plot(ax=ax)\nax = region3_admin_grids.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\")\n\n\n\n\n\nregion3_admin_grids = region3_admin_grids.to_crs(\"EPSG:3857\")  # convert to planar\nregion34ncr_osm_pois = region34ncr_osm_pois.to_crs(\"EPSG:3857\")\n\n\nregion34ncr_osm_pois\n\n\n\n\n\n\n\n\nosm_id\ncode\nfclass\nname\nBARANGAY_CODE\ngeometry\n\n\n\n\n0\n311568428\n2701\ntourist_info\nManila American Cemetery and Memorial Visitor ...\n137602022\nPOINT (13475059.129 1636701.151)\n\n\n1\n672565496\n2701\ntourist_info\necopark paging and first aid station\n137404141\nPOINT (13477983.748 1656000.058)\n\n\n2\n672565498\n2701\ntourist_info\nEcopark ticket counter\n137404141\nPOINT (13477813.318 1656135.868)\n\n\n3\n1585389544\n2701\ntourist_info\nArea Formerly Occupied by Fort Bonifacio Museum\n137602021\nPOINT (13476156.594 1637474.593)\n\n\n4\n1834855424\n2701\ntourist_info\nLotto Booth\n137601020\nPOINT (13468786.053 1622805.175)\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n2829\n1282790636\n2723\nmonument\nRizal Monument\n030808004\nPOINT (13387876.843 1652143.344)\n\n\n2830\n1430752967\n2723\nmonument\nRizal Monument\n034903092\nPOINT (13464327.852 1743609.163)\n\n\n2831\n2280492117\n2723\nmonument\nRizal Monument\n031421037\nPOINT (13467118.142 1705384.453)\n\n\n2832\n4898774223\n2723\nmonument\nRizal Monument\n035414009\nPOINT (13434387.128 1685457.796)\n\n\n2833\n3087522557\n2724\nmemorial\nRizal Monument\n031410015\nPOINT (13448861.946 1672777.772)\n\n\n\n\n2834 rows × 6 columns\n\n\n\n\nresults3 = dzs.create_distance_zonal_stats(\n    region3_admin_grids,\n    region34ncr_osm_pois,\n    max_distance=10_000,  # within 10km\n    aggregations=[dict(func=\"count\", output=\"pois_count\", fillna=[True])],\n)\n\nCPU times: user 64.3 ms, sys: 6.26 ms, total: 70.5 ms\nWall time: 67.8 ms\n\n\n\nlen(results3[results3.pois_count == 0.0])\n\n165\n\n\n\nresults3\n\n\n\n\n\n\n\n\nx\ny\ngeometry\npois_count\nnearest\n\n\n\n\n0\n0\n30\nPOLYGON ((13334497.956 1771012.807, 13339497.9...\n1.0\n8849.591855\n\n\n1\n0\n31\nPOLYGON ((13334497.956 1776012.807, 13339497.9...\n1.0\n8844.448848\n\n\n2\n0\n32\nPOLYGON ((13334497.956 1781012.807, 13339497.9...\n0.0\nNaN\n\n\n3\n1\n30\nPOLYGON ((13339497.956 1771012.807, 13344497.9...\n1.0\n3856.266007\n\n\n4\n1\n32\nPOLYGON ((13339497.956 1781012.807, 13344497.9...\n1.0\n6070.762498\n\n\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((13604497.956 1841012.807, 13609497.9...\n1.0\n674.134053\n\n\n1070\n54\n45\nPOLYGON ((13604497.956 1846012.807, 13609497.9...\n2.0\n0.000000\n\n\n1071\n54\n46\nPOLYGON ((13604497.956 1851012.807, 13609497.9...\n1.0\n4237.158313\n\n\n1072\n54\n47\nPOLYGON ((13604497.956 1856012.807, 13609497.9...\n1.0\n9237.158313\n\n\n1073\n54\n48\nPOLYGON ((13604497.956 1861012.807, 13609497.9...\n0.0\nNaN\n\n\n\n\n1074 rows × 5 columns"
  },
  {
    "objectID": "validation.html",
    "href": "validation.html",
    "title": "Geometry Validation",
    "section": "",
    "text": "geometry validations\n\n\nsource\n\nValidationError\nCommon base class for all non-exit exceptions.\n\nsource\n\n\nBaseValidator\n\n BaseValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nAbstract Base Class for single validator\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nBaseValidator.validate\n\n BaseValidator.validate (gdf:geopandas.geodataframe.GeoDataFrame,\n                         clone=True)\n\nMethod that checks the validity of a each geometry and applies a fix to these geometries or raise a warning\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngdf\nGeoDataFrame\n\nGeoDataFrame to validate\n\n\nclone\nbool\nTrue\nApply validation to copy\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\n\nsource\n\n\nOrientationValidator\n\n OrientationValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks and fixes Orientation of the geometry to ensure it follows a counter-clockwise orientation\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nOrientationValidator.check\n\n OrientationValidator.check (geometry:shapely.geometry.base.BaseGeometry)\n\nChecks if orientation is counter clockwise\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to validate\n\n\nReturns\nbool\n\n\n\n\n\nsource\n\n\nOrientationValidator.fix\n\n OrientationValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nFixes orientation if orientation is clockwise\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\n\n\n\n\n\nsource\n\n\nCrsBoundsValidator\n\n CrsBoundsValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks bounds of the geometry to ensure it is within bounds of the crs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nCrsBoundsValidator.get_check_arguments\n\n CrsBoundsValidator.get_check_arguments\n                                         (gdf:geopandas.geodataframe.GeoDa\n                                         taFrame)\n\nReturn check arguments\n\n\n\n\nType\nDetails\n\n\n\n\ngdf\nGeoDataFrame\nGeoDataFrame to check\n\n\nReturns\ndict\n\n\n\n\n\nsource\n\n\nCrsBoundsValidator.check\n\n CrsBoundsValidator.check (geometry:shapely.geometry.base.BaseGeometry,\n                           gdf:geopandas.geodataframe.GeoDataFrame)\n\nChecks if polygon is within bounds of crs.\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to validate\n\n\ngdf\nGeoDataFrame\nGeoDataframe to check\n\n\nReturns\nbool\n\n\n\n\n\nsource\n\n\nCrsBoundsValidator.fix\n\n CrsBoundsValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nNo fix available\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\npragma: no cover\n\n\n\n\nsource\n\n\nSelfIntersectingValidator\n\n SelfIntersectingValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks bounds of the geometry to ensure it is within bounds or crs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nSelfIntersectingValidator.check\n\n SelfIntersectingValidator.check\n                                  (geometry:shapely.geometry.base.BaseGeom\n                                  etry)\n\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to check\n\n\nReturns\nbool\n\n\n\n\n\nsource\n\n\nSelfIntersectingValidator.fix\n\n SelfIntersectingValidator.fix\n                                (geometry:shapely.geometry.base.BaseGeomet\n                                ry)\n\nFix intersection geometry by applying shapely.validation.make_valid\n\nsource\n\n\nNullValidator\n\n NullValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks bounds of the geometry to ensure it is within bounds or crs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nNullValidator.check\n\n NullValidator.check (geometry:shapely.geometry.base.BaseGeometry)\n\nChecks if polygon is null\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\n\n\n\nReturns\nbool\nGeometry to check\n\n\n\n\nsource\n\n\nNullValidator.fix\n\n NullValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nNo fix available\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\npragma: no cover\n\n\n\n\nsource\n\n\nAreaValidator\n\n AreaValidator (add_new_column:bool=True, apply_fix:bool=True)\n\nChecks area of the geometry to ensure it greater than 0\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nadd_new_column\nbool\nTrue\nAdd new column to show errors\n\n\napply_fix\nbool\nTrue\nUpdate geometry\n\n\n\n\nsource\n\n\nAreaValidator.check\n\n AreaValidator.check (geometry:shapely.geometry.base.BaseGeometry)\n\nChecks if area is greater than 0\n\nsource\n\n\nAreaValidator.fix\n\n AreaValidator.fix (geometry:shapely.geometry.base.BaseGeometry)\n\nNo fix available\n\n\n\n\nType\nDetails\n\n\n\n\ngeometry\nBaseGeometry\nGeometry to fix\n\n\nReturns\nBaseGeometry\npragma: no cover\n\n\n\n\nsource\n\n\nGeometryValidation\n\n GeometryValidation (gdf:geopandas.geodataframe.GeoDataFrame,\n                     validators:Sequence[Union[str,__main__.BaseValidator]\n                     ]=('null', 'self_intersecting', 'orientation',\n                     'crs_bounds', 'area'),\n                     add_validation_columns:bool=True,\n                     apply_fixes:bool=True)\n\nApplies a list of validation checks and tries to fix them\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ngdf\nGeoDataFrame\n\nGeoDataFrame to validate\n\n\nvalidators\ntyping.Sequence[typing.Union[str, main.BaseValidator]]\n(‘null’, ‘self_intersecting’, ‘orientation’, ‘crs_bounds’, ‘area’)\nValidators to apply\n\n\nadd_validation_columns\nbool\nTrue\nAdd column to show errors\n\n\napply_fixes\nbool\nTrue\nUpdate geometry\n\n\nReturns\nGeoDataFrame\n\n\n\n\n\n\nsource\n\n\nGeometryValidation.validate_all\n\n GeometryValidation.validate_all ()\n\nSequentially run validators"
  },
  {
    "objectID": "tutorial.raster_zonal_stats.html",
    "href": "tutorial.raster_zonal_stats.html",
    "title": "Raster Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to Raster Zonal Stats"
  },
  {
    "objectID": "tutorial.raster_zonal_stats.html#basic-usage",
    "href": "tutorial.raster_zonal_stats.html#basic-usage",
    "title": "Raster Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate zonal stats for a GeoDataframe containing areas of interest using raster data\nTerms:\n\naoi - (area of interest) a geodataframe which we are interested in generating zonal statistics for\nraster data - the source raster containing the features which we are interested in collecting zonal stats for our aoi.\n\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport geowrangler2.raster_zonal_stats as rzs\n\n\nLoad AOI\nOur areas of interest (AOI) are three (3) Level 1 administration regions (ADM1) of the Philippines located in the island of Luzon.\n\n# area multipolygons for regions 3,4,ncr of the philippines\naoi = gpd.read_file(\"../data/region34ncr_admin.geojson\")\n\nCPU times: user 3.26 s, sys: 195 ms, total: 3.45 s\nWall time: 3.44 s\n\n\n\n# no_test\nax = aoi.plot(\n    ax=plt.axes(),\n    facecolor=\"none\",\n    edgecolor=[\n        \"#C62828\",\n        \"#283593\",\n        \"#FF9800\",\n    ],\n)\n\n\n\n\n\n# no_test\naoi\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n\n\n\n\n\n\n\n\n\nDownload Philippine Population Data\n\nsee the Humanitarian Data Exchange World Population Counts - Philippines\n\nWe download our raster Data as GeoTiff files from the Humanitarian Data Exchange site.\n\n\n\n\n\n\nNote\n\n\n\nThis maybe slow as the file is about 180 Mb and depending on your internet download speed may take more than 5 minutes\n\n\n\n# PHL population HDX links\nphil_pop_link = \"https://data.worldpop.org/GIS/Population/Global_2000_2020/2020/PHL/phl_ppp_2020.tif\"\nphil_pop_dset = \"phl_pop_2020.tif\"\n\n\n![ ! -e ../data/{phil_pop_dset} ] && curl -o ../data/{phil_pop_dset} {phil_pop_link}\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  180M  100  180M    0     0   576k      0  0:05:19  0:05:19 --:--:--  430k\nCPU times: user 12 s, sys: 3.57 s, total: 15.6 s\nWall time: 5min 19s\n\n\nTo create our raster zonal stats, we just need to set the aggregations, as well as some extra arguments, such as the nodata value in the raster.\n\nresults = rzs.create_raster_zonal_stats(\n    aoi,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"],\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\nCPU times: user 4.22 s, sys: 128 ms, total: 4.35 s\nWall time: 4.34 s\n\n\n\nresults\n\n\n\n\n\n\n\n\nReg_Code\nReg_Name\nReg_Alt_Name\ngeometry\nsamples\npopulation_count\n\n\n\n\n0\n130000000\nNational Capital Region\nNCR\nMULTIPOLYGON (((121.03842 14.78525, 121.03815 ...\n70786\n13165866.0\n\n\n1\n030000000\nRegion III\nCentral Luzon\nMULTIPOLYGON (((120.11687 14.76309, 120.11684 ...\n2558377\n11493727.0\n\n\n2\n040000000\nRegion IV-A\nCalabarzon\nMULTIPOLYGON (((122.72165 13.36485, 122.72143 ...\n1876244\n15952383.0\n\n\n\n\n\n\n\n\n\nUsing Grid Tile AOIs\nWe can also use tile grids as our AOIs.\n\n# note that you don't need to load the aoi first\ngrid_aoi_file = \"../data/region3_admin_grids.geojson\"\n\n\ngrid_aoi_results = rzs.create_raster_zonal_stats(\n    grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"],\n        fillna=[True, True],\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\nCPU times: user 8.57 s, sys: 12.2 ms, total: 8.59 s\nWall time: 8.58 s\n\n\n\ngrid_aoi_results.head()\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nsamples\npopulation_count\n\n\n\n\n0\n0\n30\nPOLYGON ((119.78583 15.70870, 119.83075 15.708...\n171\n1171.764038\n\n\n1\n0\n31\nPOLYGON ((119.78583 15.75193, 119.83075 15.751...\n329\n278.567200\n\n\n2\n0\n32\nPOLYGON ((119.78583 15.79516, 119.83075 15.795...\n345\n279.140198\n\n\n3\n1\n30\nPOLYGON ((119.83075 15.70870, 119.87566 15.708...\n158\n808.681152\n\n\n4\n1\n32\nPOLYGON ((119.83075 15.79516, 119.87566 15.795...\n20\n0.000000\n\n\n\n\n\n\n\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = grid_aoi_results.plot(\n    ax=ax, column=\"population_count\", edgecolor=\"blue\", alpha=0.5\n)\n\n\n\n\n\n\nUsing Bing Tile Grid Tile AOIs\nWe can also use pre-existing Bing tile grids as our AOIs.\n\n# note that you don't need to load the aoi first\nbingtile_grid_aoi_file = \"../data/region3_bingtile_grid13.geojson\"\n\n\nbingtile_grid_aoi_results = rzs.create_raster_zonal_stats(\n    bingtile_grid_aoi_file,\n    f\"../data/{phil_pop_dset}\",\n    aggregation=dict(\n        func=[\"sum\", \"count\"],\n        column=\"population\",\n        output=[\"population_count\", \"samples\"],\n        fillna=[True, True],\n    ),\n    extra_args=dict(nodata=-99999),  # nodata value is -99999\n)\n\nCPU times: user 10.6 s, sys: 124 ms, total: 10.7 s\nWall time: 10.7 s\n\n\n\nbingtile_grid_aoi_results.head()\n\n\n\n\n\n\n\n\nquadkey\ngeometry\nsamples\npopulation_count\n\n\n\n\n0\n1323030303301\nPOLYGON ((120.10254 14.73239, 120.10254 14.774...\n737\n196.756744\n\n\n1\n1323030303300\nPOLYGON ((120.05859 14.73239, 120.05859 14.774...\n50\n35.732861\n\n\n2\n1323030303311\nPOLYGON ((120.19043 14.73239, 120.19043 14.774...\n248\n383.338013\n\n\n3\n1323030303133\nPOLYGON ((120.19043 14.77488, 120.19043 14.817...\n901\n5621.879395\n\n\n4\n1323030303131\nPOLYGON ((120.19043 14.81737, 120.19043 14.859...\n1328\n6584.988770\n\n\n\n\n\n\n\n\n# no_test\nax = aoi[aoi.Reg_Name == \"Region III\"].plot(\n    ax=plt.axes(), facecolor=\"none\", edgecolor=\"black\"\n)\nax = bingtile_grid_aoi_results.plot(\n    ax=ax, column=\"population_count\", edgecolor=\"blue\", alpha=0.5\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Geowrangler",
    "section": "",
    "text": "Overview\nGeowrangler is a python package for geodata wrangling. It helps build data transformation workflows that have no out-of-the-box solutions from other geospatial libraries.\nWe surveyed our past geospatial projects to extract these solutions for our work and hope that these will be useful for others as well.\nOur audience are researchers, analysts and engineers delivering geospatial projects.\nWe welcome your comments, suggestions, bug reports and code contributions to make Geowrangler better.\n\n\n\n\n\n\n\nContext\nGeowrangler was borne out of our efforts to reduce the amount of boilerplate code in wrangling geospatial data. It builds on top of existing geospatial libraries such as geopandas, rasterio, rasterstats, morecantile and others. Our goals are centered on the following tasks:\n\nExtracting area of interest zonal statistics from vector and raster data\nGridding areas of interest\nValidating geospatial datasets\nDownloading of publically available geospatial datasets (e.g. OSM, Ookla, Nightlights)\nOther geospatial vector and raster data processing tasks\n\nTo make it easy to document, maintain and extend the package, we opted to maintain the source code, tests and documentation on Jupyter notebooks. We use nbdev to generate the python package and documentation from the notebooks. See this document to learn more about our development workflow.\nBy doing this, we hope to make it easy for geospatial analysts, scientists and engineers to learn, explore and extend this package for their geospatial processing needs.\nAside from providing reference documentation for each module, we have included extensive tutorials and use case examples in order to make it easy to learn and use.\n\n\nModules\n\nGrid Tile Generation\nGeometry Validation\nVector Zonal Stats\nRaster Zonal Stats\nArea Zonal Stats\nDistance Zonal Stats\nDemographic and Health Survey (DHS) Processing Utils\nGeofabrik (OSM) Data Download\nOokla Data Download\n\nCheck this page for more details about our Roadmap\n\n\nInstallation\npip install git+https://github.com/butchtm/geowrangler2.git\n\n\nExploring the Documentation\nWe develop the package modules alongside their documentation on Jupyter notebooks. Each page comes with an Open in Colab button that will open the jupyter notebook in Google Colab for exploration (including this page).\nClick on the Open in Colab button below to open this page as a Google Colab notebook.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nall the documentation pages (including the references) are executable Jupyter notebooks.\n\n\n\nSample Code\n\n\nSample code using grids to display source\nimport geopandas as gpd\n\nimport geowrangler2.grids\n\n# view the source of a grid component\ngdf = gpd.GeoDataFrame()\ngrid = geowrangler2.grids.SquareGridGenerator(gdf, 1)\ngrid??\n\n\n\nType:        SquareGridGenerator\nString form: &lt;geowrangler2.grids.SquareGridGenerator object at 0x7fc284380880&gt;\nFile:        ~/work/unicef-ai4d/geowrangler2-1/geowrangler2/grids.py\nSource:     \nclass SquareGridGenerator:\n    def __init__(\n        self,\n        cell_size: float,  # height and width of a square cell in meters\n        grid_projection: str = \"EPSG:3857\",  # projection of grid output\n        boundary: Union[SquareGridBoundary, List[float]] = None,  # original boundary\n    ):\n        self.cell_size = cell_size\n        self.grid_projection = grid_projection\n        self.boundary = boundary\n\n\n\n\n\n\nTutorials\n\nGrids Generation\nGeometry Validation\nVector Zonal Stats\nRaster Zonal Stats\nArea Zonal Stats\nDistance Zonal Stats\nDHS Processing Utils\nDataset Downloads\n\n\n\nReference\n\nGrids Generation\nGeometry Validation\nVector Zonal Stats\nRaster Zonal Stats\nArea Zonal Stats\nDistance Zonal Stats\nDHS Processing Utils\nDataset Geofabrik (OSM)\nDataset Ookla\n\n\n\n\n\n\n\nNote\n\n\n\nall the documentation pages (including the references) are executable Jupyter notebooks."
  },
  {
    "objectID": "tutorial.area_zonal_stats.html",
    "href": "tutorial.area_zonal_stats.html",
    "title": "Vector Area Zonal Stats Tutorial",
    "section": "",
    "text": "A basic introduction to Vector Area Zonal Stats"
  },
  {
    "objectID": "tutorial.area_zonal_stats.html#basic-usage",
    "href": "tutorial.area_zonal_stats.html#basic-usage",
    "title": "Vector Area Zonal Stats Tutorial",
    "section": "Basic Usage",
    "text": "Basic Usage\nGenerate area zonal stats for a GeoDataframe containing areas of interest with a vector data source containing areas associated with statistics. :::{.callout-note}\nthe assumption for the data is that the statistics are uniformly distributed over the entire area for each row in the data source.\n:::\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport geowrangler2.area_zonal_stats as azs\n\n\nSimple Grid AOIs and Data\n\nsimple_aoi = gpd.read_file(\"../data/simple_planar_aoi.geojson\")\nsimple_data = gpd.read_file(\"../data/simple_planar_data.geojson\")\n\nGiven an aoi (simple_aoi) and geodataframe containing sample data (simple_data)\n\nsimple_aoi\n\n\n\n\n\n\n\n\ngeometry\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n\n\n\n\n\n\n\n\nsimple_data\n\n\n\n\n\n\n\n\npopulation\ninternet_speed\ngeometry\n\n\n\n\n0\n100\n20.0\nPOLYGON ((0.250 0.000, 0.250 1.000, 1.250 1.00...\n\n\n1\n200\n10.0\nPOLYGON ((1.250 0.000, 1.250 1.000, 2.250 1.00...\n\n\n2\n300\n5.0\nPOLYGON ((2.250 0.000, 2.250 1.000, 3.250 1.00...\n\n\n\n\n\n\n\nIn order correctly apportion the statistic, we need to make sure that the aoi and data geodataframes are using a planar CRS (i.e. gdf.crs.is_geographic == False)\n\nsimple_aoi.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nsimple_data.crs\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\nax = plt.axes()\nax = simple_data.plot(\n    ax=ax, color=[\"orange\", \"brown\", \"purple\"], edgecolor=\"yellow\", alpha=0.4\n)\nax = simple_aoi.plot(ax=ax, facecolor=\"none\", edgecolor=[\"r\", \"g\", \"b\"])\n\n\n\n\nThe red,green,blue outlines are the 3 regions of interest (aoi) while the orange,brown, purple areas are the data areas.\n\nempty_aoi_results = azs.create_area_zonal_stats(simple_aoi, simple_data)\n\nIf no aggregations are specified, the include_intersect=True arg specifies that the sum of the data areas intersecting our aoi is computed in the column intersect_area_sum.\n\nempty_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n\n\n\n\n\n\n\n\nApportioning aggregated statistics\nTo aggregate statistics over the aoi areas intersecting with the data areas, the default behavior of “apportioning” the statistic over the intersection of the data area overlapping the aoi area depends on the statistic.\n\nFor sum it apportions the total value of the statistic over the proportion of the data area overlapping the aoi area divided by the total area of the data.\nFor mean it apportions the total value of the statistic over the proportion of the data area overlapping the aoi area divided by the total area of the aoi.\nFor other statistics, there is no apportioning done and uses the raw statistics from the data areas overlapping the aoi area.\n\n\n\n\n\n\n\nNote\n\n\n\nthis default behavior can be overridden by specifying a prefix (raw_,data_,aoi_) to the statistic (i.e. func) – e.g. if you wish the apportion the sum as a proportion of the aoi area instead of the data area, specify the func as aoi_sum instead of sum.\n\n\n\nsimple_aoi_results = azs.create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(func=[\"mean\", \"max\", \"min\", \"std\"], column=\"internet_speed\"),\n    ],\n)\n\nCPU times: user 53.2 ms, sys: 728 µs, total: 53.9 ms\nWall time: 51.6 ms\n\n\n\nsimple_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n75.0\n1\n15.000\n20.0\n0.0\nNaN\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n175.0\n2\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n275.0\n2\n3.125\n10.0\n5.0\n3.535534\n\n\n\n\n\n\n\n\nsimple_aoi_results.population_sum.sum(axis=None)\n\n525.0\n\n\nNote the value of the mean of the internet speed for the 1st area above.\nWhile there is one data area overlapping with an internet speed of 20.0 the computed aggregate statistic for the mean is 15.0 due to the apportioning which only accounts for 0.75 (the total aoi area is 1.0) – meaning it assigns a value of 0.0 for the 0.25 area with no overlapping data area.\nIf you wish to override this behavior and impute the value of the statistic as the means of all the overlapping areas (in proportion to the overlap of their area over the total area of the aoi), you can additionally add a prefix of imputed_ as shown in the next example. Note that adding a prefix doesn’t change the default output column name, which is why we explicitly specified an output column name (internet_speed_imputed_mean in order to differentiate it from the original internet_speed_mean column.\nNotice as well that adding a raw_ prefix to the min,max,std statistics doesn’t change their values since by default these statistics don’t use any apportioning (so specifying raw_ is redundant in this case).\nLastly, check the effect of setting of the fix_min arg to False (the default value is True) – since it uses the raw column to compute the min, it is not aware that there are areas in the aoi that have no overlapping data areas and uses the min value from the overlapping areas (in this case, since there is only 1 partially overlapping area, it uses that as the min value). The fix_min arg “fixes” this by checking if the data areas completely overlap the aoi area and sets the minimum to 0 if there is a portion of the aoi area that is not completely intersected by a data area.\n\ncorrected_aoi_results = azs.create_area_zonal_stats(\n    simple_aoi,\n    simple_data,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n        dict(\n            func=[\"mean\", \"imputed_mean\", \"raw_max\", \"raw_min\", \"raw_std\"],\n            column=\"internet_speed\",\n            output=[\n                \"internet_speed_mean\",\n                \"internet_speed_imputed_mean\",\n                \"internet_speed_max\",\n                \"internet_speed_min\",\n                \"internet_speed_std\",\n            ],\n        ),\n    ],\n    fix_min=False,\n)\n\nCPU times: user 103 ms, sys: 0 ns, total: 103 ms\nWall time: 101 ms\n\n\n\ncorrected_aoi_results\n\n\n\n\n\n\n\n\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\ninternet_speed_mean\ninternet_speed_imputed_mean\ninternet_speed_max\ninternet_speed_min\ninternet_speed_std\n\n\n\n\n0\nPOLYGON ((0.000 0.000, 0.000 1.000, 1.000 1.00...\n0.75\n75.0\n1\n15.000\n20.000\n20.0\n20.0\nNaN\n\n\n1\nPOLYGON ((1.000 0.000, 1.000 1.000, 2.000 1.00...\n1.00\n175.0\n2\n6.250\n6.250\n20.0\n10.0\n7.071068\n\n\n2\nPOLYGON ((2.000 0.000, 2.000 1.000, 3.000 1.00...\n1.00\n275.0\n2\n3.125\n3.125\n10.0\n5.0\n3.535534\n\n\n\n\n\n\n\n\n\n\nCustom Grids over admin area data\n\nAnother example using aggregated statistics over admin areas (barangay level) that are apportioned into grid areas by their overlap.\n\n\nNotice that since the grid areas does not completely overlap the admin areas (and vice versa) , the sum of their total populations and land areas are not equal.\n\n\nregion3_admin_grids = gpd.read_file(\"../data/region3_admin_grids.geojson\")\nregion3_admin_grids = region3_admin_grids.to_crs(\"EPSG:3857\")  # convert to planar\n\nCPU times: user 159 ms, sys: 0 ns, total: 159 ms\nWall time: 157 ms\n\n\n\nregion3_pop_bgy_level = gpd.read_file(\"../data/region3_population_bgy_level.geojson\")\n\nCPU times: user 376 ms, sys: 29.2 ms, total: 405 ms\nWall time: 402 ms\n\n\n\naoi_result = azs.create_area_zonal_stats(\n    region3_admin_grids,\n    region3_pop_bgy_level,\n    [\n        dict(func=[\"sum\", \"count\"], column=\"population\"),\n    ],\n)\n\nCPU times: user 764 ms, sys: 0 ns, total: 764 ms\nWall time: 763 ms\n\n\n\naoi_result\n\n\n\n\n\n\n\n\nx\ny\ngeometry\nintersect_area_sum\npopulation_sum\npopulation_count\n\n\n\n\n0\n0\n30\nPOLYGON ((13334497.956 1771012.807, 13339497.9...\n1.213773e+06\n687.832840\n1\n\n\n1\n0\n31\nPOLYGON ((13334497.956 1776012.807, 13339497.9...\n2.471924e+06\n986.890853\n1\n\n\n2\n0\n32\nPOLYGON ((13334497.956 1781012.807, 13339497.9...\n2.748813e+06\n1097.435840\n1\n\n\n3\n1\n30\nPOLYGON ((13339497.956 1771012.807, 13344497.9...\n1.081669e+06\n468.368614\n2\n\n\n4\n1\n32\nPOLYGON ((13339497.956 1781012.807, 13344497.9...\n8.941593e+04\n8.570604\n2\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n1069\n54\n44\nPOLYGON ((13604497.956 1841012.807, 13609497.9...\n1.976718e+05\n15.398162\n1\n\n\n1070\n54\n45\nPOLYGON ((13604497.956 1846012.807, 13609497.9...\n1.019141e+07\n1613.913393\n3\n\n\n1071\n54\n46\nPOLYGON ((13604497.956 1851012.807, 13609497.9...\n3.129991e+06\n1033.997979\n2\n\n\n1072\n54\n47\nPOLYGON ((13604497.956 1856012.807, 13609497.9...\n8.106461e+06\n250.893691\n2\n\n\n1073\n54\n48\nPOLYGON ((13604497.956 1861012.807, 13609497.9...\n1.928818e+07\n299.377987\n3\n\n\n\n\n1074 rows × 6 columns\n\n\n\n\n(\n    aoi_result.geometry.area.sum(),\n    aoi_result.intersect_area_sum.sum(),\n    aoi_result.population_sum.sum(),\n)\n\n(26850000000.000072, 24548892214.947075, 12136963.9717533)\n\n\n\n(region3_pop_bgy_level.geometry.area.sum(), region3_pop_bgy_level.population.sum())\n\n(27658006631.682587, 13139695)\n\n\n\ngdf = region3_admin_grids\ngdf2 = region3_pop_bgy_level\n\n\nax = plt.axes()\nax = gdf2.plot(ax=ax, column=\"population\", alpha=0.4)\nax = gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"blue\", alpha=0.4)\n\n\n\n\n\nax = plt.axes()\nax = gdf2.plot(ax=ax, facecolor=\"none\", alpha=0.4, edgecolor=\"red\")\nax = aoi_result.plot(column=\"population_sum\", ax=ax, alpha=0.4, edgecolor=\"blue\")\n\n\n\n\n\nax = plt.axes()\nax = gdf2.plot(ax=ax, column=\"population\", alpha=0.4, edgecolor=\"red\")\nax = aoi_result.plot(column=\"intersect_area_sum\", ax=ax, alpha=0.4, edgecolor=\"blue\")"
  }
]