{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4460eac-f6b8-4d46-b971-109ed6ba24f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp datasets.ookla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f3485c-20cb-44c9-a82d-3cef6a4047cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# no_test\n",
    "![ -e /content ] && pip install -Uqq geowrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ad1a2-b0df-4675-af9e-3223c8f36e31",
   "metadata": {},
   "source": [
    "# Datasets Ookla\n",
    "> Download ookla data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19d8c85d-fad5-4cf2-8a00-d99f8276e4c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exporti\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import namedtuple\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Union\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import HTTPError\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from fastcore.all import L, parallel, patch\n",
    "from loguru import logger\n",
    "\n",
    "import geowrangler.area_zonal_stats as azs\n",
    "from geowrangler import grids\n",
    "from geowrangler.datasets.utils import make_report_hook, urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52a68395-fcaa-4114-87b2-a5f05f5356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporti\n",
    "\n",
    "OoklaFile = namedtuple(\"OoklaQuarter\", [\"type\", \"year\", \"quarter\"])\n",
    "DEFAULT_CACHE_DIR = \"~/.cache/geowrangler\"\n",
    "OOKLA_QUADKEY_LEVEL = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a30a6d-c28d-4be2-9325-ac7618d49a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@lru_cache(maxsize=None)\n",
    "def list_ookla_files() -> dict:\n",
    "    \"\"\"Get list of ookla data\"\"\"\n",
    "    # Query parquet files as they are easier to deal with then shapefiles\n",
    "    resp = requests.get(\n",
    "        \"https://ookla-open-data.s3.us-west-2.amazonaws.com/?list-type=2&prefix=parquet\"\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    root = ET.fromstring(resp.text)\n",
    "    keys = {}\n",
    "    # Get keys. This would require pagination once there are more than 1000 keys under the parquet folder\n",
    "    # but that would only happen after ~125 years\n",
    "    for child in root.findall(\"{http://s3.amazonaws.com/doc/2006-03-01/}Contents\"):\n",
    "        key = child.find(\"{http://s3.amazonaws.com/doc/2006-03-01/}Key\").text\n",
    "        path_key = Path(key)\n",
    "        type_ = path_key.parts[2].rsplit(\"=\")[-1]\n",
    "        year = path_key.parts[3].rsplit(\"=\")[-1]\n",
    "        quarter = path_key.parts[4].rsplit(\"=\")[-1]\n",
    "        file = path_key.parts[5]\n",
    "        keys.update({OoklaFile(type_, year, quarter): file})\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "229e9791-fb26-4134-8b3b-ff285a87b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "ookla_files = list_ookla_files()\n",
    "assert ookla_files.get(OoklaFile(\"fixed\", \"2021\", \"2\"), None) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4865876c-69aa-4d51-adf4-734d298d20d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def download_ookla_file(\n",
    "    type_: str,  # Internet connection type: 'fixed' or 'mobile'\n",
    "    year: str,  # Year (e.g. '2020')\n",
    "    quarter: str,  # Quarter (valid values: '1','2','3','4')\n",
    "    directory: str = \"data/\",  # Download directory\n",
    "    overwrite: bool = False,  # Overwrite if existing\n",
    "    show_progress=True,  # show progres bar\n",
    "    chunksize=8192,  # Download chunksize\n",
    "    reporthook=None,  # Use custom progress bar\n",
    ") -> Union[Path, None]:\n",
    "    \"\"\"Download ookla file to path\"\"\"\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    ookla_info = list_ookla_files()\n",
    "    key = OoklaFile(type_, str(year), str(quarter))\n",
    "    if key not in ookla_info:\n",
    "        raise ValueError(\n",
    "            f\"{key} not found in ookla. Run list_ookla_data() to learn more about available files\"\n",
    "        )\n",
    "    fname = ookla_info[key]\n",
    "    url = f\"https://ookla-open-data.s3.us-west-2.amazonaws.com/parquet/performance/type={type_}/year={year}/quarter={quarter}/{fname}\"\n",
    "    parsed_url = urlparse(url)\n",
    "    filename = Path(os.path.basename(parsed_url.path))\n",
    "    filepath = directory / filename\n",
    "    if not filepath.exists() or overwrite:\n",
    "        if reporthook is None:\n",
    "            reporthook = make_report_hook(show_progress)\n",
    "\n",
    "        try:\n",
    "            filepath, _, _ = urlretrieve(\n",
    "                url, filepath, reporthook=reporthook, chunksize=chunksize\n",
    "            )\n",
    "        except HTTPError as err:\n",
    "            if err.code == 404:\n",
    "                logger.warning(\n",
    "                    f\"No url found for type {type_} year {year} and {quarter} : {url} \"\n",
    "                )\n",
    "                return None\n",
    "            else:\n",
    "                raise err\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c612bfab-4246-4b20-a44e-8e8efcae2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def parallel_download(item):\n",
    "    (\n",
    "        quarter,\n",
    "        type_,\n",
    "        year,\n",
    "        directory,\n",
    "        overwrite,\n",
    "        show_progress,\n",
    "        chunksize,\n",
    "        reporthook,\n",
    "    ) = item  # unpack tuple\n",
    "    logger.info(\n",
    "        f\"Ookla Data: Downloading Ookla parquet file for quarter {quarter}... type: {type_} year: {year} in {directory}\"\n",
    "    )\n",
    "    return download_ookla_file(\n",
    "        type_=type_,\n",
    "        year=year,\n",
    "        quarter=quarter,\n",
    "        directory=directory,\n",
    "        overwrite=overwrite,\n",
    "        show_progress=show_progress,\n",
    "        chunksize=chunksize,\n",
    "        reporthook=reporthook,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e42707bb-ee16-4666-a7cd-6877aea4ec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def download_ookla_parallel(\n",
    "    num_expected_ookla_files,\n",
    "    type_,\n",
    "    year,\n",
    "    directory,\n",
    "    overwrite,\n",
    "    show_progress,\n",
    "    chunksize,\n",
    "    reporthook,\n",
    "):\n",
    "    items = [\n",
    "        (\n",
    "            str(i),\n",
    "            type_,\n",
    "            year,\n",
    "            directory,\n",
    "            overwrite,\n",
    "            show_progress,\n",
    "            chunksize,\n",
    "            reporthook,\n",
    "        )\n",
    "        for i in range(1, num_expected_ookla_files + 1, 1)\n",
    "    ]\n",
    "    parallel(parallel_download, items, threadpool=True, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14bb3c79-5d97-42a9-8457-046dd2b407b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def download_ookla_year_data(\n",
    "    type_,\n",
    "    year,\n",
    "    cache_dir,\n",
    "    use_cache=True,\n",
    "    show_progress=True,\n",
    "    chunksize=8192,\n",
    "    reporthook=None,\n",
    "):\n",
    "\n",
    "    \"Download ookla data for a specifed type (fixed or mobile) and year. Data for all 4 quarters will be downloaded.\"\n",
    "\n",
    "    # Determine number of expected data for type_ and year, specified by OoklaFile(type, year, quarter)\n",
    "    available_ookla_files = list_ookla_files()\n",
    "    expected_ookla_files = {}\n",
    "    for quarter in [1, 2, 3, 4]:\n",
    "        quarter_ookla_file = OoklaFile(str(type_), str(year), str(quarter))\n",
    "        if quarter_ookla_file in available_ookla_files.keys():\n",
    "            expected_ookla_files[quarter_ookla_file] = available_ookla_files[\n",
    "                quarter_ookla_file\n",
    "            ]\n",
    "    num_expected_ookla_files = len(expected_ookla_files)\n",
    "\n",
    "    if num_expected_ookla_files == 0:\n",
    "        logger.warning(f\"Ookla data: No data available for {type_} and {year}\")\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Ookla Data: Number of available files for {type_} and {year}: {num_expected_ookla_files}\"\n",
    "        )\n",
    "\n",
    "    ookla_cache_dir = os.path.join(cache_dir, \"ookla/\")\n",
    "    type_year_cache_dir = os.path.join(ookla_cache_dir, type_, str(year))\n",
    "\n",
    "    # Check if the cached data is valid. Otherwise, we have to re-download.\n",
    "    # For Ookla, we need to check if we've downloaded all expected files for that year.\n",
    "    cached_data_available = (\n",
    "        os.path.exists(type_year_cache_dir)\n",
    "        and len(os.listdir(type_year_cache_dir)) == num_expected_ookla_files\n",
    "    )\n",
    "\n",
    "    logger.info(\n",
    "        f\"Ookla Data: Cached data available for {type_} and {year} at {type_year_cache_dir}? {cached_data_available}\"\n",
    "    )\n",
    "\n",
    "    # Download if cache is invalid or user specified use_cache = False\n",
    "    if not cached_data_available or not use_cache:\n",
    "        logger.info(\n",
    "            f\"Ookla Data: Re-initializing Ookla type/year cache dir at {type_year_cache_dir}...\"\n",
    "        )\n",
    "        # Re-create the country cache dir and start over to fix any corrupted states\n",
    "        shutil.rmtree(type_year_cache_dir, ignore_errors=True)\n",
    "        Path(type_year_cache_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # This downloads a parquet file to the type_year_dir for each quarter\n",
    "        overwrite = not use_cache\n",
    "        download_ookla_parallel(\n",
    "            num_expected_ookla_files,\n",
    "            type_,\n",
    "            year,\n",
    "            type_year_cache_dir,\n",
    "            overwrite,\n",
    "            show_progress,\n",
    "            chunksize,\n",
    "            reporthook,\n",
    "        )\n",
    "\n",
    "        logger.info(\n",
    "            f\"Ookla Data: Successfully downloaded and cached Ookla data for {type_} and {year} at {type_year_cache_dir}!\"\n",
    "        )\n",
    "\n",
    "    return type_year_cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61c76533-3a3a-4dec-b98e-d0cbdcd26b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def lookup_ookla_file(filename):\n",
    "    \"\"\"Get OoklaFile for the given filename\"\"\"\n",
    "    return next((k for k, v in list_ookla_files().items() if v == filename), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "273a93d1-1b48-44e1-9214-6c28e237c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert lookup_ookla_file(\"2021-04-01_performance_fixed_tiles.parquet\") == OoklaFile(\n",
    "    \"fixed\", \"2021\", \"2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6154b68d-331f-4bd5-a144-7219980433f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def compute_datakey(aoi_bounds, type_, year, return_geometry):\n",
    "    data_tuple = (\n",
    "        np.array2string(aoi_bounds, precision=6),\n",
    "        str(type_),\n",
    "        str(year),\n",
    "        str(return_geometry),\n",
    "    )\n",
    "    m = hashlib.md5()\n",
    "    for item in data_tuple:\n",
    "        m.update(item.encode())\n",
    "    data_key = m.hexdigest()\n",
    "    return data_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b69fc5-2d54-48af-a9ff-61afe535ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def write_ookla_metajson(\n",
    "    cache_dir, data_key, total_bounds, type_, year, return_geometry\n",
    "):\n",
    "    extension = \"geojson\" if return_geometry else \"csv\"\n",
    "    cached_metajson_file_path = cache_dir / f\"{data_key}.{extension}.metadata.json\"\n",
    "    with open(cached_metajson_file_path, \"w\") as f:\n",
    "        f.write(\n",
    "            json.dumps(\n",
    "                {\n",
    "                    \"bounds\": np.array2string(total_bounds, precision=6),\n",
    "                    \"type_\": type_,\n",
    "                    \"year\": year,\n",
    "                    \"with_geom\": return_geometry,\n",
    "                }\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c720b27-0194-4dcc-80c5-42a8bde7c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class OoklaDataManager:\n",
    "    \"\"\"An instance of this class provides convenience functoins for loading and caching Ookla data\"\"\"\n",
    "\n",
    "    def __init__(self, cache_dir=DEFAULT_CACHE_DIR):\n",
    "        self.aggregated_cache = {}\n",
    "        self.cache_dir = os.path.expanduser(cache_dir)\n",
    "        processed_cache_dir = os.path.join(self.cache_dir, \"ookla/processed/\")\n",
    "        aggregated_cache_dir = os.path.join(self.cache_dir, \"ookla/aggregated/\")\n",
    "        self.processed_cache_dir = Path(processed_cache_dir)\n",
    "        self.processed_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.aggregated_cache_dir = Path(aggregated_cache_dir)\n",
    "        self.aggregated_cache_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be695dbe-a999-4b6b-adc7-98b2837a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def reinitialize_processed_cache(self: OoklaDataManager):\n",
    "    \"Reinitialize processed_cache_dir to start over from scratch.\"\n",
    "    shutil.rmtree(self.processed_cache_dir, ignore_errors=True)\n",
    "    self.processed_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(\n",
    "        f\"{self.processed_cache_dir} reintialized. All cached processed data in this folder has been deleted.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af3f5988-fc7e-4e96-a555-7c0a17638e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def reinitialize_aggregated_cache(self: OoklaDataManager):\n",
    "    \"Reinitialize aggregated_cache_dir to start over from scratch.\"\n",
    "    shutil.rmtree(self.aggregated_cache_dir, ignore_errors=True)\n",
    "    self.aggregated_cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(\n",
    "        f\"{self.aggregated_cache_dir} reintialized. All cached aggregated data in this folder has been deleted.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7ddb416-74c9-4579-9792-ea269ce19ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def load_type_year_data(\n",
    "    self: OoklaDataManager,\n",
    "    aoi: gpd.GeoDataFrame,  # area of interest\n",
    "    type_: str,  # ookla data type: fixed or mobile\n",
    "    year: str,  # year\n",
    "    use_cache=True,  # use cache dir\n",
    "    return_geometry=False,  # include geometry in returned values\n",
    "    show_progress=True,  # display progress bar\n",
    "    chunksize=8192,  # download buffer size\n",
    "    reporthook=None,  # custom progress bar\n",
    "):\n",
    "    \"Load Ookla data across all quarters for a specified aoi, type (fixed, mobile) and year\"\n",
    "\n",
    "    # Generate hash from aoi, type_, and year, which will act as a hash key for the cache\n",
    "    data_key = compute_datakey(aoi.total_bounds, type_, year, return_geometry)\n",
    "\n",
    "    # Get cached data from filesystem if saved\n",
    "    extension = \"geojson\" if return_geometry else \"csv\"\n",
    "    cached_file_path = self.processed_cache_dir / f\"{data_key}.{extension}\"\n",
    "\n",
    "    if cached_file_path.exists() and use_cache:\n",
    "        logger.debug(\n",
    "            f\"Processed Ookla data for aoi, {type_} {year} found in {cached_file_path}. Loading in cache.\"\n",
    "        )\n",
    "        if not return_geometry:\n",
    "            df = pd.read_csv(cached_file_path)\n",
    "        else:\n",
    "            df = gpd.read_file(cached_file_path, driver=\"GeoJSON\")\n",
    "        return df\n",
    "    if not cached_file_path.exists():\n",
    "        logger.debug(\"No cached data found. Processing Ookla data from scratch.\")\n",
    "    else:\n",
    "        logger.debug(\"Overwriting cache contents. Processing Ookla data from scratch\")\n",
    "\n",
    "    # Otherwise, load from raw file and add to RAM cache\n",
    "    type_year_cache_dir = download_ookla_year_data(\n",
    "        type_,\n",
    "        year,\n",
    "        cache_dir=self.cache_dir,\n",
    "        use_cache=use_cache,\n",
    "        show_progress=show_progress,\n",
    "        chunksize=chunksize,\n",
    "        reporthook=reporthook,\n",
    "    )\n",
    "\n",
    "    # Generate the bing tile quadkeys that intersect with the input aoi\n",
    "    logger.debug(\n",
    "        f\"Generating bing tile grids for aoi total bounds {np.array2string(aoi.total_bounds, precision=6)}\"\n",
    "    )\n",
    "    bing_tile_grid_generator_no_geom = grids.BingTileGridGenerator(\n",
    "        OOKLA_QUADKEY_LEVEL, return_geometry=False\n",
    "    )\n",
    "    aoi_quadkeys = bing_tile_grid_generator_no_geom.generate_grid(aoi)[\n",
    "        \"quadkey\"\n",
    "    ].tolist()\n",
    "\n",
    "    # Combine quarterly data for the specified year, filtered to the aoi using quadkey\n",
    "    # Quarter is inferred from the Ookla filename\n",
    "    quarter_df_list = []\n",
    "    for ookla_filename in sorted(os.listdir(type_year_cache_dir)):\n",
    "        ooklaFile = lookup_ookla_file(ookla_filename)\n",
    "        if ooklaFile:\n",
    "            ookla_quarter_filepath = os.path.join(type_year_cache_dir, ookla_filename)\n",
    "            logger.debug(\n",
    "                f\"Ookla data for aoi, {type_} {year} {ooklaFile.quarter} being loaded from {ookla_quarter_filepath}\"\n",
    "            )\n",
    "            quarter_df = pd.read_parquet(ookla_quarter_filepath)\n",
    "            # TODO optimize filtering via merge\n",
    "            quarter_df = quarter_df[quarter_df[\"quadkey\"].isin(aoi_quadkeys)]\n",
    "            quarter_df[\"quarter\"] = int(ooklaFile.quarter)\n",
    "            quarter_df_list.append(quarter_df)\n",
    "\n",
    "            # Free memory after processing\n",
    "            del quarter_df\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Concatenating quarterly Ookla data for {type_} and {year} into one dataframe\"\n",
    "    )\n",
    "    df = pd.concat(quarter_df_list, ignore_index=True)\n",
    "\n",
    "    # NOTE: Since there will be groupby operations in processing, we don't return\n",
    "    #       a geodataframe by default since it does not work well with aggregations\n",
    "    #       by quadkey.\n",
    "    write_ookla_metajson(\n",
    "        self.processed_cache_dir,\n",
    "        data_key,\n",
    "        aoi.total_bounds,\n",
    "        type_,\n",
    "        year,\n",
    "        return_geometry,\n",
    "    )\n",
    "\n",
    "    if not return_geometry:\n",
    "        logger.debug(f\"Saving Ookla data into csv file {cached_file_path}\")\n",
    "        df.to_csv(cached_file_path, index=False)\n",
    "    else:\n",
    "        logger.debug(f\"Converting Ookla data into geojson file {cached_file_path}\")\n",
    "        df = gpd.GeoDataFrame(df, geometry=gpd.GeoSeries.from_wkt(df[\"tile\"]))\n",
    "        df.to_file(cached_file_path, driver=\"GeoJSON\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75432dda-099d-4aa1-b593-6a17303a124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@patch\n",
    "def aggregate_ookla_features(\n",
    "    self: OoklaDataManager,  # Ookla Data Manager Instance\n",
    "    aoi: gpd.GeoDataFrame,  # Area of interest\n",
    "    type_: str,  # Ookla speed type: 'fixed` or `mobile`\n",
    "    year: str,  # Year to aggregate (over 4 quarters)\n",
    "    use_cache=True,  # Use cached data in cache dir as specified in ookla_data_manager\n",
    "    return_geometry=False,  # Save aggregated data as geojson\n",
    "    output_crs=\"epsg:4326\",  # crs to use in creating aggregated geodataframe\n",
    "    aggregations: Dict[  # Aggregation functions on ookla data (see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html)\n",
    "        str, Any\n",
    "    ] = dict(\n",
    "        mean_avg_d_kbps=(\"avg_d_kbps\", \"mean\"),\n",
    "        mean_avg_u_kbps=(\"avg_u_kbps\", \"mean\"),\n",
    "        mean_avg_lat_ms=(\"avg_lat_ms\", \"mean\"),\n",
    "        mean_num_tests=(\"tests\", \"mean\"),\n",
    "        mean_num_devices=(\"devices\", \"mean\"),\n",
    "    ),\n",
    "    show_progress=True,  # display progress bar\n",
    "    chunksize=8192,  # download buffer size\n",
    "    reporthook=None,  # custom progress bar\n",
    "):\n",
    "    \"\"\"Generates yearly aggregate features for the AOI based on Ookla data for a given type (fixed, mobile) and year.\"\"\"\n",
    "\n",
    "    data_key = compute_datakey(aoi.total_bounds, type_, year, return_geometry)\n",
    "    logger.debug(f\"Contents of aggregated ache: {list(self.aggregated_cache.keys())}\")\n",
    "    if data_key in self.aggregated_cache:\n",
    "        logger.debug(\n",
    "            f\"Ookla aggregated data for aoi, {type_} {year} (key: {data_key}) found in cache.\"\n",
    "        )\n",
    "        return self.aggregated_cache[data_key]\n",
    "\n",
    "    # see if in file system\n",
    "    ## Get cached data from filesystem if saved\n",
    "    extension = \"geojson\" if return_geometry else \"csv\"\n",
    "    cached_file_path = self.aggregated_cache_dir / f\"{data_key}.{extension}\"\n",
    "\n",
    "    if cached_file_path.exists() and use_cache:\n",
    "        logger.debug(\n",
    "            f\"Aggregated Ookla data for aoi, {type_} {year} (key: {data_key}) found in filesystem. Loading in cache.\"\n",
    "        )\n",
    "        if return_geometry:\n",
    "            df = gpd.read_file(cached_file_path, driver=\"GeoJSON\")\n",
    "        else:\n",
    "            df = pd.read_csv(cached_file_path)\n",
    "        return df\n",
    "\n",
    "    if cached_file_path.exists():\n",
    "        logger.debug(\"Overwriting cached data. Processing Ookla data from scratch.\")\n",
    "    else:\n",
    "        logger.debug(\"No aggregated data found. Processing Ookla data from scratch.\")\n",
    "\n",
    "    ookla = self.load_type_year_data(\n",
    "        aoi,\n",
    "        type_,\n",
    "        year,\n",
    "        use_cache=use_cache,\n",
    "        return_geometry=return_geometry,\n",
    "        show_progress=show_progress,\n",
    "        chunksize=chunksize,\n",
    "        reporthook=reporthook,\n",
    "    )\n",
    "\n",
    "    # Combine quarterly data from Ookla into yearly aggregate data\n",
    "    # Geometries are stored separately and rejoined after aggregation by quadkey\n",
    "    # TODO: incorporate parametrized aggregations, take inspiration from GeoWrangler agg spec\n",
    "\n",
    "    logger.info(\n",
    "        f\"Aggregating ookla data for bounds {np.array2string(aoi.total_bounds, precision=6)} type {type_} year {year} \"\n",
    "    )\n",
    "    ookla_geoms = ookla[[\"quadkey\", \"tile\"]].drop_duplicates().reset_index(drop=True)\n",
    "    ookla_yearly = ookla.groupby(\"quadkey\").agg(**aggregations).reset_index()\n",
    "    # Add type_year prefix to feature names\n",
    "    ookla_yearly = ookla_yearly.rename(\n",
    "        {\n",
    "            col: f\"{type_}_{year}_\" + col\n",
    "            for col in ookla_yearly.columns[~ookla_yearly.columns.isin([\"quadkey\"])]\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    ookla_yearly = ookla_yearly.merge(ookla_geoms, on=\"quadkey\", how=\"left\")\n",
    "\n",
    "    # write ookla_yearly to cache/aggregated\n",
    "\n",
    "    if return_geometry:\n",
    "        logger.debug(\n",
    "            f\"Saving Ookla aggregated data into geojson file {cached_file_path}\"\n",
    "        )\n",
    "        ookla_yearly = gpd.GeoDataFrame(\n",
    "            ookla_yearly,\n",
    "            geometry=gpd.GeoSeries.from_wkt(ookla_yearly[\"tile\"], crs=output_crs),\n",
    "        )\n",
    "        ookla_yearly.to_file(cached_file_path, driver=\"GeoJSON\")\n",
    "    else:\n",
    "        logger.debug(f\"Saving Ookla aggregated data into csv file {cached_file_path}\")\n",
    "        ookla_yearly.to_csv(cached_file_path)\n",
    "    write_ookla_metajson(\n",
    "        self.aggregated_cache_dir,\n",
    "        data_key,\n",
    "        aoi.total_bounds,\n",
    "        type_,\n",
    "        year,\n",
    "        return_geometry,\n",
    "    )\n",
    "\n",
    "    self.aggregated_cache[data_key] = ookla_yearly\n",
    "\n",
    "    return ookla_yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23d8b707-6b41-426b-9135-a422d5a2ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 05_datasets_ookla.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "# no_test\n",
    "from nbdev.export import notebook2script\n",
    "\n",
    "notebook2script(\"05_datasets_ookla.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4a07a05096b6351e45107f092fcbc6d58e4d1183d490a1128ce24e8ca5af3ddc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
